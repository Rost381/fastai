1
00:00:00,149 --> 00:00:03,600
Добро пожаловать на третью неделю курса.

2
00:00:03,600 --> 00:00:09,599
Вы наверняка заметили, что на этой неделе на форумах происходило много интересного.

3
00:00:09,599 --> 00:00:25,920
Многие участники курса подготовили материалы по курсу, чтобы помочь своим одногруппникам и лучше разобраться самим.

4
00:00:25,920 --> 00:00:32,340
Я хочу рассказать про некоторые, про что-то я уже писал на вики, но материалов очень много.

5
00:00:32,340 --> 00:00:42,480
Пользователь reshamas создала много полезных заметок — например, что делать, если не получается подключиться к AWS,

6
00:00:46,079 --> 00:00:57,750
она расписала всё в мелочах, я считаю, что это очень круто.

7
00:00:57,750 --> 00:01:05,460
Если вы делаете какие-то заметки для себя — поделитесь ими на форуме, это удобно делать в файлах разметки Markdown.

8
00:01:07,439 --> 00:01:13,789
Если вы загрузите свои заметки на GitHub, все смогут ими пользоваться. Или загрузите их на наш форум,

9
00:01:13,889 --> 00:01:25,140
reshamas сделала так со своей заметкой про tmux.

10
00:01:25,140 --> 00:01:39,869
tmux — консольная утилита, позволяющая показывать несколько терминалов на одном экране.

11
00:01:39,869 --> 00:01:48,210
Здесь в одном терминале у меня модули библиотеки, открытые редактором vim,

12
00:01:48,210 --> 00:01:53,579
в другом запущен Jupyter Notebook и так далее.

13
00:01:53,579 --> 00:02:03,060
Если интересно, reshamas написала на эту тему туториал, в её аккаунте на GitHub ещё много интересного.

14
00:02:03,060 --> 00:02:28,810
Apil Tamang написал хороший сжатый конспект предыдущей лекции.

15
00:02:29,610 --> 00:02:45,069
Pavel Surmenok написал пост про алгоритм поиска скорости обучения.

16
00:02:45,069 --> 00:02:59,500
Это очень круто, потому что об этом алгоритме ещё нигде не писали, а он очень полезный.

17
00:02:59,500 --> 00:03:13,560
Когда я поделился ссылкой на его пост в Twitter, им поделились сотни раз, у поста тысячи просмотров, отличная работа.

18
00:03:13,560 --> 00:03:20,779
Radek написал несколько полезных постов, мне особенно понравился гайд по PyTorch,

19
00:03:20,879 --> 00:03:32,260
он подойдёт для продвинутых студентов, например, тех, кто никогда не использовал PyTorch, но уже что-то знает про численное программирование.

20
00:03:35,560 --> 00:03:40,624
Есть интересная статья про связь между скоростью обучения и размером минибатча.

21
00:03:40,724 --> 00:03:46,030
Один студент недавно задал мне этот вопрос, поэтому я вспомнил этот пост.

22
00:03:46,030 --> 00:04:01,235
Автор поста пробовал различные скорости обучения и размеры минибатча и проанализировал, как они связаны, можете сами попробовать.

23
00:04:01,335 --> 00:04:15,586
Radek написал пост на тему моего утверждения о том, что SDGR находит более плоские области поверхности потерь и в них модель лучше обобщает.

24
00:04:15,686 --> 00:04:25,147
Он попробовал описать эту закономерность более точно, не очень удачно, но пост интересный.

25
00:04:25,247 --> 00:04:32,999
Есть пост по введению в свёрточные нейронные сети.

26
00:04:32,999 --> 00:04:57,059
Anand Saha написал отличный анализ архитектуры ResNet, мы ещё обсудим это в курсе, продвинутые студенты могут читать уже сейчас.

27
00:04:57,059 --> 00:05:04,349
Apil Tamang написал похожий пост. В общем, на форумах много чего происходит.

28
00:05:06,059 --> 00:05:17,479
Мы также создали форум для новичков. Тупых вопросов не бывает, но иногда страшно задавать вопрос про что-то простое,

29
00:05:19,860 --> 00:05:29,819
когда вокруг обсуждаются очень сложные вещи. Надеемся, что форум новичков будет не таким устрашающим.

30
00:05:29,819 --> 00:05:38,632
Если вы продвинутый студент и можете отвечать на такие вопросы, пожалуйста, делайте это дружелюбно —

31
00:05:38,732 --> 00:05:47,934
у людей за плечами может быть всего год опыта программирования и никакого опыта машинного обучения.

32
00:05:48,034 --> 00:05:56,159
Если вам хочется написать какой-то вспомогательный материал, не стесняйтесь — большинство авторов только что упомянутых заметок

33
00:05:56,159 --> 00:06:04,769
никогда не публиковали ничего в интернете, они такие же люди, как и вы.

34
00:06:04,769 --> 00:06:20,399
Если вы не уверены в каких-то деталях, запостите сначала на форум, люди помогут вам улучшить ваш материал фразами вроде

35
00:06:20,399 --> 00:06:29,439
«Вот здесь всё устроено немного по-другому, сейчас расскажу» или «Это очень интересно, вы не думали углубиться в эту тему?».

36
00:06:29,539 --> 00:06:38,969
К текущему моменту мы немного обсудили свёрточные нейронные сети.

37
00:06:38,969 --> 00:06:59,319
Мы не углублялись в детали того, как они работают, зато построили на их основе превосходного качества модель.

38
00:06:59,319 --> 00:07:12,280
Сегодня мы ещё раз посмотрим на модели и наконец-то подойдём к теории — что такое свёрточная нейронная сеть,

39
00:07:12,280 --> 00:07:16,000
что такое свёртка, как и почему это работает.

40
00:07:16,000 --> 00:07:25,930
Дальше мы продвинемся по нашему плану и обсудим использование нейронных сетей для анализа структурированных данных —

41
00:07:25,930 --> 00:07:31,449
логистика, прогнозы, анализ рынка и прочее.

42
00:07:31,449 --> 00:07:45,550
Потом посмотрим на обработку естественного языка, потом на коллаборативную фильтрацию для рекомендательных систем.

43
00:07:45,550 --> 00:07:53,020
Это будет проходить в том же формате, что и обсуждение CNN — без углубления в теорию, но с построением качественных моделей.

44
00:07:55,150 --> 00:08:01,984
Потом мы пройдёмся по этим же темам, но в другом порядке и более углубленно —

45
00:08:02,084 --> 00:08:09,949
рассмотрим коллаборативную фильтрацию, поймём, как написан соответствующий код и какая за этим стоит математика,

46
00:08:10,049 --> 00:08:20,620
потом сделаем то же самое для анализа структурированных данных, свёрточных нейронных сетей и обработки естественного языка.

47
00:08:20,620 --> 00:08:37,078
Давайте проговорим некоторые вещи с прошлых лекций ещё раз.

48
00:08:37,178 --> 00:08:55,889
Я хочу убедиться, что все смогут повторить модель с прошлой лекции для различения пород собак.

49
00:08:55,889 --> 00:09:11,339
Для этого нужно скачать данные. Данные можно скачивать либо с Kaggle, либо откуда-то ещё.

50
00:09:11,339 --> 00:09:37,960
Для скачивания данных с Kaggle мы используем kaggle-cli, он должен был установиться при загрузке материалов для курса.

51
00:09:38,060 --> 00:09:53,279
Поскольку данные скачиваются с сайта Kaggle, каждый раз, как на сайте что-то меняется, kaggle-cli ломается,

52
00:09:53,279 --> 00:10:13,434
с этим можно справиться командой pip install kaggle-cli --upgrade.

53
00:10:13,534 --> 00:10:25,765
После этого следуйте инструкциям reshamas для скачивания данных.

54
00:10:25,865 --> 00:10:43,509
Команда для скачивания данных: kg download -u <username> -p <password> -c <competition>.

55
00:10:43,609 --> 00:11:02,100
<competition> — это фраза, идущая после /c/ в адресной строке на странице соревнования.

56
00:11:02,100 --> 00:11:12,650
Перед скачиванием данных через kaggle-cli убедитесь, что согласились с правилами соревнования — для этого начните скачивать данные с сайта.

57
00:11:12,750 --> 00:11:18,850
Если правила не приняты, kaggle-cli вам об этом скажет.

58
00:11:18,850 --> 00:11:31,085
Если вы используете аккаунт Google для входа в Kaggle, kaggle-cli не будет работать, используйте форму восстановления пароля Kaggle.

59
00:11:31,185 --> 00:11:38,775
kaggle-cli создаст папку на вашем компьютере и скачает туда данные.

60
00:11:38,875 --> 00:11:52,600
kaggle-cli не подходит, если вы используете датасет не с Kaggle или если вам не нужны все предоставленные там данные.

61
00:11:52,600 --> 00:12:11,890
Например, в этом соревновании данные предоставлены в форматах TIFF (19 ГБ) и JPG (600 МБ), возможно, вы не захотите использовать оба.

62
00:12:11,890 --> 00:12:32,480
Для таких случаев есть расширение CurlWget для Google Chrome.

63
00:12:32,580 --> 00:13:02,944
Для всех страниц, откуда можно что-нибудь скачать, CurlWget предоставит вам ссылку для скачивания из терминала.

64
00:13:03,044 --> 00:13:10,449
В ссылке содержатся куки вашего браузера, плагин активируется, когда вы запускаете скачивание в первый раз.

65
00:13:10,449 --> 00:13:19,420
С помощью этого расширения можно скачать что угодно — например, ваш любимый сериал.

66
00:13:19,420 --> 00:13:33,610
Это очень полезный инструмент для анализа данных, потому что зачастую приходится анализировать видео.

67
00:13:33,610 --> 00:13:44,019
Итак, есть два способа получить данные. После этого можно начинать обучать модель.

68
00:13:44,019 --> 00:13:57,670
В переменной PATH указано, что данные лежат в директории data рабочей директории Jupyter ноутбука.

69
00:13:57,670 --> 00:14:04,990
Это не всегда удобно — данные могут лежать в другом месте или даже на другом диске,

70
00:14:04,990 --> 00:14:17,949
поэтому можно создать символическую ссылку на директорию с данными.

71
00:14:17,949 --> 00:14:24,109
Вы можете сложить ваши данные куда угодно и добавить на них ссылку или сложить их в рабочую директорию Jupyter ноутбука.

72
00:14:24,209 --> 00:14:35,829
Символические ссылки — это очень удобно, можете почитать про них на нашем форуме, если не работали с ними раньше.

73
00:14:35,829 --> 00:14:45,490
Как видите, модули библиотеки fast.ai доступны из Jupyter ноутбука таким же образом.

74
00:14:45,490 --> 00:15:06,845
Чтобы вывести список файлов и директорий с указанием ссылок в Linux, используйте команду ls -l.

75
00:15:06,945 --> 00:15:20,315
Вам могло показаться, что для обучения модели нужно больше кода, чем на самом деле.

76
00:15:20,415 --> 00:15:28,292
Здесь на одном экране показаны все шаги, которые я проделал для обучения модели для классификации кошек и собак.

77
00:15:28,392 --> 00:15:36,197
Здесь не показаны скачивание и распаковка данных с Kaggle.

78
00:15:36,297 --> 00:15:51,130
Это все необходимые этапы. Сначала мы импортируем библиотеки — fastai.conv_learner импортирует всё необходимое сам.

79
00:15:51,130 --> 00:15:57,860
Нужно указать путь к файлам, размер изображений и размер минибатча.

80
00:15:57,960 --> 00:16:10,940
В этой строке мы говорим, как нужно преобразовать изображения — какая будет модель, какого они должны быть размера,

81
00:16:11,040 --> 00:16:18,490
какой алгоритм дополнения данных использовать, какое максимальное увеличение использовать.

82
00:16:18,490 --> 00:16:34,360
Здесь мы говорим, что данные рассортированы на обучающую и валидационную выборку, а внутри каждой выборки — на кошек и собак.

83
00:16:34,360 --> 00:16:45,170
Если папки с обучающей и валидационной выборкой названы нестандартно, их названия можно передать через параметры trn_name и val_name.

84
00:16:45,270 --> 00:16:56,380
Название папки с неразмеченной тестовой выборкой test_name необходимо указывать, если вы будете отправлять модель на Kaggle.

85
00:16:59,770 --> 00:17:08,205
После этого мы создаём модель с архитектурой ResNet на основе уже обученной и вызываем метод .fit().

86
00:17:08,305 --> 00:17:17,420
Напомню, что по умолчанию все слои, кроме последних, заморожены, мы ещё будем про это говорить.

87
00:17:17,420 --> 00:17:23,110
Метод .fit() работал около двух с половиной минут. Я не выставлял precompute=True.

88
00:17:26,119 --> 00:17:35,390
На форумах было много уточняющих вопросов по поводу значения этого параметра, повторюсь — это просто небольшое ускорение.

89
00:17:35,390 --> 00:17:42,325
Если не до конца понятно, просто пропускайте и оставляйте precompute=False по умолчанию.

90
00:17:42,425 --> 00:17:52,635
precompute=True кэширует некоторые промежуточные результаты, чтобы их не нужно было пересчитывать каждый раз.

91
00:17:52,735 --> 00:18:11,180
Помните, что с precomputed=True не работает дополнение данных, потому что дополнение данных не работает с предвычисленными активациями.

92
00:18:11,180 --> 00:18:14,780
Я максимально упростил процесс, поэтому precompute=False.

93
00:18:14,780 --> 00:18:22,810
Последний слой обучается 3 цикла с длиной цикла в одну эпоху (cycle_len=1).

94
00:18:23,110 --> 00:18:27,190
После этого я размораживаю модель и обучаю уже все слои.

95
00:18:27,590 --> 00:18:39,170
Метод .bn_freeze() мы ещё обсудим, это особенность сложных архитектур типа ResNet50 или ResNeXt101.

96
00:18:39,170 --> 00:18:49,005
Эту строку имеет добавлять после разморозки, если вы используете датасеты, подобные изображениям ImageNet —

97
00:18:49,105 --> 00:19:02,495
фотографии обычных объектов со стороны размера от 200 до 500 пикселей.

98
00:19:02,595 --> 00:19:10,630
Для продвинутых студентов — это фиксирует нормализацию минибатчей.

99
00:19:10,730 --> 00:19:20,409
Мы ещё обсудим это во второй части курса, в других библиотеках этого нет, но это очень важный аспект.

100
00:19:20,409 --> 00:19:31,789
После этого все слои нейронной сети обучаются в течение одной эпохи, и применяется дополнение тестовых данных.

101
00:19:31,889 --> 00:19:37,909
Это даёт долю правильных ответов в 99.45%.

102
00:19:38,009 --> 00:19:47,139
Это минимальные шаги, которые можно выполнить при работе с новым датасетом,

103
00:19:47,139 --> 00:20:02,799
при условии, что вы уже подобрали скорость обучения, знаете, как устроены данные и так далее.

104
00:20:02,799 --> 00:20:15,499
Я хотел показать вам, как устроены другие библиотеки, и выбрал для этого Keras.

105
00:20:15,599 --> 00:20:33,059
Библиотека fast.ai построена на основе PyTorch, а Keras поддерживает TensorFlow, MXNet, CNTK и многие другие библиотеки,

106
00:20:33,159 --> 00:20:37,450
большинство людей используют Keras с TensorFlow.

107
00:20:37,450 --> 00:20:51,024
В Jupyter ноутбуке keras_lesson1.ipynb я постараюсь воссоздать модель с первой лекции на Keras, чтобы вы увидели, как это можно делать.

108
00:20:51,124 --> 00:20:59,510
Я не буду пока ничего говорить про метод .bn_freeze(), кроме показаний к применению —

109
00:21:00,850 --> 00:21:11,950
это архитектура нейронной сети с числом слоёв больше 34, как ResNet50 или ResNeXt101,

110
00:21:11,950 --> 00:21:24,520
и датасет, похожий на изображения ImageNet, где объект занимает большую часть изображений нормального размера.

111
00:21:24,520 --> 00:21:32,989
Если вы не уверены в его необходимости, попробуйте убрать и сравнить результаты.

112
00:21:33,089 --> 00:21:39,910
Продвинутые студенты наверняка начнут обсуждать это на форумах уже сейчас, а мы дойдём до этого

113
00:21:39,910 --> 00:21:46,720
только во второй части курса, когда вернёмся к свёрточным нейронным сетям.

114
00:21:50,820 --> 00:22:01,480
Итак, для работы с Keras нужно импортировать необходимые модули.

115
00:22:01,480 --> 00:22:12,151
Keras поддерживает стандартный способ сортировки данных на обучающую и валидационную выборки и на классы внутри выборок.

116
00:22:12,251 --> 00:22:22,805
Здесь мы указываем пути к папкам с обучающей и валидационной выборкой.

117
00:22:22,905 --> 00:22:36,575
Вы заметите, что с Keras обучение модели требует больше кода и различных параметров,

118
00:22:36,675 --> 00:22:44,650
и очень просто задать неправильные параметры, поэтому я постараюсь подробно всё показать.

119
00:22:44,650 --> 00:22:55,030
Для подготовки данных необходимо создать генератор данных конструктором ImageDataGenerator().

120
00:22:55,030 --> 00:23:10,634
В параметры генератора данных необходимо передать параметры дополнения данных и нормализации.

121
00:23:10,734 --> 00:23:15,619
В библиотеке fast.ai достаточно указать архитектуру, например, ResNet50, и необходимые параметры выставляются автоматически,

122
00:23:15,719 --> 00:23:21,700
здесь надо примерно понимать, что для этого требуется.

123
00:23:21,700 --> 00:23:30,220
В принципе копирования кода из интернета достаточно, чтобы всё работало.

124
00:23:30,220 --> 00:23:43,550
Нет общепринятых стандартов по поводу этих параметров дополнения данных, я скопировал эту строку из документации Keras.

125
00:23:43,550 --> 00:23:49,140
Я не знаю, хороший ли это набор параметров, но в документации используется такой.

126
00:23:49,240 --> 00:23:56,540
Параметры говорят, отражать ли изображения относительно горизонтали, как увеличивать, как сдвигать.

127
00:23:56,540 --> 00:24:03,102
Из генератора данных создаётся генератор методом .flow_from_directory().

128
00:24:03,202 --> 00:24:17,985
В его параметры передаётся путь к файлам, размер изображений, размер минибатча и параметр class_mode.

129
00:24:18,085 --> 00:24:31,650
Параметр class_mode указывает вид задачи классификации — двухклассовая или многоклассовая, 'binary' или 'categorial'.

130
00:24:31,750 --> 00:24:36,525
У нас два класса — кошки и собаки, class_mode='binary'.

131
00:24:36,625 --> 00:24:48,048
Необходимо отдельно создать генератор данных без дополнения данных для валидации

132
00:24:48,148 --> 00:25:00,760
и создать соответствующий генератор с параметром shuffle=False, чтобы валидационная выборка не перемешивалась —

133
00:25:00,860 --> 00:25:11,270
это полезно для обучающей выборки, но на валидационной помешает отслеживать прогресс в обучении.

134
00:25:11,270 --> 00:25:18,465
Эти шаги в Keras необходимо делать каждый раз.

135
00:25:18,565 --> 00:25:32,750
Keras не поддерживает ResNet34, поэтому в конце прошлой лекции я поменял ResNet34 на ResNet50, чтобы мы могли сравнить fastai и Keras на одной архитектуре.

136
00:25:32,750 --> 00:25:42,290
В Keras модель не подстраивается под датасет автоматически, это нужно делать вручную.

137
00:25:42,290 --> 00:25:50,600
Для этого конструктором ResNet50() создаётся базовая модель и к ней вручную добавляются дополнительные слои.

138
00:25:50,600 --> 00:26:01,370
К концу этого курса вы поймёте, почему мы добавили именно эти три слоя.

139
00:26:01,370 --> 00:26:06,070
Модель создаётся конструктором Model().

140
00:26:06,070 --> 00:26:19,515
В Keras нет встроенной функции заморозки, поэтому мы проходим по всем слоям и выставляем поле .trainable=False.

141
00:26:19,615 --> 00:26:27,110
В Keras необходимо компилировать модель после создания методом .compile().

142
00:26:28,160 --> 00:26:35,360
Метод принимает как параметры вид оптимизации, функцию потерь и метрику оценки качества модели.

143
00:26:36,439 --> 00:26:47,324
В fast.ai эти значения передаются по умолчанию, хотя есть возможность заменить их своими.

144
00:26:47,424 --> 00:26:55,886
Вместо метода .fit() вызывается метод .fit_generator(), он принимает как параметры два только что созданных генератора,

145
00:26:55,886 --> 00:27:06,681
зачем-то просит количество минибатчей в одной эпохе — это размер генератора, делённый на размер минибатча.

146
00:27:07,081 --> 00:27:13,680
Как и в fast.ai, задаётся количество эпох.

147
00:27:15,100 --> 00:27:35,639
Задаётся количество воркеров. В отличие от fast.ai, по умолчанию они не используются, важно не забыть про этот параметр для достижения хорошей скорости.

148
00:27:35,739 --> 00:27:43,469
Этого достаточно, чтобы начать тонкую настройку последних слоёв.

149
00:27:43,569 --> 00:27:53,805
На валидационной выборке доля правильных ответов получилась 95%, но на первой и второй эпохах она была 49% и 69%.

150
00:27:53,905 --> 00:28:01,115
Я не знаю, почему это так — возможно, ошибка в Keras, возможно, в моём коде.

151
00:28:01,215 --> 00:28:07,469
Я писал про это в Twitter, но там никто не смог разобраться.

152
00:28:07,569 --> 00:28:15,509
Это одна из причин, почему я использую fast.ai в этом курсе — там гораздо сложнее всё испортить.

153
00:28:15,609 --> 00:28:18,806
Я не знаю, в чём тут ошибка.

154
00:28:18,906 --> 00:28:23,270
Янет: Здесь используется TensorFlow?

155
00:28:23,500 --> 00:28:50,279
Да, здесь используется TensorFlow, для этого нужно установить его командой pip install tensorflow-gpu keras.

156
00:28:50,379 --> 00:29:08,539
В Keras нет дифференциальных скоростей обучения и частичного размораживания, поэтому нужно вручную отделить последние слои.

157
00:29:08,539 --> 00:29:17,210
Я буду настраивать все слои, начиная со 140-го, для этого прохожу по всем слоям и замораживаю или размораживаю их, после этого снова вызываю метод .compile().

158
00:29:17,210 --> 00:29:26,924
После этого я снова обучаю модель, доля правильных ответов на обучающей выборке примерно такая же, а на валидационной опять ерунда.

159
00:29:27,024 --> 00:29:40,062
Даже если не учитывать это, Keras проигрывает в сравнении с fastai — кода гораздо больше и результаты хуже:

160
00:29:40,162 --> 00:29:49,934
модель на Keras за восемь минут достигла доли правильных ответов в 97% на обучающей выборке,

161
00:29:50,034 --> 00:30:02,380
а модель на fastai за четыре или пять минут — 99.5% на валидационной выборке.

162
00:30:02,380 --> 00:30:17,620
Используйте TensorFlow, если вы разрабатываете что-то для смартфонов, PyTorch пока плохо это поддерживает.

163
00:30:17,620 --> 00:30:24,365
Вам придётся использовать TensorFlow, если это делает компания, где вы работаете.

164
00:30:24,465 --> 00:30:37,000
Если вам нужно повторить что-то из этого курса с TensorFlow, используйте Keras и будьте готовы к тому,

165
00:30:37,000 --> 00:30:53,690
что будет больше кода, и будет сложнее повторить результаты, которые легко достигаются в fast.ai.

166
00:30:54,669 --> 00:31:05,990
В fast.ai нет ничего, что нельзя было бы повторить в Keras,

167
00:31:06,090 --> 00:31:20,389
но каждый раз заново писать SGDR, дифференциальные скорости обучения и всё остальное — неудобно.

168
00:31:20,489 --> 00:31:29,199
На форуме один человек работает над интеграцией Keras/TensorFlow и fast.ai, я надеюсь, что из этого что-то выйдет.

169
00:31:29,299 --> 00:31:43,270
Я разговаривал с Google и они тоже в этом заинтересованы. Возможно, к тому моменту, как этот курс появится на MOOC-платформе, это сделают.

170
00:31:43,270 --> 00:32:05,900
Keras/TensorFlow не очень сложные, для перехода с fast.ai после этого курса вам понадобится пара дней.

171
00:32:06,000 --> 00:32:19,890
Всего сказанного должно хватить для того, чтобы вы смогли обучить модель на датасете с породами собак.

172
00:32:19,890 --> 00:32:26,600
Большую часть того, что нужно сделать, я показал в конце прошлой лекции —

173
00:32:30,870 --> 00:32:37,885
например, как я изучал данные, чтобы понять, как устроены классы и какого размера изображения.

174
00:32:37,985 --> 00:32:41,980
Если вы что-то забыли, пересмотрите прошлую лекцию.

175
00:32:43,080 --> 00:32:53,794
Мы не успели обсудить, как отправить модель на Kaggle, сейчас покажу.

176
00:32:53,894 --> 00:33:01,500
Я уже написал про это в вики.

177
00:33:01,500 --> 00:33:12,955
На Kaggle для каждого соревнования есть вкладка Evaluation, в ней написано, какой формат нужен.

178
00:33:13,055 --> 00:33:19,810
В этом соревновании на выходе должен быть файл, где в заголовке — ID и все возможные породы собак,

179
00:33:20,410 --> 00:33:31,860
а в остальных строках — ID файлов тестовой выборки и вероятности того, что на этих файлах различные породы собак.

180
00:33:35,610 --> 00:33:55,240
Объект data.classes содержит названия всех классов в алфавитном порядке.

181
00:33:55,340 --> 00:34:01,645
Объект data.test_ds содержит тестовую выборку, названия файлов лежат в data.test_ds.fnames.

182
00:34:01,745 --> 00:34:18,444
Напоминаю, что изображения не разложены по папкам в стиле Keras, а размечены в csv-файле,

183
00:34:18,544 --> 00:34:27,859
поэтому мы используем метод ImageDataClassifier.from_csv(), а не ImageDataClassifier.from_paths().

184
00:34:31,799 --> 00:34:40,139
Keras не поддерживает такой формат, поэтому на форумах Kaggle люди выкладывают скрипты для сортировки данных по папкам,

185
00:34:40,139 --> 00:34:47,574
но нам этого делать не придётся.

186
00:34:47,674 --> 00:35:03,740
Итак, у нас есть названия пород и имена файлов тестовой выборки.

187
00:35:03,740 --> 00:35:28,789
Я всегда использую TTA при предсказании тестовой выборки, для этого в метод .TTA() передаётся параметр is_test=True,

188
00:35:28,889 --> 00:35:35,369
чтобы предсказания делались на тестовой выборке, а не на валидационной.

189
00:35:35,369 --> 00:35:44,765
Мы не знаем, какая получилась доля правильных ответов, потому что тестовая выборка не размечена.

190
00:35:44,865 --> 00:35:57,099
Большинство моделей PyTorch возвращает логарифмы вероятностей, метод np.exp() переводит их в обычные вероятности.

191
00:35:57,199 --> 00:36:10,529
В тестовой выборке 10357 изображений, принадлежащих 120 различным породам собак, это размеры полученной матрицы предсказаний probs.

192
00:36:10,529 --> 00:36:17,695
Из этой матрицы мы создадим файл необходимого формата с помощью pandas.

193
00:36:17,795 --> 00:36:27,472
Если вы не работали с pandas, погуглите или посмотрите наш курс по машинному обучению, там это часто используется.

194
00:36:27,572 --> 00:36:41,007
Мы создаём датафрейм pandas из матрицы конструктором pandas.DataFrame(), присваиваем колонкам названия пород собак

195
00:36:41,607 --> 00:36:57,745
и вставляем нулевую колонку с названиями файлов. Названия содержат 'test/' в начале и '.jpg' в конце, эти части мы обрезаем.

196
00:36:57,845 --> 00:37:06,550
Итоговый датафрейм выглядит так.

197
00:37:06,650 --> 00:37:24,000
Датафреймы с данными обычно называют df (data frame).

198
00:37:24,000 --> 00:37:36,680
С помощью метода .to_csv() можно записать получившийся датафрейм в csv-файл. Имеет смысл включить сжатие параметром compression='gzip'.

199
00:37:36,780 --> 00:37:45,082
После этого на сервере Jupyter Notebook появится csv-файл.

200
00:37:45,182 --> 00:37:57,235
После этого вы можете либо скачать файл с сервера и отправить его вручную, либо использовать kaggle-cli.

201
00:37:57,335 --> 00:38:04,170
Я обычно скачиваю файл себе на компьютер, чтобы посмотреть на него перед отправкой.

202
00:38:04,170 --> 00:38:27,130
Есть удобная утилита FileLink, которая создаёт ссылку, по которой можно скачать файл с сервера Jupyter Notebook на ваш компьютер.

203
00:38:33,490 --> 00:38:43,025
Архив с файлом скачался.

204
00:38:43,125 --> 00:38:54,095
Формат именно такой, какой нужно — в заголовке строке ID и породы собак, остальные строки содержат имя файла и вероятности.

205
00:38:54,195 --> 00:39:00,695
Теперь можно загрузить его на Kaggle через веб-интерфейс.

206
00:39:00,795 --> 00:39:15,160
Итак, теперь мы умеем скачивать файлы из интернета на сервер Jupyter Notebook через CurlWget в Google Chrome

207
00:39:17,170 --> 00:39:31,270
и умеем скачивать файлы с сервера на свой компьютер. Можно использовать scp в терминале, но мне нравится делать это в Jupyter ноутбуке.

208
00:39:31,270 --> 00:39:42,910
На этой неделе меня спросили, как получить предсказание только для одного файла.

209
00:39:42,910 --> 00:39:49,790
Допустим, я хочу получить предсказание для первого изображения валидационной выборки.

210
00:39:49,890 --> 00:39:59,350
Вот имя файла, я могу его вывести методом Image.open() стандартной библиотеки Python.

211
00:39:59,350 --> 00:40:16,230
Самое простое, что вы можете сделать — вызвать метод .predict_array().

212
00:40:16,230 --> 00:40:21,390
Для этого надо сначала применить к изображению дополнение данных.

213
00:40:21,390 --> 00:40:36,310
Функция tfms_from_model возвращает преобразования данных отдельно для обучающей и валидационной выборки.

214
00:40:36,310 --> 00:40:45,280
После этого мы применяем на изображении дополнение данных для обучающей выборки. Нет, лучше для валидационной.

215
00:40:45,280 --> 00:40:52,420
Полученный массив можно передавать в метод .predict_array().

216
00:40:55,440 --> 00:41:05,320
Данные можно подавать в модель и получать от модели только в минибатчах.

217
00:41:05,320 --> 00:41:15,250
У нас только одно изображение, и мы хотим превратить его в минибатч,

218
00:41:15,250 --> 00:41:21,490
то есть превратить из тензора размерности (количество строк)x(количество столбцов)х(цветовые каналы)

219
00:41:21,490 --> 00:41:26,230
в тензор размерности (количество изображений)x(количество строк)x(количество столбцов)х(цветовые каналы).

220
00:41:26,230 --> 00:41:31,330
У нас трёхмерная матрица, а должна быть четырёхмерная.

221
00:41:31,330 --> 00:41:46,480
Если в numpy индексировать массив im как im[None], вернётся массив размерностью больше на 1, так мы превратили изображение в минибатч.

222
00:41:46,480 --> 00:42:02,080
Если вы забудете это сделать при использовании PyTorch или fast.ai, получите ошибку вроде «expected 4 dimensions but got 3».

223
00:42:02,080 --> 00:42:15,040
Модели не только принимают, но и возвращают минибатчи, это тоже учтите.

224
00:42:15,040 --> 00:42:38,405
На этом мы закончим с практикой и перейдём к теории свёрточных нейронных сетей.

225
00:42:38,505 --> 00:42:54,175
На первой лекции мы немного поговорили про теорию, используя демонстрацию setosa.io/ev/, Explained Visually.

226
00:42:54,275 --> 00:43:03,910
Мы узнали, что свёртка — это алгоритм, который рассматривает область 3х3 пикселя за раз и умножает значение каждого пикселя

227
00:43:04,010 --> 00:43:16,790
на соответствующее значение матрицы свёртки, а потом складывает числа внутри области для получения нового значения в центре области.

228
00:43:16,890 --> 00:43:29,065
Давайте посмотрим, как с помощью этого алгоритма создаются слои нейронной сети, которые мы видели в статье Зайлера и Фергюса.

229
00:43:29,165 --> 00:43:39,570
Для этого я покажу вам работу человека, который гораздо умнее меня — Отавио Гуда.

230
00:43:39,570 --> 00:43:47,155
Отавио Гуд создал Word Lens — это система распознавания текста, которая сейчас используется в Google Translate,

231
00:43:47,255 --> 00:43:58,080
когда вы наводите камеру телефона на текст на незнакомом языке и поверх изображения показывается перевод.

232
00:43:58,080 --> 00:44:06,385
Отавио разработал эту систему и создал превосходную демонстрацию её работы, сейчас он работает в Google.

233
00:44:06,485 --> 00:44:21,000
Я прокомментирую эту демонстрацию, а потом мы посмотрим на нечто похожее в таблице в Microsoft Excel.

234
00:44:21,500 --> 00:44:27,720
Надеюсь, что принцип работы будет ясен и тем, кто любит видео, и тем, кто любит таблицы.

235
00:44:29,880 --> 00:44:41,610
Эта демонстрация распознавания текста, дальше в курсе мы займёмся распознаванием цифр, задачи очень похожи.

236
00:44:41,610 --> 00:44:51,990
На изображении — буква А, изображение — это матрица чисел.

237
00:44:51,990 --> 00:44:59,035
К этой матрице чисел применяется первый свёрточный фильтр. Предполагается, что все фильтры уже вычислены, модель обучена.

238
00:44:59,135 --> 00:45:05,010
Фильтр чёрный слева и белый справа, это значит, что матрица свёртки выглядит примерно так:

239
00:45:05,010 --> 00:45:10,350
[[-1, 0, 1],
[-1, 0, 1],
[-1, 0, 1]].

240
00:45:13,140 --> 00:45:21,670
Каждая область 3х3 поэлементно умножается на эту матрицу, полученные результаты складываются.

241
00:45:21,770 --> 00:45:30,180
Везде, где чёрное переходит в белое, мы получаем положительные значения, они показаны зелёным,

242
00:45:30,180 --> 00:45:36,475
а там, где белое переходит в чёрное — отрицательные значения, они показаны красным.

243
00:45:36,575 --> 00:45:41,920
Это результат работы первого ядра свёртки.

244
00:45:42,020 --> 00:45:47,020
Вот новое ядро, с белой полосой наверху, а не справа.

245
00:45:47,120 --> 00:46:02,610
Фильтр проходит через каждую область изображения 3x3 и определяет, насколько красным или зелёным получится новый пиксель.

246
00:46:02,610 --> 00:46:15,570
Допустим, у нас было всего два фильтра, видно, что результат отражает вид матриц свёртки.

247
00:46:15,570 --> 00:46:26,520
Полученные результаты пропускаются через выпрямитель (ReLU), который убирает отрицательные значения.

248
00:46:26,520 --> 00:46:30,780
Здесь показан первый входной слой, второй слой — результат работы свёрточных фильтров,

249
00:46:30,780 --> 00:46:36,180
третий слой — результат работы выпрямителя,

250
00:46:38,190 --> 00:46:55,320
четвёртый слой — подвыборка максимумом: каждая область 2х2 заменяется на максимальный элемент этой области, такой алгоритм уменьшения.

251
00:46:55,420 --> 00:47:05,599
После этого процедура повторяется. Новые фильтры свёртки проходят уже оба полученных фильтра с предыдущего слоя,

252
00:47:05,699 --> 00:47:21,190
полученные результаты пропускаются через выпрямитель, получается ещё один слой свёрточной нейронной сети.

253
00:47:21,190 --> 00:47:30,490
Видно, что на первом слое свёртки выделялись горизонтальные или вертикальные края.

254
00:47:33,010 --> 00:47:42,559
Результат работы следующего слоя уже не так очевиден, но принцип его работы такой же.

255
00:47:42,659 --> 00:47:52,180
После этого опять выполняется подвыборка максимумом, каждая область 2x2 заменяется одним числом.

256
00:47:53,799 --> 00:48:07,865
Полученное изображение сравнивается с шаблонами возможных классов, одному из которых оно принадлежит.

257
00:48:07,965 --> 00:48:19,456
Это делается таким же образом — изображение 4x8 поэлементно умножается на шаблон, соответствующий какому-то классу,

258
00:48:19,556 --> 00:48:30,614
результаты складываются и потом конвертируются в вероятность.

259
00:48:31,114 --> 00:48:38,524
Это изображение на 92% совпало с шаблоном класса А, модель считает, что на изображении буква А.

260
00:48:38,624 --> 00:48:46,119
Демонстрация показывает работу уже обученной модели на тестовой выборке,

261
00:48:46,119 --> 00:49:00,484
например, вашей модели или модели, преобученной на изображениях ImageNet.

262
00:49:00,584 --> 00:49:17,855
Ещё раз: на каждом слое сначала работают свёрточные фильтры, потом выпрямитель, потом подвыборка максимумом.

263
00:49:17,955 --> 00:49:29,395
После работы многих слоёв результат сравнивается с шаблонами и получается предсказание.

264
00:49:29,495 --> 00:49:40,420
Как видите, демонстрация очень крутая, я не смог бы такое нарисовать, спасибо Отавио за то, что поделился этим.

265
00:49:40,420 --> 00:49:49,895
Это видео демонстрирует работу реальной свёрточной нейронной сети, Отавио написал для этого специальную программу.

266
00:49:49,995 --> 00:49:58,060
Я человек простой и предпочитаю таблицы в Excel.

267
00:49:58,060 --> 00:50:08,950
Эта таблица есть в репозитории fast.ai на GitHub, можете клонировать весь репозиторий или скачать её отдельно,

268
00:50:08,950 --> 00:50:36,880
она доступна по адресу github.com/fastai/fastai/tree/master/courses/dl1/excel/conv-example.xlsx.

269
00:50:36,880 --> 00:50:55,290
В качестве входных данных я взял изображение цифры 7 из базы данных MNIST, мы с ней ещё будем работать.

270
00:50:55,290 --> 00:51:09,640
Каждая ячейка представляет чёрно-белый пиксель, число от 0 до 1. Иногда используются числа от 0 до 255,

271
00:51:13,060 --> 00:51:25,900
это не важно, в PyTorch всё конвертируется в действительные числа от 0 до 1.

272
00:51:25,900 --> 00:51:47,299
Я использовал условное форматирование и сделал высокие значения красными, видно, что здесь изображена цифра 7.

273
00:51:47,399 --> 00:51:55,249
В демонстрации Отавио в первом слое использовались два свёрточных фильтра.

274
00:51:55,349 --> 00:52:05,170
Я создал фильтр, который выделяет верхние границы изображения, матрица свёртки выглядит так:

275
00:52:05,170 --> 00:52:10,119
[[1, 1, 1],
[0, 0, 0],
[-1, -1, -1]].

276
00:52:10,119 --> 00:52:16,630
Давайте выберем один пиксель и посмотрим, что происходит.

277
00:52:16,630 --> 00:52:24,112
Область изображения 3x3 поэлементно умножается на матрицу свёртки.

278
00:52:24,212 --> 00:52:44,134
В верхнем ряду все единицы, в нижнем почти все нули, поэтому итоговое значение получается высоким.

279
00:52:44,234 --> 00:52:54,670
Если сдвинуться на два пикселя вниз, в области уже почти нет ненулевых значений, в итоге ноль.

280
00:52:54,670 --> 00:53:08,859
Более интересный пример: здесь высокие значения как в верхнем ряду, так и в нижнем, в сумме тоже ноль.

281
00:53:08,859 --> 00:53:15,169
Как видно, такой фильтр активирует только горизонтальные края.

282
00:53:15,669 --> 00:53:49,070
Это число 3 называется активацией. Активация — число, полученное после выполнения линейной операции над изображением.

283
00:53:49,170 --> 00:54:03,095
В моей формуле есть и свёртка, и выпрямитель. Выпрямитель отбрасывает отрицательные значения,

284
00:54:03,195 --> 00:54:32,920
это записывается формулой y = MAX(0, x). Выглядит слишком просто, но это так и есть, здесь я ничего не упрощаю.

285
00:54:32,920 --> 00:54:50,490
Когда я упрощаю что-то, я обязательно говорю, что это упрощение, но выпрямитель и свёртка действительно работают очень просто.

286
00:54:50,490 --> 00:55:03,560
На экране сейчас полностью воплощён один слой свёрточной нейронной сети.

287
00:55:03,560 --> 00:55:09,290
Этот свёрточный фильтр выделяет горизонтальные границы.

288
00:55:09,290 --> 00:55:24,660
Опять же, подразумевается, что модель обучили и в процессе обучения появились эти фильтры.

289
00:55:24,760 --> 00:55:31,890
Вот второй фильтр того же слоя, в матрице другие числа.

290
00:55:31,990 --> 00:55:54,230
PyTorch не хранит фильтры как отдельные матрицы 3x3, он хранит их в виде тензора. Тензор — это многомерная матрица.

291
00:55:54,230 --> 00:56:03,495
Фильтры хранятся в виде тензора, что позволяет создавать из них слои.

292
00:56:03,595 --> 00:56:19,700
Понятия свёрточный фильтр и свёрточное ядро взаимозаменяемы — они означают одну из матриц 3x3, одну из частей трёхмерного тензора.

293
00:56:19,700 --> 00:56:35,295
Как видно, этот фильтр находит вертикальные границы изображения.

294
00:56:35,395 --> 00:56:42,030
Два свёрточных фильтра с двумя выпрямителями образуют слой свёрточной нейронной сети.

295
00:56:42,130 --> 00:56:48,680
Этот слой — скрытый, так называются все слои, кроме входного и выходного.

296
00:56:50,810 --> 00:57:05,974
Размер этого слоя — 2, потому что он содержит два свёрточных фильтра.

297
00:57:06,074 --> 00:57:13,729
Переходим к следующему слою.

298
00:57:13,829 --> 00:57:34,540
Он устроен сложнее, потому что на вход теперь подаются оба изображения с предыдущего слоя, поэтому здесь два фильтра.

299
00:57:34,540 --> 00:57:53,464
PyTorch хранит эти две матрицы в одном тензоре 2x3x3, поэтому стоит думать о них, как об одном фильтре.

300
00:57:53,564 --> 00:58:14,264
Для получения активации складываются результаты от двух матриц 3x3.

301
00:58:14,364 --> 00:58:22,420
Верхнее изображение умножается на одну часть фильтра, нижнее — на другую.

302
00:58:22,420 --> 00:58:35,530
Со временем вам придётся привыкнуть к многомерным линейным пространствам.

303
00:58:35,530 --> 00:58:44,855
Я нарисовал свёрточные фильтры один под другим, но на самом деле они как бы наложены друг на друга.

304
00:58:44,955 --> 00:58:50,600
Джеффри Хинтон в своём курсе «Нейронные сети для машинного обучения» на Coursera в 2012 году рассказал,

305
00:58:50,700 --> 00:58:58,990
как все специалисты по анализу данных представляют себе многомерные пространства.

306
00:58:58,990 --> 00:59:06,390
Они представляют двумерное пространство, а потом очень быстро произносят: «Двенадцатимерное пространство!» и всё получается.

307
00:59:06,390 --> 00:59:19,550
Мы дошли до второго слоя, вам придётся просто поверить, что все остальные устроены так же,

308
00:59:19,550 --> 00:59:38,900
потому что Excel не поддерживает трёхмерные матрицы. Если бы поддерживал, эту операцию я бы провёл одним умножением, без суммирования.

309
00:59:38,900 --> 00:59:44,720
Опять же, после свёртки я использую выпрямитель, он же ReLU.

310
00:59:48,710 --> 01:00:02,540
Архитектура нашей нейронной сети такова:

311
01:00:02,540 --> 01:00:15,250
на первом слое 2 свёрточных фильтра 3x3, вот первый и второй,

312
01:00:16,150 --> 01:00:31,895
на втором слое 2 свёрточных фильтра 2x3x3, вот первый и второй.

313
01:00:31,995 --> 01:00:52,940
Все числа в больших таблицах — активации, эта активация вычислена по двум областям 3x3 с помощью фильтра 2x3x3.

314
01:00:52,940 --> 01:00:57,830
Обычно слои свёрточной нейронной сети как-то называют.

315
01:00:57,830 --> 01:01:10,650
Первый слой мы назовём Conv1, второй — Conv2.

316
01:01:10,750 --> 01:01:21,990
Названия слоёв у различных архитектур выводятся в их описании.

317
01:01:22,090 --> 01:01:36,520
Следующая часть архитектуры после слоёв — подвыборка максимумом, этот слой мы назовём Maxpool.

318
01:01:36,520 --> 01:01:43,569
Подвыборку максимумом сложно показать в Excel, но я старался.

319
01:01:43,569 --> 01:01:53,219
При подвыборке максимумом высота и ширина изображения уменьшаются вдвое.

320
01:01:53,319 --> 01:01:59,909
Из каждых четырёх чисел в области 2x2 выбирается максимальное.

321
01:02:00,009 --> 01:02:06,780
Так как изображение уменьшится в два раза, я заполняю только половину ячеек.

322
01:02:06,780 --> 01:02:19,030
Изображение получается похожим, но в два раза меньше по обоим измерениям.

323
01:02:19,030 --> 01:02:24,160
При этом рассматриваются не все возможные области 2x2, изображение как бы разрезается на эти области —

324
01:02:26,319 --> 01:02:38,050
одна область начинается в столбце BQ, а следующая — в столбце BS, они не накладываются друг на друга, поэтому изображение уменьшается.

325
01:02:38,050 --> 01:02:47,525
Если кто-то из вас любит таблицы, можете изучить внимательнее.

326
01:02:47,625 --> 01:02:55,084
После подвыборки максимумом возможны различные варианты развития архитектуры.

327
01:02:55,184 --> 01:03:00,454
Я покажу классический подход, который сейчас уже слегка устарел.

328
01:03:00,554 --> 01:03:07,490
В старых архитектурах и архитектурах для работы со структурированными данными

329
01:03:07,590 --> 01:03:14,810
вместо подвыборки максимумом использовались полносвязные слои.

330
01:03:14,910 --> 01:03:43,094
В полносвязных слоях каждая активация умножается на соответствующий ей вес и результаты складываются.

331
01:03:43,194 --> 01:03:49,490
В отличие от свёрточного слоя, здесь рассматривается всё изображение за раз, а не области 3x3,

332
01:03:51,980 --> 01:04:03,290
матрица весов по размеру совпадает с изображением.

333
01:04:03,290 --> 01:04:17,744
У архитектур с полносвязными слоями очень много весов, поэтому они медленно работают и легко переобучаются.

334
01:04:17,844 --> 01:04:28,465
Архитектура VGG-Net была первой успешной глубокой архитектурой, она содержит до 19 слоёв.

335
01:04:28,565 --> 01:04:42,930
VGG содержит полносвязный слой с 4096 активациями, связанный со скрытым слоем с 4096 активациями.

336
01:04:43,030 --> 01:04:53,180
Это уже 4096x4096x(количество свёрточных ядер слоя) весов.

337
01:04:53,180 --> 01:05:09,380
Суммарно VGG содержит около 300 миллионов весов, из которых 250 миллионов — веса полносвязных слоёв.

338
01:05:09,380 --> 01:05:13,700
Дальше в курсе мы узнаем про то, как избегать полносвязные слои при построении архитектуры.

339
01:05:15,470 --> 01:05:23,004
Все используемые нами архитектуры — ResNet и ResNeXt — не содержат больших полносвязных слоёв.

340
01:05:23,104 --> 01:05:40,280
Янет: Как выглядят фильтры для изображений с тремя цветовыми каналами?

341
01:05:40,280 --> 01:05:52,160
Если бы у нашего изображения было три цветовых канала, входной слой выглядел бы, как слой Conv1.

342
01:05:52,160 --> 01:06:00,164
В Conv1 два канала, поэтому фильтры во втором слое состоят из двух каналов.

343
01:06:00,264 --> 01:06:11,749
Если у входного изображения несколько каналов, фильтры первого слоя будут выглядеть так, как в нашем примере выглядят фильтры второго слоя.

344
01:06:11,749 --> 01:06:17,779
У полноцветных изображений три цветовых канала — красный, зелёный и синий, иногда есть альфа-канал.

345
01:06:17,779 --> 01:06:23,059
Сколько у изображения каналов, столько и будет матриц во входном слое.

346
01:06:23,059 --> 01:06:30,764
Я знаю, что Янет сейчас использует модель, обученную на полноцветных изображениях ImageNet,

347
01:06:30,864 --> 01:06:35,124
для определения костного возраста по рентгеновским снимкам, у которых только один канал.

348
01:06:35,224 --> 01:06:51,989
Для этого она дважды продублировала единственный канал снимков, чтобы создать «полноцветное» изображение.

349
01:06:52,089 --> 01:06:59,630
Получается, что при обучении модель получает избыточную информацию, так как все каналы одинаковые,

350
01:06:59,630 --> 01:07:08,640
зато так работают предобученные фильтры для полноцветных изображений.

351
01:07:08,740 --> 01:07:17,660
Сейчас на Kaggle есть соревнование по распознаванию айсбергов на спутниковых двухканальных снимках,

352
01:07:17,660 --> 01:07:30,029
в этом случае можно продублировать один из каналов или создать новый канал как среднее от двух имеющихся.

353
01:07:30,129 --> 01:07:36,794
Это не идеальное решение, но оно позволяет использовать предобученные нейронные сети.

354
01:07:36,894 --> 01:07:48,410
Однажды я использовал обученную на трёх каналах модель для работы с четырёхканальными изображениями.

355
01:07:48,410 --> 01:07:53,029
Это были спутниковые снимки, где четвёртый канал был в ближнем инфракрасном диапазоне.

356
01:07:53,029 --> 01:08:08,545
Для этого перед обучением я добавил четвёртый уровень из нулей в каждый свёрточный фильтр.

357
01:08:08,645 --> 01:08:21,500
На следующей лекции вы увидите, что при обучении модели с нуля вместо  преобученных фильтров используются матрицы случайных чисел,

358
01:08:21,600 --> 01:08:33,070
на которых потом применяется стохастический градиентный спуск с перезапуском, который улучшает эти случайные числа.

359
01:08:35,350 --> 01:08:44,985
Давайте сделаем перерыв на 7 минут и продолжим в 7:50.

360
01:08:45,085 --> 01:08:50,310


361
01:08:50,310 --> 01:09:00,339


362
01:09:02,290 --> 01:09:07,180


363
01:09:07,180 --> 01:09:11,770


364
01:09:11,770 --> 01:09:17,920


365
01:09:17,920 --> 01:09:23,970


366
01:09:23,970 --> 01:09:36,460


367
01:09:36,460 --> 01:09:44,740


368
01:09:44,740 --> 01:09:50,370


369
01:09:50,370 --> 01:09:57,130


370
01:09:57,130 --> 01:10:04,030


371
01:10:04,030 --> 01:10:09,790


372
01:10:09,790 --> 01:10:14,680


373
01:10:14,680 --> 01:10:19,810


374
01:10:19,810 --> 01:10:23,150


375
01:10:27,110 --> 01:10:40,190


376
01:10:40,190 --> 01:10:48,190


377
01:10:48,190 --> 01:10:56,539


378
01:10:56,539 --> 01:11:02,030


379
01:11:02,030 --> 01:11:06,199


380
01:11:06,199 --> 01:11:10,820


381
01:11:10,820 --> 01:11:16,989


382
01:11:16,989 --> 01:11:23,150


383
01:11:23,150 --> 01:11:32,300


384
01:11:32,300 --> 01:11:37,039


385
01:11:37,039 --> 01:11:40,340


386
01:11:40,340 --> 01:11:44,479


387
01:11:44,479 --> 01:11:48,249


388
01:11:50,510 --> 01:11:55,969


389
01:11:55,969 --> 01:12:01,400


390
01:12:01,400 --> 01:12:07,449


391
01:12:07,449 --> 01:12:16,340


392
01:12:16,340 --> 01:12:23,630


393
01:12:23,630 --> 01:12:29,780


394
01:12:29,780 --> 01:12:32,920


395
01:12:33,070 --> 01:12:39,260


396
01:12:39,260 --> 01:12:44,230


397
01:12:45,590 --> 01:12:55,230


398
01:12:58,619 --> 01:13:04,500


399
01:13:04,500 --> 01:13:09,840


400
01:13:09,840 --> 01:13:13,340


401
01:13:13,829 --> 01:13:18,210


402
01:13:18,210 --> 01:13:22,139


403
01:13:22,139 --> 01:13:29,179


404
01:13:29,179 --> 01:13:34,769


405
01:13:34,769 --> 01:13:39,599


406
01:13:39,599 --> 01:13:45,570


407
01:13:45,570 --> 01:13:51,269


408
01:13:51,269 --> 01:13:54,749


409
01:13:54,749 --> 01:14:00,239


410
01:14:00,239 --> 01:14:04,979


411
01:14:04,979 --> 01:14:10,320


412
01:14:12,300 --> 01:14:19,289


413
01:14:19,289 --> 01:14:24,869


414
01:14:24,869 --> 01:14:29,550


415
01:14:29,550 --> 01:14:35,729


416
01:14:35,729 --> 01:14:43,289


417
01:14:46,139 --> 01:14:53,489


418
01:14:54,960 --> 01:14:59,940


419
01:14:59,940 --> 01:15:06,090


420
01:15:06,090 --> 01:15:10,170


421
01:15:10,170 --> 01:15:16,199


422
01:15:18,630 --> 01:15:23,280


423
01:15:23,280 --> 01:15:26,670


424
01:15:26,670 --> 01:15:29,610


425
01:15:29,610 --> 01:15:37,470


426
01:15:37,470 --> 01:15:41,760


427
01:15:41,760 --> 01:15:46,500


428
01:15:46,500 --> 01:15:51,420


429
01:15:51,420 --> 01:15:58,650


430
01:15:58,650 --> 01:16:03,450


431
01:16:03,450 --> 01:16:08,670


432
01:16:08,670 --> 01:16:19,530


433
01:16:19,530 --> 01:16:33,090


434
01:16:33,090 --> 01:16:37,260


435
01:16:37,260 --> 01:16:41,010


436
01:16:41,010 --> 01:16:45,360


437
01:16:50,820 --> 01:16:57,480


438
01:16:57,480 --> 01:17:03,390


439
01:17:03,390 --> 01:17:14,370


440
01:17:14,370 --> 01:17:21,450


441
01:17:21,450 --> 01:17:25,140


442
01:17:25,140 --> 01:17:31,650


443
01:17:33,780 --> 01:17:38,260


444
01:17:38,260 --> 01:17:44,590


445
01:17:44,590 --> 01:17:49,450


446
01:17:49,450 --> 01:17:52,630


447
01:17:52,630 --> 01:17:58,210


448
01:17:58,210 --> 01:18:02,710


449
01:18:02,710 --> 01:18:05,320


450
01:18:05,320 --> 01:18:10,480


451
01:18:10,480 --> 01:18:15,850


452
01:18:15,850 --> 01:18:28,120


453
01:18:32,340 --> 01:18:37,830


454
01:18:37,830 --> 01:18:43,860


455
01:18:43,860 --> 01:18:51,460


456
01:18:51,460 --> 01:18:56,890


457
01:18:56,890 --> 01:19:04,840


458
01:19:04,840 --> 01:19:11,050


459
01:19:11,050 --> 01:19:16,510


460
01:19:16,510 --> 01:19:20,739


461
01:19:23,110 --> 01:19:28,420


462
01:19:28,420 --> 01:19:33,100


463
01:19:33,100 --> 01:19:39,190


464
01:19:41,140 --> 01:19:47,140


465
01:19:47,140 --> 01:19:53,680


466
01:19:53,680 --> 01:19:57,700


467
01:20:00,100 --> 01:20:07,510


468
01:20:07,510 --> 01:20:12,610


469
01:20:14,980 --> 01:20:22,600


470
01:20:22,600 --> 01:20:31,180


471
01:20:31,180 --> 01:20:34,780


472
01:20:37,600 --> 01:20:43,230


473
01:20:45,419 --> 01:20:48,840


474
01:20:48,840 --> 01:20:53,010


475
01:20:53,010 --> 01:20:57,119


476
01:21:00,419 --> 01:21:08,189


477
01:21:08,189 --> 01:21:13,229


478
01:21:13,229 --> 01:21:19,769


479
01:21:19,769 --> 01:21:25,559


480
01:21:25,559 --> 01:21:30,389


481
01:21:30,389 --> 01:21:34,260


482
01:21:34,260 --> 01:21:39,719


483
01:21:39,719 --> 01:21:44,880


484
01:21:44,880 --> 01:21:50,999


485
01:21:50,999 --> 01:21:56,969


486
01:21:56,969 --> 01:22:02,550


487
01:22:02,550 --> 01:22:09,840


488
01:22:09,840 --> 01:22:15,689


489
01:22:15,689 --> 01:22:21,749


490
01:22:23,610 --> 01:22:28,079


491
01:22:28,079 --> 01:22:34,559


492
01:22:34,559 --> 01:22:39,419


493
01:22:39,419 --> 01:22:46,229


494
01:22:46,229 --> 01:22:49,590


495
01:22:49,590 --> 01:22:55,249


496
01:22:55,249 --> 01:23:00,550


497
01:23:00,550 --> 01:23:05,590


498
01:23:05,590 --> 01:23:08,560


499
01:23:08,560 --> 01:23:15,940


500
01:23:21,880 --> 01:23:25,600


501
01:23:25,600 --> 01:23:29,770


502
01:23:29,770 --> 01:23:40,690


503
01:23:43,150 --> 01:23:48,370


504
01:23:48,370 --> 01:23:55,180


505
01:23:55,180 --> 01:24:04,050


506
01:24:04,050 --> 01:24:12,160


507
01:24:12,160 --> 01:24:16,420


508
01:24:16,420 --> 01:24:21,610


509
01:24:21,610 --> 01:24:27,220


510
01:24:27,220 --> 01:24:29,800


511
01:24:29,800 --> 01:24:35,140


512
01:24:35,140 --> 01:24:39,670


513
01:24:39,670 --> 01:24:45,070


514
01:24:45,070 --> 01:24:50,620


515
01:24:50,620 --> 01:24:55,630


516
01:24:55,630 --> 01:25:01,690


517
01:25:05,670 --> 01:25:11,130


518
01:25:11,130 --> 01:25:16,290


519
01:25:16,290 --> 01:25:23,340


520
01:25:23,340 --> 01:25:28,440


521
01:25:32,429 --> 01:25:37,650


522
01:25:37,650 --> 01:25:43,230


523
01:25:43,230 --> 01:25:48,360


524
01:25:48,360 --> 01:25:53,310


525
01:25:53,310 --> 01:25:58,080


526
01:26:00,300 --> 01:26:04,650


527
01:26:08,429 --> 01:26:12,900


528
01:26:12,900 --> 01:26:20,219


529
01:26:20,219 --> 01:26:25,560


530
01:26:25,560 --> 01:26:30,480


531
01:26:32,159 --> 01:26:37,260


532
01:26:37,260 --> 01:26:42,719


533
01:26:42,719 --> 01:26:47,880


534
01:26:47,880 --> 01:26:51,989


535
01:26:54,480 --> 01:26:57,480


536
01:26:57,480 --> 01:27:02,550


537
01:27:02,550 --> 01:27:07,350


538
01:27:07,350 --> 01:27:13,290


539
01:27:13,290 --> 01:27:18,800


540
01:27:18,800 --> 01:27:23,070


541
01:27:24,829 --> 01:27:31,489


542
01:27:31,489 --> 01:27:38,329


543
01:27:38,329 --> 01:27:42,349


544
01:27:42,349 --> 01:27:49,880


545
01:27:49,880 --> 01:27:53,960


546
01:27:53,960 --> 01:28:00,559


547
01:28:00,559 --> 01:28:05,690


548
01:28:08,090 --> 01:28:15,619


549
01:28:17,780 --> 01:28:20,960


550
01:28:20,960 --> 01:28:25,360


551
01:28:25,360 --> 01:28:34,099


552
01:28:34,099 --> 01:28:40,239


553
01:28:41,570 --> 01:28:47,840


554
01:28:47,840 --> 01:28:52,099


555
01:28:52,099 --> 01:28:57,710


556
01:28:57,710 --> 01:29:07,040


557
01:29:07,040 --> 01:29:15,829


558
01:29:15,829 --> 01:29:21,559


559
01:29:21,559 --> 01:29:25,489


560
01:29:27,440 --> 01:29:31,190


561
01:29:31,190 --> 01:29:36,790


562
01:29:36,790 --> 01:29:42,599


563
01:29:42,599 --> 01:29:51,869


564
01:29:53,219 --> 01:30:01,080


565
01:30:01,080 --> 01:30:07,230


566
01:30:07,230 --> 01:30:12,599


567
01:30:12,599 --> 01:30:18,869


568
01:30:22,940 --> 01:30:29,699


569
01:30:29,699 --> 01:30:34,139


570
01:30:34,139 --> 01:30:39,119


571
01:30:39,119 --> 01:30:44,489


572
01:30:44,489 --> 01:30:50,040


573
01:30:50,040 --> 01:30:56,940


574
01:30:56,940 --> 01:31:03,540


575
01:31:03,540 --> 01:31:08,670


576
01:31:08,670 --> 01:31:12,179


577
01:31:12,179 --> 01:31:16,110


578
01:31:16,110 --> 01:31:21,320


579
01:31:21,680 --> 01:31:28,250


580
01:31:28,250 --> 01:31:36,530


581
01:31:36,530 --> 01:31:40,700


582
01:31:40,700 --> 01:31:48,710


583
01:31:48,710 --> 01:31:56,420


584
01:31:56,420 --> 01:32:01,160


585
01:32:01,160 --> 01:32:04,850


586
01:32:04,850 --> 01:32:11,680


587
01:32:11,680 --> 01:32:17,750


588
01:32:17,750 --> 01:32:23,270


589
01:32:23,270 --> 01:32:27,860


590
01:32:30,050 --> 01:32:34,160


591
01:32:34,160 --> 01:32:40,040


592
01:32:40,040 --> 01:32:45,350


593
01:32:45,350 --> 01:32:51,080


594
01:32:51,080 --> 01:32:59,000


595
01:32:59,000 --> 01:33:07,940


596
01:33:07,940 --> 01:33:24,200


597
01:33:24,200 --> 01:33:29,670


598
01:33:29,670 --> 01:33:33,110


599
01:33:35,450 --> 01:33:44,250


600
01:33:44,250 --> 01:33:49,650


601
01:33:49,650 --> 01:33:56,070


602
01:33:56,070 --> 01:34:02,970


603
01:34:02,970 --> 01:34:08,670


604
01:34:08,670 --> 01:34:12,930


605
01:34:12,930 --> 01:34:15,840


606
01:34:15,840 --> 01:34:19,710


607
01:34:19,710 --> 01:34:22,830


608
01:34:22,830 --> 01:34:27,990


609
01:34:27,990 --> 01:34:33,300


610
01:34:33,300 --> 01:34:41,010


611
01:34:41,010 --> 01:34:46,350


612
01:34:46,350 --> 01:34:52,170


613
01:34:52,170 --> 01:34:56,370


614
01:34:56,370 --> 01:35:02,580


615
01:35:02,580 --> 01:35:07,770


616
01:35:07,770 --> 01:35:14,130


617
01:35:14,130 --> 01:35:18,530


618
01:35:18,530 --> 01:35:25,650


619
01:35:25,650 --> 01:35:32,690


620
01:35:32,690 --> 01:35:37,170


621
01:35:37,170 --> 01:35:44,910


622
01:35:44,910 --> 01:35:48,270


623
01:35:48,270 --> 01:35:52,620


624
01:35:54,360 --> 01:36:00,060


625
01:36:00,060 --> 01:36:04,980


626
01:36:07,440 --> 01:36:12,000


627
01:36:12,000 --> 01:36:17,760


628
01:36:17,760 --> 01:36:23,480


629
01:36:25,920 --> 01:36:31,260


630
01:36:31,260 --> 01:36:39,870


631
01:36:39,870 --> 01:36:44,460


632
01:36:44,460 --> 01:36:49,890


633
01:36:49,890 --> 01:36:57,530


634
01:37:00,210 --> 01:37:04,920


635
01:37:04,920 --> 01:37:13,410


636
01:37:13,410 --> 01:37:17,280


637
01:37:17,280 --> 01:37:25,920


638
01:37:25,920 --> 01:37:30,390


639
01:37:30,390 --> 01:37:38,090


640
01:37:38,090 --> 01:37:44,190


641
01:37:47,190 --> 01:37:52,410


642
01:37:52,410 --> 01:37:58,140


643
01:37:58,140 --> 01:38:04,620


644
01:38:04,620 --> 01:38:09,120


645
01:38:09,120 --> 01:38:14,820


646
01:38:14,820 --> 01:38:21,840


647
01:38:21,840 --> 01:38:25,950


648
01:38:25,950 --> 01:38:30,090


649
01:38:30,090 --> 01:38:35,300


650
01:38:35,300 --> 01:38:39,440


651
01:38:42,150 --> 01:38:51,140


652
01:38:51,200 --> 01:38:59,160


653
01:38:59,160 --> 01:39:07,650


654
01:39:07,650 --> 01:39:12,810


655
01:39:12,810 --> 01:39:17,130


656
01:39:17,130 --> 01:39:20,300


657
01:39:21,510 --> 01:39:25,710


658
01:39:25,710 --> 01:39:29,699


659
01:39:29,699 --> 01:39:35,099


660
01:39:35,099 --> 01:39:41,659


661
01:39:45,989 --> 01:39:51,300


662
01:39:51,300 --> 01:39:57,150


663
01:40:01,320 --> 01:40:08,400


664
01:40:08,400 --> 01:40:14,070


665
01:40:14,070 --> 01:40:19,079


666
01:40:19,079 --> 01:40:23,280


667
01:40:23,280 --> 01:40:27,300


668
01:40:27,300 --> 01:40:34,409


669
01:40:36,809 --> 01:40:40,440


670
01:40:44,219 --> 01:40:48,389


671
01:40:48,389 --> 01:40:53,880


672
01:40:53,880 --> 01:41:05,119


673
01:41:05,119 --> 01:41:13,980


674
01:41:13,980 --> 01:41:19,170


675
01:41:19,170 --> 01:41:21,840


676
01:41:21,840 --> 01:41:24,900


677
01:41:26,880 --> 01:41:32,570


678
01:41:33,980 --> 01:41:39,400


679
01:41:39,400 --> 01:41:47,090


680
01:41:47,090 --> 01:41:51,140


681
01:41:51,140 --> 01:41:54,260


682
01:41:54,260 --> 01:41:59,390


683
01:41:59,390 --> 01:42:04,370


684
01:42:04,370 --> 01:42:11,540


685
01:42:11,540 --> 01:42:15,140


686
01:42:15,140 --> 01:42:19,700


687
01:42:21,739 --> 01:42:28,730


688
01:42:28,730 --> 01:42:33,110


689
01:42:33,110 --> 01:42:38,120


690
01:42:38,120 --> 01:42:47,270


691
01:42:47,270 --> 01:42:55,540


692
01:42:57,320 --> 01:43:08,690


693
01:43:08,690 --> 01:43:13,400


694
01:43:13,400 --> 01:43:19,340


695
01:43:19,340 --> 01:43:25,970


696
01:43:25,970 --> 01:43:30,530


697
01:43:33,380 --> 01:43:38,930


698
01:43:38,930 --> 01:43:44,290


699
01:43:46,710 --> 01:43:54,490


700
01:43:54,490 --> 01:44:00,580


701
01:44:00,580 --> 01:44:06,970


702
01:44:06,970 --> 01:44:15,940


703
01:44:18,520 --> 01:44:26,470


704
01:44:26,470 --> 01:44:32,890


705
01:44:32,890 --> 01:44:38,140


706
01:44:38,140 --> 01:44:47,080


707
01:44:47,080 --> 01:44:52,180


708
01:44:52,180 --> 01:44:58,390


709
01:44:58,390 --> 01:45:05,350


710
01:45:05,350 --> 01:45:09,100


711
01:45:09,100 --> 01:45:13,510


712
01:45:13,510 --> 01:45:19,690


713
01:45:23,650 --> 01:45:28,690


714
01:45:28,690 --> 01:45:34,210


715
01:45:34,210 --> 01:45:40,870


716
01:45:40,870 --> 01:45:48,240


717
01:45:48,240 --> 01:45:55,170


718
01:45:55,170 --> 01:46:05,119


719
01:46:05,119 --> 01:46:15,439


720
01:46:15,439 --> 01:46:21,229


721
01:46:21,229 --> 01:46:26,300


722
01:46:26,300 --> 01:46:34,570


723
01:46:36,050 --> 01:46:44,560


724
01:46:45,869 --> 01:46:53,440


725
01:46:53,440 --> 01:47:01,960


726
01:47:01,960 --> 01:47:05,440


727
01:47:05,440 --> 01:47:08,949


728
01:47:08,949 --> 01:47:15,880


729
01:47:15,880 --> 01:47:19,869


730
01:47:19,869 --> 01:47:22,659


731
01:47:22,659 --> 01:47:34,059


732
01:47:34,059 --> 01:47:39,659


733
01:47:42,989 --> 01:47:50,920


734
01:47:50,920 --> 01:47:55,960


735
01:47:55,960 --> 01:48:01,599


736
01:48:01,599 --> 01:48:07,119


737
01:48:10,840 --> 01:48:16,210


738
01:48:16,210 --> 01:48:23,769


739
01:48:23,769 --> 01:48:27,519


740
01:48:27,519 --> 01:48:33,820


741
01:48:36,190 --> 01:48:42,969


742
01:48:42,969 --> 01:48:50,309


743
01:48:50,309 --> 01:48:56,920


744
01:48:56,920 --> 01:49:02,530


745
01:49:02,530 --> 01:49:08,380


746
01:49:08,380 --> 01:49:16,830


747
01:49:16,830 --> 01:49:22,960


748
01:49:22,960 --> 01:49:28,270


749
01:49:28,270 --> 01:49:34,690


750
01:49:37,420 --> 01:49:42,730


751
01:49:45,460 --> 01:49:52,150


752
01:49:52,150 --> 01:50:00,219


753
01:50:00,219 --> 01:50:03,989


754
01:50:07,300 --> 01:50:13,960


755
01:50:13,960 --> 01:50:18,250


756
01:50:18,250 --> 01:50:22,449


757
01:50:22,449 --> 01:50:28,179


758
01:50:28,179 --> 01:50:34,960


759
01:50:34,960 --> 01:50:40,270


760
01:50:40,270 --> 01:50:48,190


761
01:50:49,719 --> 01:50:53,890


762
01:50:53,890 --> 01:50:57,610


763
01:51:00,910 --> 01:51:05,290


764
01:51:05,290 --> 01:51:09,190


765
01:51:09,190 --> 01:51:13,250


766
01:51:13,250 --> 01:51:19,969


767
01:51:19,969 --> 01:51:24,050


768
01:51:24,050 --> 01:51:28,840


769
01:51:28,840 --> 01:51:34,369


770
01:51:35,809 --> 01:51:41,900


771
01:51:46,909 --> 01:51:54,349


772
01:51:54,349 --> 01:52:02,869


773
01:52:09,619 --> 01:52:19,699


774
01:52:19,699 --> 01:52:24,320


775
01:52:24,320 --> 01:52:29,750


776
01:52:29,750 --> 01:52:34,730


777
01:52:34,730 --> 01:52:41,329


778
01:52:41,329 --> 01:52:49,250


779
01:52:49,250 --> 01:52:52,670


780
01:52:52,670 --> 01:52:58,610


781
01:52:58,610 --> 01:53:03,559


782
01:53:03,559 --> 01:53:13,489


783
01:53:18,019 --> 01:53:24,070


784
01:53:27,010 --> 01:53:33,099


785
01:53:33,099 --> 01:53:40,539


786
01:53:40,539 --> 01:53:46,780


787
01:53:46,780 --> 01:53:50,170


788
01:53:50,170 --> 01:53:54,070


789
01:53:54,070 --> 01:53:59,289


790
01:53:59,289 --> 01:54:03,880


791
01:54:03,880 --> 01:54:08,860


792
01:54:08,860 --> 01:54:17,499


793
01:54:17,499 --> 01:54:23,230


794
01:54:23,230 --> 01:54:27,039


795
01:54:27,039 --> 01:54:33,429


796
01:54:33,429 --> 01:54:39,249


797
01:54:39,249 --> 01:54:47,079


798
01:54:47,079 --> 01:54:51,280


799
01:54:51,280 --> 01:54:54,909


800
01:54:54,909 --> 01:55:04,030


801
01:55:04,030 --> 01:55:08,409


802
01:55:08,409 --> 01:55:14,949


803
01:55:14,949 --> 01:55:19,389


804
01:55:19,389 --> 01:55:22,659


805
01:55:24,579 --> 01:55:28,150


806
01:55:28,150 --> 01:55:31,230


807
01:55:35,349 --> 01:55:40,729


808
01:55:40,729 --> 01:55:46,550


809
01:55:46,550 --> 01:55:50,689


810
01:55:50,689 --> 01:55:55,579


811
01:55:57,889 --> 01:56:03,679


812
01:56:03,679 --> 01:56:10,219


813
01:56:10,219 --> 01:56:14,929


814
01:56:14,929 --> 01:56:19,669


815
01:56:19,669 --> 01:56:24,019


816
01:56:24,019 --> 01:56:26,630


817
01:56:26,630 --> 01:56:30,469


818
01:56:30,469 --> 01:56:33,860


819
01:56:33,860 --> 01:56:38,869


820
01:56:38,869 --> 01:56:43,999


821
01:56:43,999 --> 01:56:54,229


822
01:56:54,229 --> 01:57:02,479


823
01:57:02,479 --> 01:57:09,590


824
01:57:09,590 --> 01:57:14,419


825
01:57:14,419 --> 01:57:21,919


826
01:57:21,919 --> 01:57:27,110


827
01:57:27,110 --> 01:57:33,260


828
01:57:33,260 --> 01:57:38,449


829
01:57:41,869 --> 01:57:46,820


830
01:57:46,820 --> 01:57:50,900


831
01:57:50,900 --> 01:57:56,260


832
01:57:56,260 --> 01:58:04,280


833
01:58:07,580 --> 01:58:13,130


834
01:58:13,130 --> 01:58:18,290


835
01:58:18,290 --> 01:58:23,660


836
01:58:23,660 --> 01:58:29,200


837
01:58:29,200 --> 01:58:35,240


838
01:58:35,240 --> 01:58:39,200


839
01:58:39,200 --> 01:58:47,870


840
01:58:47,870 --> 01:58:54,080


841
01:58:54,080 --> 01:59:00,770


842
01:59:00,770 --> 01:59:06,260


843
01:59:06,260 --> 01:59:12,650


844
01:59:14,030 --> 01:59:18,260


845
01:59:18,260 --> 01:59:22,910


846
01:59:22,910 --> 01:59:26,450


847
01:59:26,450 --> 01:59:30,560


848
01:59:30,560 --> 01:59:35,530


849
01:59:38,250 --> 01:59:44,440


850
01:59:44,440 --> 01:59:48,160


851
01:59:48,160 --> 01:59:52,690


852
01:59:52,690 --> 02:00:02,500


853
02:00:02,500 --> 02:00:10,300


854
02:00:10,300 --> 02:00:16,600


855
02:00:16,600 --> 02:00:21,850


856
02:00:21,850 --> 02:00:30,130


857
02:00:30,130 --> 02:00:37,199


858
02:00:39,960 --> 02:00:45,520


859
02:00:45,520 --> 02:00:49,449


860
02:00:51,550 --> 02:00:57,940


861
02:01:00,480 --> 02:01:05,489


862
02:01:05,489 --> 02:01:11,770


863
02:01:11,770 --> 02:01:16,210


864
02:01:16,210 --> 02:01:21,840


865
02:01:21,840 --> 02:01:31,199


866
02:01:34,810 --> 02:01:39,730


867
02:01:41,590 --> 02:01:46,179


868
02:01:46,179 --> 02:01:49,719


869
02:01:49,719 --> 02:01:55,880


870
02:01:55,880 --> 02:02:01,309


871
02:02:01,309 --> 02:02:05,749


872
02:02:05,749 --> 02:02:10,070


873
02:02:10,070 --> 02:02:14,780


874
02:02:14,780 --> 02:02:21,130


875
02:02:21,399 --> 02:02:26,360


876
02:02:28,099 --> 02:02:32,659


877
02:02:35,989 --> 02:02:40,099


878
02:02:40,099 --> 02:02:50,539


879
02:02:50,539 --> 02:02:53,780


880
02:02:53,780 --> 02:02:58,579


881
02:02:58,579 --> 02:03:03,320


882
02:03:03,320 --> 02:03:10,130


883
02:03:10,130 --> 02:03:15,769


884
02:03:15,769 --> 02:03:19,849


885
02:03:19,849 --> 02:03:24,369


886
02:03:29,059 --> 02:03:34,639


887
02:03:34,639 --> 02:03:40,189


888
02:03:40,189 --> 02:03:45,289


889
02:03:48,889 --> 02:03:52,849


890
02:03:52,849 --> 02:03:57,769


891
02:03:57,769 --> 02:04:04,010


892
02:04:04,010 --> 02:04:09,560


893
02:04:09,560 --> 02:04:14,600


894
02:04:14,600 --> 02:04:18,950


895
02:04:20,600 --> 02:04:25,000


896
02:04:25,000 --> 02:04:30,230


897
02:04:30,230 --> 02:04:36,080


898
02:04:36,080 --> 02:04:41,630


899
02:04:41,630 --> 02:04:49,100


900
02:04:49,100 --> 02:04:54,710


901
02:04:54,710 --> 02:04:59,240


902
02:04:59,240 --> 02:05:08,240


903
02:05:08,240 --> 02:05:13,690


904
02:05:14,730 --> 02:05:18,020


905
02:05:18,020 --> 02:05:24,920


906
02:05:24,920 --> 02:05:30,619


907
02:05:30,619 --> 02:05:37,340


908
02:05:37,340 --> 02:05:45,940


909
02:05:48,949 --> 02:05:54,980


910
02:05:54,980 --> 02:05:59,030


911
02:05:59,030 --> 02:06:06,710


912
02:06:06,710 --> 02:06:10,610


913
02:06:10,610 --> 02:06:15,500


914
02:06:15,500 --> 02:06:19,579


915
02:06:19,579 --> 02:06:24,409


916
02:06:24,409 --> 02:06:36,159


917
02:06:36,159 --> 02:06:44,150


918
02:06:44,150 --> 02:06:49,820


919
02:06:49,820 --> 02:06:55,639


920
02:06:55,639 --> 02:07:03,710


921
02:07:03,710 --> 02:07:08,780


922
02:07:08,780 --> 02:07:12,440


923
02:07:12,440 --> 02:07:16,880


924
02:07:16,880 --> 02:07:23,030


925
02:07:23,030 --> 02:07:28,460


926
02:07:28,460 --> 02:07:30,840


927
02:07:30,840 --> 02:07:34,469


928
02:07:34,469 --> 02:07:41,520


929
02:07:41,520 --> 02:07:48,780


930
02:07:50,909 --> 02:08:04,190


931
02:08:05,400 --> 02:08:12,270


932
02:08:12,270 --> 02:08:19,860


933
02:08:23,429 --> 02:08:26,510


934
02:08:29,940 --> 02:08:38,320


935
02:08:38,320 --> 02:08:43,360


936
02:08:43,360 --> 02:08:47,410


937
02:08:47,410 --> 02:08:51,760


938
02:08:51,760 --> 02:08:54,550


939
02:08:54,550 --> 02:08:59,740


940
02:08:59,740 --> 02:09:03,400


941
02:09:03,400 --> 02:09:10,210


942
02:09:10,210 --> 02:09:12,930


943
02:09:13,989 --> 02:09:19,239


944
02:09:19,239 --> 02:09:31,120


945
02:09:31,120 --> 02:09:35,380


946
02:09:35,380 --> 02:09:40,540


947
02:09:40,540 --> 02:09:44,380


948
02:09:44,380 --> 02:09:48,520


949
02:09:48,520 --> 02:09:55,180


950
02:09:55,180 --> 02:09:59,430


951
02:09:59,430 --> 02:10:05,760


952
02:10:09,250 --> 02:10:20,710


953
02:10:20,710 --> 02:10:24,430


954
02:10:24,430 --> 02:10:30,130


955
02:10:30,130 --> 02:10:35,530


956
02:10:35,530 --> 02:10:38,920


957
02:10:38,920 --> 02:10:43,780


958
02:10:43,780 --> 02:10:46,360


959
02:10:46,360 --> 02:10:49,380


960
02:10:49,380 --> 02:10:59,530


961
02:10:59,530 --> 02:11:04,300


962
02:11:04,300 --> 02:11:07,630


963
02:11:07,630 --> 02:11:12,970


964
02:11:12,970 --> 02:11:18,460


965
02:11:18,460 --> 02:11:22,020


966
02:11:22,740 --> 02:11:26,800


967
02:11:26,800 --> 02:11:29,950


968
02:11:29,950 --> 02:11:37,930


969
02:11:37,930 --> 02:11:42,940


970
02:11:45,130 --> 02:11:52,180


971
02:11:52,180 --> 02:11:57,630


972
02:11:57,630 --> 02:12:01,300


973
02:12:01,300 --> 02:12:05,800


974
02:12:05,800 --> 02:12:11,170


975
02:12:11,170 --> 02:12:16,420


976
02:12:16,420 --> 02:12:20,770


977
02:12:20,770 --> 02:12:26,410


978
02:12:28,420 --> 02:12:32,410


979
02:12:32,410 --> 02:12:37,540


980
02:12:37,540 --> 02:12:40,540


981
02:12:40,540 --> 02:12:45,400


982
02:12:45,400 --> 02:12:50,650


983
02:12:50,650 --> 02:12:57,580


984
02:12:57,580 --> 02:13:01,690


985
02:13:01,690 --> 02:13:09,400


986
02:13:09,400 --> 02:13:18,510


987
02:13:18,510 --> 02:13:25,780


988
02:13:28,990 --> 02:13:36,160


989
02:13:36,160 --> 02:13:40,900


990
02:13:40,900 --> 02:13:48,640


991
02:13:48,640 --> 02:13:52,300


992
02:13:52,300 --> 02:13:58,480


993
02:14:01,390 --> 02:14:08,050


994
02:14:08,050 --> 02:14:13,150


995
02:14:15,490 --> 02:14:20,620


996
02:14:20,620 --> 02:14:26,170


997
02:14:26,170 --> 02:14:29,770


998
02:14:29,770 --> 02:14:34,039


999
02:14:35,839 --> 02:14:43,609


1000
02:14:43,609 --> 02:14:49,849


1001
02:14:49,849 --> 02:14:53,419


1002
02:14:53,419 --> 02:14:58,669


1003
02:14:58,669 --> 02:15:02,899


1004
02:15:02,899 --> 02:15:09,109


1005
02:15:09,109 --> 02:15:13,780


1006
02:15:17,689 --> 02:15:23,659


1007
02:15:26,359 --> 02:15:33,019


1008
02:15:33,019 --> 02:15:39,079


1009
02:15:40,339 --> 02:15:47,479


1010
02:15:47,479 --> 02:15:53,030


1011
02:15:59,030 --> 02:16:05,869


1012
02:16:05,869 --> 02:16:11,030


1013
02:16:11,030 --> 02:16:17,059


1014
02:16:17,059 --> 02:16:19,879


1015
02:16:19,879 --> 02:16:24,619


1016
02:16:24,619 --> 02:16:28,869


1017
02:16:28,869 --> 02:16:34,119


