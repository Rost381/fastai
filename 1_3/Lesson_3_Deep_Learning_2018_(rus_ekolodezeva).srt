1
00:00:00,149 --> 00:00:03,600
Добро пожаловать на третью неделю курса.

2
00:00:03,600 --> 00:00:09,599
Вы наверняка заметили, что на этой неделе на форумах происходило много интересного.

3
00:00:09,599 --> 00:00:25,920
Многие участники курса подготовили материалы по курсу, чтобы помочь своим одногруппникам и лучше разобраться самим.

4
00:00:25,920 --> 00:00:32,340
Я хочу рассказать про некоторые, про что-то я уже писал на вики, но материалов очень много.

5
00:00:32,340 --> 00:00:42,480
Пользователь reshamas создала много полезных заметок — например, что делать, если не получается подключиться к AWS,

6
00:00:46,079 --> 00:00:57,750
она расписала всё в мелочах, я считаю, что это очень круто.

7
00:00:57,750 --> 00:01:05,460
Если вы делаете какие-то заметки для себя — поделитесь ими на форуме, это удобно делать в файлах разметки Markdown.

8
00:01:07,439 --> 00:01:13,789
Если вы загрузите свои заметки на GitHub, все смогут ими пользоваться. Или загрузите их на наш форум,

9
00:01:13,889 --> 00:01:25,140
reshamas сделала так со своей заметкой про tmux.

10
00:01:25,140 --> 00:01:39,869
tmux — консольная утилита, позволяющая показывать несколько терминалов на одном экране.

11
00:01:39,869 --> 00:01:48,210
Здесь в одном терминале у меня модули библиотеки, открытые редактором vim,

12
00:01:48,210 --> 00:01:53,579
в другом запущен Jupyter Notebook и так далее.

13
00:01:53,579 --> 00:02:03,060
Если интересно, reshamas написала на эту тему туториал, в её аккаунте на GitHub ещё много интересного.

14
00:02:03,060 --> 00:02:28,810
Apil Tamang написал хороший сжатый конспект предыдущей лекции.

15
00:02:29,610 --> 00:02:45,069
Pavel Surmenok написал пост про алгоритм поиска скорости обучения.

16
00:02:45,069 --> 00:02:59,500
Это очень круто, потому что об этом алгоритме ещё нигде не писали, а он очень полезный.

17
00:02:59,500 --> 00:03:13,560
Когда я поделился ссылкой на его пост в Twitter, им поделились сотни раз, у поста тысячи просмотров, отличная работа.

18
00:03:13,560 --> 00:03:20,779
Radek написал несколько полезных постов, мне особенно понравился гайд по PyTorch,

19
00:03:20,879 --> 00:03:32,260
он подойдёт для продвинутых студентов, например, тех, кто никогда не использовал PyTorch, но уже что-то знает про численное программирование.

20
00:03:35,560 --> 00:03:40,624
Есть интересная статья про связь между скоростью обучения и размером минибатча.

21
00:03:40,724 --> 00:03:46,030
Один студент недавно задал мне этот вопрос, поэтому я вспомнил этот пост.

22
00:03:46,030 --> 00:04:01,235
Автор поста пробовал различные скорости обучения и размеры минибатча и проанализировал, как они связаны, можете сами попробовать.

23
00:04:01,335 --> 00:04:15,586
Radek написал пост на тему моего утверждения о том, что SDGR находит более плоские области поверхности потерь и в них модель лучше обобщает.

24
00:04:15,686 --> 00:04:25,147
Он попробовал описать эту закономерность более точно, не очень удачно, но пост интересный.

25
00:04:25,247 --> 00:04:32,999
Есть пост по введению в свёрточные нейронные сети.

26
00:04:32,999 --> 00:04:57,059
Anand Saha написал отличный анализ архитектуры ResNet, мы ещё обсудим это в курсе, продвинутые студенты могут читать уже сейчас.

27
00:04:57,059 --> 00:05:04,349
Apil Tamang написал похожий пост. В общем, на форумах много чего происходит.

28
00:05:06,059 --> 00:05:17,479
Мы также создали форум для новичков. Тупых вопросов не бывает, но иногда страшно задавать вопрос про что-то простое,

29
00:05:19,860 --> 00:05:29,819
когда вокруг обсуждаются очень сложные вещи. Надеемся, что форум новичков будет не таким устрашающим.

30
00:05:29,819 --> 00:05:38,632
Если вы продвинутый студент и можете отвечать на такие вопросы, пожалуйста, делайте это дружелюбно —

31
00:05:38,732 --> 00:05:47,934
у людей за плечами может быть всего год опыта программирования и никакого опыта машинного обучения.

32
00:05:48,034 --> 00:05:56,159
Если вам хочется написать какой-то вспомогательный материал, не стесняйтесь — большинство авторов только что упомянутых заметок

33
00:05:56,159 --> 00:06:04,769
никогда не публиковали ничего в интернете, они такие же люди, как и вы.

34
00:06:04,769 --> 00:06:20,399
Если вы не уверены в каких-то деталях, запостите сначала на форум, люди помогут вам улучшить ваш материал фразами вроде

35
00:06:20,399 --> 00:06:29,439
«Вот здесь всё устроено немного по-другому, сейчас расскажу» или «Это очень интересно, вы не думали углубиться в эту тему?».

36
00:06:29,539 --> 00:06:38,969
К текущему моменту мы немного обсудили свёрточные нейронные сети.

37
00:06:38,969 --> 00:06:59,319
Мы не углублялись в детали того, как они работают, зато построили на их основе превосходного качества модель.

38
00:06:59,319 --> 00:07:12,280
Сегодня мы ещё раз посмотрим на модели и наконец-то подойдём к теории — что такое свёрточная нейронная сеть,

39
00:07:12,280 --> 00:07:16,000
что такое свёртка, как и почему это работает.

40
00:07:16,000 --> 00:07:25,930
Дальше мы продвинемся по нашему плану и обсудим использование нейронных сетей для анализа структурированных данных —

41
00:07:25,930 --> 00:07:31,449
логистика, прогнозы, анализ рынка и прочее.

42
00:07:31,449 --> 00:07:45,550
Потом посмотрим на обработку естественного языка, потом на коллаборативную фильтрацию для рекомендательных систем.

43
00:07:45,550 --> 00:07:53,020
Это будет проходить в том же формате, что и обсуждение CNN — без углубления в теорию, но с построением качественных моделей.

44
00:07:55,150 --> 00:08:01,984
Потом мы пройдёмся по этим же темам, но в другом порядке и более углубленно —

45
00:08:02,084 --> 00:08:09,949
рассмотрим коллаборативную фильтрацию, поймём, как написан соответствующий код и какая за этим стоит математика,

46
00:08:10,049 --> 00:08:20,620
потом сделаем то же самое для анализа структурированных данных, свёрточных нейронных сетей и обработки естественного языка.

47
00:08:20,620 --> 00:08:37,078
Давайте проговорим некоторые вещи с прошлых лекций ещё раз.

48
00:08:37,178 --> 00:08:55,889
Я хочу убедиться, что все смогут повторить модель с прошлой лекции для различения пород собак.

49
00:08:55,889 --> 00:09:11,339
Для этого нужно скачать данные. Данные можно скачивать либо с Kaggle, либо откуда-то ещё.

50
00:09:11,339 --> 00:09:37,960
Для скачивания данных с Kaggle мы используем kaggle-cli, он должен был установиться при загрузке материалов для курса.

51
00:09:38,060 --> 00:09:53,279
Поскольку данные скачиваются с сайта Kaggle, каждый раз, как на сайте что-то меняется, kaggle-cli ломается,

52
00:09:53,279 --> 00:10:13,434
с этим можно справиться командой pip install kaggle-cli --upgrade.

53
00:10:13,534 --> 00:10:25,765
После этого следуйте инструкциям reshamas для скачивания данных.

54
00:10:25,865 --> 00:10:43,509
Команда для скачивания данных: kg download -u  -p  -c .

55
00:10:43,609 --> 00:11:02,100
— это фраза, идущая после /c/ в адресной строке на странице соревнования.

56
00:11:02,100 --> 00:11:12,650
Перед скачиванием данных через kaggle-cli убедитесь, что согласились с правилами соревнования — для этого начните скачивать данные с сайта.

57
00:11:12,750 --> 00:11:18,850
Если правила не приняты, kaggle-cli вам об этом скажет.

58
00:11:18,850 --> 00:11:31,085
Если вы используете аккаунт Google для входа в Kaggle, kaggle-cli не будет работать, используйте форму восстановления пароля Kaggle.

59
00:11:31,185 --> 00:11:38,775
kaggle-cli создаст папку на вашем компьютере и скачает туда данные.

60
00:11:38,875 --> 00:11:52,600
kaggle-cli не подходит, если вы используете датасет не с Kaggle или если вам не нужны все предоставленные там данные.

61
00:11:52,600 --> 00:12:11,890
Например, в этом соревновании данные предоставлены в форматах TIFF (19 ГБ) и JPG (600 МБ), возможно, вы не захотите использовать оба.

62
00:12:11,890 --> 00:12:32,480
Для таких случаев есть расширение CurlWget для Google Chrome.

63
00:12:32,580 --> 00:13:02,944
Для всех страниц, откуда можно что-нибудь скачать, CurlWget предоставит вам ссылку для скачивания из терминала.

64
00:13:03,044 --> 00:13:10,449
В ссылке содержатся куки вашего браузера, плагин активируется, когда вы запускаете скачивание в первый раз.

65
00:13:10,449 --> 00:13:19,420
С помощью этого расширения можно скачать что угодно — например, ваш любимый сериал.

66
00:13:19,420 --> 00:13:33,610
Это очень полезный инструмент для анализа данных, потому что зачастую приходится анализировать видео.

67
00:13:33,610 --> 00:13:44,019
Итак, есть два способа получить данные. После этого можно начинать обучать модель.

68
00:13:44,019 --> 00:13:57,670
В переменной PATH указано, что данные лежат в директории data рабочей директории Jupyter ноутбука.

69
00:13:57,670 --> 00:14:04,990
Это не всегда удобно — данные могут лежать в другом месте или даже на другом диске,

70
00:14:04,990 --> 00:14:17,949
поэтому можно создать символическую ссылку на директорию с данными.

71
00:14:17,949 --> 00:14:24,109
Вы можете сложить ваши данные куда угодно и добавить на них ссылку или сложить их в рабочую директорию Jupyter ноутбука.

72
00:14:24,209 --> 00:14:35,829
Символические ссылки — это очень удобно, можете почитать про них на нашем форуме, если не работали с ними раньше.

73
00:14:35,829 --> 00:14:45,490
Как видите, модули библиотеки fast.ai доступны из Jupyter ноутбука таким же образом.

74
00:14:45,490 --> 00:15:06,845
Чтобы вывести список файлов и директорий с указанием ссылок в Linux, используйте команду ls -l.

75
00:15:06,945 --> 00:15:20,315
Вам могло показаться, что для обучения модели нужно больше кода, чем на самом деле.

76
00:15:20,415 --> 00:15:28,292
Здесь на одном экране показаны все шаги, которые я проделал для обучения модели для классификации кошек и собак.

77
00:15:28,392 --> 00:15:36,197
Здесь не показаны скачивание и распаковка данных с Kaggle.

78
00:15:36,297 --> 00:15:51,130
Это все необходимые этапы. Сначала мы импортируем библиотеки — fastai.conv_learner импортирует всё необходимое сам.

79
00:15:51,130 --> 00:15:57,860
Нужно указать путь к файлам, размер изображений и размер минибатча.

80
00:15:57,960 --> 00:16:10,940
В этой строке мы говорим, как нужно преобразовать изображения — какая будет модель, какого они должны быть размера,

81
00:16:11,040 --> 00:16:18,490
какой алгоритм дополнения данных использовать, какое максимальное увеличение использовать.

82
00:16:18,490 --> 00:16:34,360
Здесь мы говорим, что данные рассортированы на обучающую и валидационную выборку, а внутри каждой выборки — на кошек и собак.

83
00:16:34,360 --> 00:16:45,170
Если папки с обучающей и валидационной выборкой названы нестандартно, их названия можно передать через параметры trn_name и val_name.

84
00:16:45,270 --> 00:16:56,380
Название папки с неразмеченной тестовой выборкой test_name необходимо указывать, если вы будете отправлять модель на Kaggle.

85
00:16:59,770 --> 00:17:08,205
После этого мы создаём модель с архитектурой ResNet на основе уже обученной и вызываем метод .fit().

86
00:17:08,305 --> 00:17:17,420
Напомню, что по умолчанию все слои, кроме последних, заморожены, мы ещё будем про это говорить.

87
00:17:17,420 --> 00:17:23,110
Метод .fit() работал около двух с половиной минут. Я не выставлял precompute=True.

88
00:17:26,119 --> 00:17:35,390
На форумах было много уточняющих вопросов по поводу значения этого параметра, повторюсь — это просто небольшое ускорение.

89
00:17:35,390 --> 00:17:42,325
Если не до конца понятно, просто пропускайте и оставляйте precompute=False по умолчанию.

90
00:17:42,425 --> 00:17:52,635
precompute=True кэширует некоторые промежуточные результаты, чтобы их не нужно было пересчитывать каждый раз.

91
00:17:52,735 --> 00:18:11,180
Помните, что с precomputed=True не работает дополнение данных, потому что дополнение данных не работает с предвычисленными активациями.

92
00:18:11,180 --> 00:18:14,780
Я максимально упростил процесс, поэтому precompute=False.

93
00:18:14,780 --> 00:18:22,810
Последний слой обучается 3 цикла с длиной цикла в одну эпоху (cycle_len=1).

94
00:18:23,110 --> 00:18:27,190
После этого я размораживаю модель и обучаю уже все слои.

95
00:18:27,590 --> 00:18:39,170
Метод .bn_freeze() мы ещё обсудим, это особенность сложных архитектур типа ResNet50 или ResNeXt101.

96
00:18:39,170 --> 00:18:49,005
Эту строку имеет добавлять после разморозки, если вы используете датасеты, подобные изображениям ImageNet —

97
00:18:49,105 --> 00:19:02,495
фотографии обычных объектов со стороны размера от 200 до 500 пикселей.

98
00:19:02,595 --> 00:19:10,630
Для продвинутых студентов — это фиксирует нормализацию минибатчей.

99
00:19:10,730 --> 00:19:20,409
Мы ещё обсудим это во второй части курса, в других библиотеках этого нет, но это очень важный аспект.

100
00:19:20,409 --> 00:19:31,789
После этого все слои нейронной сети обучаются в течение одной эпохи, и применяется дополнение тестовых данных.

101
00:19:31,889 --> 00:19:37,909
Это даёт долю правильных ответов в 99.45%.

102
00:19:38,009 --> 00:19:47,139
Это минимальные шаги, которые можно выполнить при работе с новым датасетом,

103
00:19:47,139 --> 00:20:02,799
при условии, что вы уже подобрали скорость обучения, знаете, как устроены данные и так далее.

104
00:20:02,799 --> 00:20:15,499
Я хотел показать вам, как устроены другие библиотеки, и выбрал для этого Keras.

105
00:20:15,599 --> 00:20:33,059
Библиотека fast.ai построена на основе PyTorch, а Keras поддерживает TensorFlow, MXNet, CNTK и многие другие библиотеки,

106
00:20:33,159 --> 00:20:37,450
большинство людей используют Keras с TensorFlow.

107
00:20:37,450 --> 00:20:51,024
В Jupyter ноутбуке keras_lesson1.ipynb я постараюсь воссоздать модель с первой лекции на Keras, чтобы вы увидели, как это можно делать.

108
00:20:51,124 --> 00:20:59,510
Я не буду пока ничего говорить про метод .bn_freeze(), кроме показаний к применению —

109
00:21:00,850 --> 00:21:11,950
это архитектура нейронной сети с числом слоёв больше 34, как ResNet50 или ResNeXt101,

110
00:21:11,950 --> 00:21:24,520
и датасет, похожий на изображения ImageNet, где объект занимает большую часть изображений нормального размера.

111
00:21:24,520 --> 00:21:32,989
Если вы не уверены в его необходимости, попробуйте убрать и сравнить результаты.

112
00:21:33,089 --> 00:21:39,910
Продвинутые студенты наверняка начнут обсуждать это на форумах уже сейчас, а мы дойдём до этого

113
00:21:39,910 --> 00:21:46,720
только во второй части курса, когда вернёмся к свёрточным нейронным сетям.

114
00:21:50,820 --> 00:22:01,480
Итак, для работы с Keras нужно импортировать необходимые модули.

115
00:22:01,480 --> 00:22:12,151
Keras поддерживает стандартный способ сортировки данных на обучающую и валидационную выборки и на классы внутри выборок.

116
00:22:12,251 --> 00:22:22,805
Здесь мы указываем пути к папкам с обучающей и валидационной выборкой.

117
00:22:22,905 --> 00:22:36,575
Вы заметите, что с Keras обучение модели требует больше кода и различных параметров,

118
00:22:36,675 --> 00:22:44,650
и очень просто задать неправильные параметры, поэтому я постараюсь подробно всё показать.

119
00:22:44,650 --> 00:22:55,030
Для подготовки данных необходимо создать генератор данных конструктором ImageDataGenerator().

120
00:22:55,030 --> 00:23:10,634
В параметры генератора данных необходимо передать параметры дополнения данных и нормализации.

121
00:23:10,734 --> 00:23:15,619
В библиотеке fast.ai достаточно указать архитектуру, например, ResNet50, и необходимые параметры выставляются автоматически,

122
00:23:15,719 --> 00:23:21,700
здесь надо примерно понимать, что для этого требуется.

123
00:23:21,700 --> 00:23:30,220
В принципе копирования кода из интернета достаточно, чтобы всё работало.

124
00:23:30,220 --> 00:23:43,550
Нет общепринятых стандартов по поводу этих параметров дополнения данных, я скопировал эту строку из документации Keras.

125
00:23:43,550 --> 00:23:49,140
Я не знаю, хороший ли это набор параметров, но в документации используется такой.

126
00:23:49,240 --> 00:23:56,540
Параметры говорят, отражать ли изображения относительно горизонтали, как увеличивать, как сдвигать.

127
00:23:56,540 --> 00:24:03,102
Из генератора данных создаётся генератор методом .flow_from_directory().

128
00:24:03,202 --> 00:24:17,985
В его параметры передаётся путь к файлам, размер изображений, размер минибатча и параметр class_mode.

129
00:24:18,085 --> 00:24:31,650
Параметр class_mode указывает вид задачи классификации — двухклассовая или многоклассовая, 'binary' или 'categorial'.

130
00:24:31,750 --> 00:24:36,525
У нас два класса — кошки и собаки, class_mode='binary'.

131
00:24:36,625 --> 00:24:48,048
Необходимо отдельно создать генератор данных без дополнения данных для валидации

132
00:24:48,148 --> 00:25:00,760
и создать соответствующий генератор с параметром shuffle=False, чтобы валидационная выборка не перемешивалась —

133
00:25:00,860 --> 00:25:11,270
это полезно для обучающей выборки, но на валидационной помешает отслеживать прогресс в обучении.

134
00:25:11,270 --> 00:25:18,465
Эти шаги в Keras необходимо делать каждый раз.

135
00:25:18,565 --> 00:25:32,750
Keras не поддерживает ResNet34, поэтому в конце прошлой лекции я поменял ResNet34 на ResNet50, чтобы мы могли сравнить fastai и Keras на одной архитектуре.

136
00:25:32,750 --> 00:25:42,290
В Keras модель не подстраивается под датасет автоматически, это нужно делать вручную.

137
00:25:42,290 --> 00:25:50,600
Для этого конструктором ResNet50() создаётся базовая модель и к ней вручную добавляются дополнительные слои.

138
00:25:50,600 --> 00:26:01,370
К концу этого курса вы поймёте, почему мы добавили именно эти три слоя.

139
00:26:01,370 --> 00:26:06,070
Модель создаётся конструктором Model().

140
00:26:06,070 --> 00:26:19,515
В Keras нет встроенной функции заморозки, поэтому мы проходим по всем слоям и выставляем поле .trainable=False.

141
00:26:19,615 --> 00:26:27,110
В Keras необходимо компилировать модель после создания методом .compile().

142
00:26:28,160 --> 00:26:35,360
Метод принимает как параметры вид оптимизации, функцию потерь и метрику оценки качества модели.

143
00:26:36,439 --> 00:26:47,324
В fast.ai эти значения передаются по умолчанию, хотя есть возможность заменить их своими.

144
00:26:47,424 --> 00:26:55,886
Вместо метода .fit() вызывается метод .fit_generator(), он принимает как параметры два только что созданных генератора,

145
00:26:55,886 --> 00:27:06,681
зачем-то просит количество минибатчей в одной эпохе — это размер генератора, делённый на размер минибатча.

146
00:27:07,081 --> 00:27:13,680
Как и в fast.ai, задаётся количество эпох.

147
00:27:15,100 --> 00:27:35,639
Задаётся количество воркеров. В отличие от fast.ai, по умолчанию они не используются, важно не забыть про этот параметр для достижения хорошей скорости.

148
00:27:35,739 --> 00:27:43,469
Этого достаточно, чтобы начать тонкую настройку последних слоёв.

149
00:27:43,569 --> 00:27:53,805
На валидационной выборке доля правильных ответов получилась 95%, но на первой и второй эпохах она была 49% и 69%.

150
00:27:53,905 --> 00:28:01,115
Я не знаю, почему это так — возможно, ошибка в Keras, возможно, в моём коде.

151
00:28:01,215 --> 00:28:07,469
Я писал про это в Twitter, но там никто не смог разобраться.

152
00:28:07,569 --> 00:28:15,509
Это одна из причин, почему я использую fast.ai в этом курсе — там гораздо сложнее всё испортить.

153
00:28:15,609 --> 00:28:18,806
Я не знаю, в чём тут ошибка.

154
00:28:18,906 --> 00:28:23,270
Янет: Здесь используется TensorFlow?

155
00:28:23,500 --> 00:28:50,279
Да, здесь используется TensorFlow, для этого нужно установить его командой pip install tensorflow-gpu keras.

156
00:28:50,379 --> 00:29:08,539
В Keras нет дифференциальных скоростей обучения и частичного размораживания, поэтому нужно вручную отделить последние слои.

157
00:29:08,539 --> 00:29:17,210
Я буду настраивать все слои, начиная со 140-го, для этого прохожу по всем слоям и замораживаю или размораживаю их, после этого снова вызываю метод .compile().

158
00:29:17,210 --> 00:29:26,924
После этого я снова обучаю модель, доля правильных ответов на обучающей выборке примерно такая же, а на валидационной опять ерунда.

159
00:29:27,024 --> 00:29:40,062
Даже если не учитывать это, Keras проигрывает в сравнении с fastai — кода гораздо больше и результаты хуже:

160
00:29:40,162 --> 00:29:49,934
модель на Keras за восемь минут достигла доли правильных ответов в 97% на обучающей выборке,

161
00:29:50,034 --> 00:30:02,380
а модель на fastai за четыре или пять минут — 99.5% на валидационной выборке.

162
00:30:02,380 --> 00:30:17,620
Используйте TensorFlow, если вы разрабатываете что-то для смартфонов, PyTorch пока плохо это поддерживает.

163
00:30:17,620 --> 00:30:24,365
Вам придётся использовать TensorFlow, если это делает компания, где вы работаете.

164
00:30:24,465 --> 00:30:37,000
Если вам нужно повторить что-то из этого курса с TensorFlow, используйте Keras и будьте готовы к тому,

165
00:30:37,000 --> 00:30:53,690
что будет больше кода, и будет сложнее повторить результаты, которые легко достигаются в fast.ai.

166
00:30:54,669 --> 00:31:05,990
В fast.ai нет ничего, что нельзя было бы повторить в Keras,

167
00:31:06,090 --> 00:31:20,389
но каждый раз заново писать SGDR, дифференциальные скорости обучения и всё остальное — неудобно.

168
00:31:20,489 --> 00:31:29,199
На форуме один человек работает над интеграцией Keras/TensorFlow и fast.ai, я надеюсь, что из этого что-то выйдет.

169
00:31:29,299 --> 00:31:43,270
Я разговаривал с Google и они тоже в этом заинтересованы. Возможно, к тому моменту, как этот курс появится на MOOC-платформе, это сделают.

170
00:31:43,270 --> 00:32:05,900
Keras/TensorFlow не очень сложные, для перехода с fast.ai после этого курса вам понадобится пара дней.

171
00:32:06,000 --> 00:32:19,890
Всего сказанного должно хватить для того, чтобы вы смогли обучить модель на датасете с породами собак.

172
00:32:19,890 --> 00:32:26,600
Большую часть того, что нужно сделать, я показал в конце прошлой лекции —

173
00:32:30,870 --> 00:32:37,885
например, как я изучал данные, чтобы понять, как устроены классы и какого размера изображения.

174
00:32:37,985 --> 00:32:41,980
Если вы что-то забыли, пересмотрите прошлую лекцию.

175
00:32:43,080 --> 00:32:53,794
Мы не успели обсудить, как отправить модель на Kaggle, сейчас покажу.

176
00:32:53,894 --> 00:33:01,500
Я уже написал про это в вики.

177
00:33:01,500 --> 00:33:12,955
На Kaggle для каждого соревнования есть вкладка Evaluation, в ней написано, какой формат нужен.

178
00:33:13,055 --> 00:33:19,810
В этом соревновании на выходе должен быть файл, где в заголовке — ID и все возможные породы собак,

179
00:33:20,410 --> 00:33:31,860
а в остальных строках — ID файлов тестовой выборки и вероятности того, что на этих файлах различные породы собак.

180
00:33:35,610 --> 00:33:55,240
Объект data.classes содержит названия всех классов в алфавитном порядке.

181
00:33:55,340 --> 00:34:01,645
Объект data.test_ds содержит тестовую выборку, названия файлов лежат в data.test_ds.fnames.

182
00:34:01,745 --> 00:34:18,444
Напоминаю, что изображения не разложены по папкам в стиле Keras, а размечены в файле CSV,

183
00:34:18,544 --> 00:34:27,859
поэтому мы используем метод ImageDataClassifier.from_csv(), а не ImageDataClassifier.from_paths().

184
00:34:31,799 --> 00:34:40,139
Keras не поддерживает такой формат, поэтому на форумах Kaggle люди выкладывают скрипты для сортировки данных по папкам,

185
00:34:40,139 --> 00:34:47,574
но нам этого делать не придётся.

186
00:34:47,674 --> 00:35:03,740
Итак, у нас есть названия пород и имена файлов тестовой выборки.

187
00:35:03,740 --> 00:35:28,789
Я всегда использую TTA при предсказании тестовой выборки, для этого в метод .TTA() передаётся параметр is_test=True,

188
00:35:28,889 --> 00:35:35,369
чтобы предсказания делались на тестовой выборке, а не на валидационной.

189
00:35:35,369 --> 00:35:44,765
Мы не знаем, какая получилась доля правильных ответов, потому что тестовая выборка не размечена.

190
00:35:44,865 --> 00:35:57,099
Большинство моделей PyTorch возвращает логарифмы вероятностей, метод np.exp() переводит их в обычные вероятности.

191
00:35:57,199 --> 00:36:10,529
В тестовой выборке 10357 изображений, принадлежащих 120 различным породам собак, это размеры полученной матрицы предсказаний probs.

192
00:36:10,529 --> 00:36:17,695
Из этой матрицы мы создадим файл необходимого формата с помощью pandas.

193
00:36:17,795 --> 00:36:27,472
Если вы не работали с pandas, погуглите или посмотрите наш курс по машинному обучению, там это часто используется.

194
00:36:27,572 --> 00:36:41,007
Мы создаём датафрейм pandas из матрицы конструктором pandas.DataFrame(), присваиваем столбцам названия пород собак

195
00:36:41,607 --> 00:36:57,745
и вставляем нулевой столбец с названиями файлов. Названия содержат 'test/' в начале и '.jpg' в конце, эти части мы обрезаем.

196
00:36:57,845 --> 00:37:06,550
Итоговый датафрейм выглядит так.

197
00:37:06,650 --> 00:37:24,000
Датафреймы с данными обычно называют df (data frame).

198
00:37:24,000 --> 00:37:36,680
С помощью метода .to_csv() можно записать получившийся датафрейм в файл CSV. Имеет смысл включить сжатие параметром compression='gzip'.

199
00:37:36,780 --> 00:37:45,082
После этого на сервере Jupyter Notebook появится файл CSV.

200
00:37:45,182 --> 00:37:57,235
После этого вы можете либо скачать файл с сервера и отправить его вручную, либо использовать kaggle-cli.

201
00:37:57,335 --> 00:38:04,170
Я обычно скачиваю файл себе на компьютер, чтобы посмотреть на него перед отправкой.

202
00:38:04,170 --> 00:38:27,130
Есть удобная утилита FileLink, которая создаёт ссылку, по которой можно скачать файл с сервера Jupyter Notebook на ваш компьютер.

203
00:38:33,490 --> 00:38:43,025
Архив с файлом скачался.

204
00:38:43,125 --> 00:38:54,095
Формат именно такой, какой нужно — в заголовке строке ID и породы собак, остальные строки содержат имя файла и вероятности.

205
00:38:54,195 --> 00:39:00,695
Теперь можно загрузить его на Kaggle через веб-интерфейс.

206
00:39:00,795 --> 00:39:15,160
Итак, теперь мы умеем скачивать файлы из интернета на сервер Jupyter Notebook через CurlWget в Google Chrome

207
00:39:17,170 --> 00:39:31,270
и умеем скачивать файлы с сервера на свой компьютер. Можно использовать scp в терминале, но мне нравится делать это в Jupyter ноутбуке.

208
00:39:31,270 --> 00:39:42,910
На этой неделе меня спросили, как получить предсказание только для одного файла.

209
00:39:42,910 --> 00:39:49,790
Допустим, я хочу получить предсказание для первого изображения валидационной выборки.

210
00:39:49,890 --> 00:39:59,350
Вот имя файла, я могу его вывести методом Image.open() стандартной библиотеки Python.

211
00:39:59,350 --> 00:40:16,230
Самое простое, что вы можете сделать — вызвать метод .predict_array().

212
00:40:16,230 --> 00:40:21,390
Для этого надо сначала применить к изображению дополнение данных.

213
00:40:21,390 --> 00:40:36,310
Функция tfms_from_model возвращает преобразования данных отдельно для обучающей и валидационной выборки.

214
00:40:36,310 --> 00:40:45,280
После этого мы применяем на изображении дополнение данных для обучающей выборки. Нет, лучше для валидационной.

215
00:40:45,280 --> 00:40:52,420
Полученный массив можно передавать в метод .predict_array().

216
00:40:55,440 --> 00:41:05,320
Данные можно подавать в модель и получать от модели только в минибатчах.

217
00:41:05,320 --> 00:41:15,250
У нас только одно изображение, и мы хотим превратить его в минибатч,

218
00:41:15,250 --> 00:41:21,490
то есть превратить из тензора размерности (количество строк)x(количество столбцов)х(цветовые каналы)

219
00:41:21,490 --> 00:41:26,230
в тензор размерности (количество изображений)x(количество строк)x(количество столбцов)х(цветовые каналы).

220
00:41:26,230 --> 00:41:31,330
У нас трёхмерная матрица, а должна быть четырёхмерная.

221
00:41:31,330 --> 00:41:46,480
Если в numpy индексировать массив im как im[None], вернётся массив размерностью больше на 1, так мы превратили изображение в минибатч.

222
00:41:46,480 --> 00:42:02,080
Если вы забудете это сделать при использовании PyTorch или fast.ai, получите ошибку вроде «expected 4 dimensions but got 3».

223
00:42:02,080 --> 00:42:15,040
Модели не только принимают, но и возвращают минибатчи, это тоже учтите.

224
00:42:15,040 --> 00:42:38,405
На этом мы закончим с практикой и перейдём к теории свёрточных нейронных сетей.

225
00:42:38,505 --> 00:42:54,175
На первой лекции мы немного поговорили про теорию, используя демонстрацию setosa.io/ev/, Explained Visually.

226
00:42:54,275 --> 00:43:03,910
Мы узнали, что свёртка — это алгоритм, который рассматривает область 3х3 пикселя за раз и умножает значение каждого пикселя

227
00:43:04,010 --> 00:43:16,790
на соответствующее значение матрицы свёртки, а потом складывает числа внутри области для получения нового значения в центре области.

228
00:43:16,890 --> 00:43:29,065
Давайте посмотрим, как с помощью этого алгоритма создаются слои нейронной сети, которые мы видели в статье Зайлера и Фергюса.

229
00:43:29,165 --> 00:43:39,570
Для этого я покажу вам работу человека, который гораздо умнее меня — Отавио Гуда.

230
00:43:39,570 --> 00:43:47,155
Отавио Гуд создал Word Lens — это система распознавания текста, которая сейчас используется в Google Translate,

231
00:43:47,255 --> 00:43:58,080
когда вы наводите камеру телефона на текст на незнакомом языке и поверх изображения показывается перевод.

232
00:43:58,080 --> 00:44:06,385
Отавио разработал эту систему и создал превосходную демонстрацию её работы, сейчас он работает в Google.

233
00:44:06,485 --> 00:44:21,000
Я прокомментирую эту демонстрацию, а потом мы посмотрим на нечто похожее в таблице в Microsoft Excel.

234
00:44:21,500 --> 00:44:27,720
Надеюсь, что принцип работы будет ясен и тем, кто любит видео, и тем, кто любит таблицы.

235
00:44:29,880 --> 00:44:41,610
Эта демонстрация распознавания текста, дальше в курсе мы займёмся распознаванием цифр, задачи очень похожи.

236
00:44:41,610 --> 00:44:51,990
На изображении — буква А, изображение — это матрица чисел.

237
00:44:51,990 --> 00:44:59,035
К этой матрице чисел применяется первый свёрточный фильтр. Предполагается, что все фильтры уже вычислены, модель обучена.

238
00:44:59,135 --> 00:45:05,010
Фильтр чёрный слева и белый справа, это значит, что матрица свёртки выглядит примерно так:

239
00:45:05,010 --> 00:45:10,350
[[-1, 0, 1],
[-1, 0, 1],
[-1, 0, 1]].

240
00:45:13,140 --> 00:45:21,670
Каждая область 3х3 поэлементно умножается на эту матрицу, полученные результаты складываются.

241
00:45:21,770 --> 00:45:30,180
Везде, где чёрное переходит в белое, мы получаем положительные значения, они показаны зелёным,

242
00:45:30,180 --> 00:45:36,475
а там, где белое переходит в чёрное — отрицательные значения, они показаны красным.

243
00:45:36,575 --> 00:45:41,920
Это результат работы первого ядра свёртки.

244
00:45:42,020 --> 00:45:47,020
Вот новое ядро, с белой полосой наверху, а не справа.

245
00:45:47,120 --> 00:46:02,610
Фильтр проходит через каждую область изображения 3x3 и определяет, насколько красным или зелёным получится новый пиксель.

246
00:46:02,610 --> 00:46:15,570
Допустим, у нас было всего два фильтра, видно, что результат отражает вид матриц свёртки.

247
00:46:15,570 --> 00:46:26,520
Полученные результаты пропускаются через выпрямитель (ReLU), который убирает отрицательные значения.

248
00:46:26,520 --> 00:46:30,780
Здесь показан первый входной слой, второй слой — результат работы свёрточных фильтров,

249
00:46:30,780 --> 00:46:36,180
третий слой — результат работы выпрямителя,

250
00:46:38,190 --> 00:46:55,320
четвёртый слой — подвыборка максимумом: каждая область 2х2 заменяется на максимальный элемент этой области, такой алгоритм уменьшения.

251
00:46:55,420 --> 00:47:05,599
После этого процедура повторяется. Новые фильтры свёртки проходят уже оба полученных фильтра с предыдущего слоя,

252
00:47:05,699 --> 00:47:21,190
полученные результаты пропускаются через выпрямитель, получается ещё один слой свёрточной нейронной сети.

253
00:47:21,190 --> 00:47:30,490
Видно, что на первом слое свёртки выделялись горизонтальные или вертикальные края.

254
00:47:33,010 --> 00:47:42,559
Результат работы следующего слоя уже не так очевиден, но принцип его работы такой же.

255
00:47:42,659 --> 00:47:52,180
После этого опять выполняется подвыборка максимумом, каждая область 2x2 заменяется одним числом.

256
00:47:53,799 --> 00:48:07,865
Полученное изображение сравнивается с шаблонами возможных классов, одному из которых оно принадлежит.

257
00:48:07,965 --> 00:48:19,456
Это делается таким же образом — изображение 4x8 поэлементно умножается на шаблон, соответствующий какому-то классу,

258
00:48:19,556 --> 00:48:30,614
результаты складываются и потом конвертируются в вероятность.

259
00:48:31,114 --> 00:48:38,524
Это изображение на 92% совпало с шаблоном класса А, модель считает, что на изображении буква А.

260
00:48:38,624 --> 00:48:46,119
Демонстрация показывает работу уже обученной модели на тестовой выборке,

261
00:48:46,119 --> 00:49:00,484
например, вашей модели или модели, преобученной на изображениях ImageNet.

262
00:49:00,584 --> 00:49:17,855
Ещё раз: на каждом слое сначала работают свёрточные фильтры, потом выпрямитель, потом подвыборка максимумом.

263
00:49:17,955 --> 00:49:29,395
После работы многих слоёв результат сравнивается с шаблонами и получается предсказание.

264
00:49:29,495 --> 00:49:40,420
Как видите, демонстрация очень крутая, я не смог бы такое нарисовать, спасибо Отавио за то, что поделился этим.

265
00:49:40,420 --> 00:49:49,895
Это видео демонстрирует работу реальной свёрточной нейронной сети, Отавио написал для этого специальную программу.

266
00:49:49,995 --> 00:49:58,060
Я человек простой и предпочитаю таблицы в Excel.

267
00:49:58,060 --> 00:50:08,950
Эта таблица есть в репозитории fast.ai на GitHub, можете клонировать весь репозиторий или скачать её отдельно,

268
00:50:08,950 --> 00:50:36,880
она доступна по адресу github.com/fastai/fastai/tree/master/courses/dl1/excel/conv-example.xlsx.

269
00:50:36,880 --> 00:50:55,290
В качестве входных данных я взял изображение цифры 7 из базы данных MNIST, мы с ней ещё будем работать.

270
00:50:55,290 --> 00:51:09,640
Каждая ячейка представляет чёрно-белый пиксель, число от 0 до 1. Иногда используются числа от 0 до 255,

271
00:51:13,060 --> 00:51:25,900
это не важно, в PyTorch всё конвертируется в действительные числа от 0 до 1.

272
00:51:25,900 --> 00:51:47,299
Я использовал условное форматирование и сделал высокие значения красными, видно, что здесь изображена цифра 7.

273
00:51:47,399 --> 00:51:55,249
В демонстрации Отавио в первом слое использовались два свёрточных фильтра.

274
00:51:55,349 --> 00:52:05,170
Я создал фильтр, который выделяет верхние границы изображения, матрица свёртки выглядит так:

275
00:52:05,170 --> 00:52:10,119
[[1, 1, 1],
[0, 0, 0],
[-1, -1, -1]].

276
00:52:10,119 --> 00:52:16,630
Давайте выберем один пиксель и посмотрим, что происходит.

277
00:52:16,630 --> 00:52:24,112
Область изображения 3x3 поэлементно умножается на матрицу свёртки.

278
00:52:24,212 --> 00:52:44,134
В верхнем ряду все единицы, в нижнем почти все нули, поэтому итоговое значение получается высоким.

279
00:52:44,234 --> 00:52:54,670
Если сдвинуться на два пикселя вниз, в области уже почти нет ненулевых значений, в итоге ноль.

280
00:52:54,670 --> 00:53:08,859
Более интересный пример: здесь высокие значения как в верхнем ряду, так и в нижнем, в сумме тоже ноль.

281
00:53:08,859 --> 00:53:15,169
Как видно, такой фильтр активирует только горизонтальные края.

282
00:53:15,669 --> 00:53:49,070
Это число 3 называется активацией. Активация — число, полученное после выполнения линейной операции над изображением.

283
00:53:49,170 --> 00:54:03,095
В моей формуле есть и свёртка, и выпрямитель. Выпрямитель отбрасывает отрицательные значения,

284
00:54:03,195 --> 00:54:32,920
это записывается формулой y = max(0, x). Выглядит слишком просто, но это так и есть, здесь я ничего не упрощаю.

285
00:54:32,920 --> 00:54:50,490
Когда я упрощаю что-то, я обязательно говорю, что это упрощение, но выпрямитель и свёртка действительно работают очень просто.

286
00:54:50,490 --> 00:55:03,560
На экране сейчас полностью воплощён один слой свёрточной нейронной сети.

287
00:55:03,560 --> 00:55:09,290
Этот свёрточный фильтр выделяет горизонтальные границы.

288
00:55:09,290 --> 00:55:24,660
Опять же, подразумевается, что модель обучили и в процессе обучения появились эти фильтры.

289
00:55:24,760 --> 00:55:31,890
Вот второй фильтр того же слоя, в матрице другие числа.

290
00:55:31,990 --> 00:55:54,230
PyTorch не хранит фильтры как отдельные матрицы 3x3, он хранит их в виде тензора. Тензор — это многомерная матрица.

291
00:55:54,230 --> 00:56:03,495
Фильтры хранятся в виде тензора, что позволяет создавать из них слои.

292
00:56:03,595 --> 00:56:19,700
Понятия свёрточный фильтр и свёрточное ядро взаимозаменяемы — они означают одну из матриц 3x3, одну из частей трёхмерного тензора.

293
00:56:19,700 --> 00:56:35,295
Как видно, этот фильтр находит вертикальные границы изображения.

294
00:56:35,395 --> 00:56:42,030
Два свёрточных фильтра с двумя выпрямителями образуют слой свёрточной нейронной сети.

295
00:56:42,130 --> 00:56:48,680
Этот слой — скрытый, так называются все слои, кроме входного и выходного.

296
00:56:50,810 --> 00:57:05,974
Размер этого слоя — 2, потому что он содержит два свёрточных фильтра.

297
00:57:06,074 --> 00:57:13,729
Переходим к следующему слою.

298
00:57:13,829 --> 00:57:34,540
Он устроен сложнее, потому что на вход теперь подаются оба изображения с предыдущего слоя, поэтому здесь два фильтра.

299
00:57:34,540 --> 00:57:53,464
PyTorch хранит эти две матрицы в одном тензоре 2x3x3, поэтому стоит думать о них, как об одном фильтре.

300
00:57:53,564 --> 00:58:14,264
Для получения активации складываются результаты от двух матриц 3x3.

301
00:58:14,364 --> 00:58:22,420
Верхнее изображение умножается на одну часть фильтра, нижнее — на другую.

302
00:58:22,420 --> 00:58:35,530
Со временем вам придётся привыкнуть к многомерным линейным пространствам.

303
00:58:35,530 --> 00:58:44,855
Я нарисовал свёрточные фильтры один под другим, но на самом деле они как бы наложены друг на друга.

304
00:58:44,955 --> 00:58:50,600
Джеффри Хинтон в своём курсе «Нейронные сети для машинного обучения» на Coursera в 2012 году рассказал,

305
00:58:50,700 --> 00:58:58,990
как все специалисты по анализу данных представляют себе многомерные пространства.

306
00:58:58,990 --> 00:59:06,390
Они представляют двумерное пространство, а потом очень быстро произносят: «Двенадцатимерное пространство!» и всё получается.

307
00:59:06,390 --> 00:59:19,550
Мы дошли до второго слоя, вам придётся просто поверить, что все остальные устроены так же,

308
00:59:19,550 --> 00:59:38,900
потому что Excel не поддерживает трёхмерные матрицы. Если бы поддерживал, эту операцию я бы провёл одним умножением, без суммирования.

309
00:59:38,900 --> 00:59:44,720
Опять же, после свёртки я использую выпрямитель, он же ReLU.

310
00:59:48,710 --> 01:00:02,540
Архитектура нашей нейронной сети такова:

311
01:00:02,540 --> 01:00:15,250
на первом слое 2 свёрточных фильтра 3x3, вот первый и второй,

312
01:00:16,150 --> 01:00:31,895
на втором слое 2 свёрточных фильтра 2x3x3, вот первый и второй.

313
01:00:31,995 --> 01:00:52,940
Все числа в больших таблицах — активации, эта активация вычислена по двум областям 3x3 с помощью фильтра 2x3x3.

314
01:00:52,940 --> 01:00:57,830
Обычно слои свёрточной нейронной сети как-то называют.

315
01:00:57,830 --> 01:01:10,650
Первый слой мы назовём Conv1, второй — Conv2.

316
01:01:10,750 --> 01:01:21,990
Названия слоёв у различных архитектур выводятся в их описании.

317
01:01:22,090 --> 01:01:36,520
Следующая часть архитектуры после слоёв — подвыборка максимумом, этот слой мы назовём Maxpool.

318
01:01:36,520 --> 01:01:43,569
Подвыборку максимумом сложно показать в Excel, но я старался.

319
01:01:43,569 --> 01:01:53,219
При подвыборке максимумом высота и ширина изображения уменьшаются вдвое.

320
01:01:53,319 --> 01:01:59,909
Из каждых четырёх чисел в области 2x2 выбирается максимальное.

321
01:02:00,009 --> 01:02:06,780
Так как изображение уменьшится в два раза, я заполняю только половину ячеек.

322
01:02:06,780 --> 01:02:19,030
Изображение получается похожим, но в два раза меньше по обоим измерениям.

323
01:02:19,030 --> 01:02:24,160
При этом рассматриваются не все возможные области 2x2, изображение как бы разрезается на эти области —

324
01:02:26,319 --> 01:02:38,050
одна область начинается в столбце BQ, а следующая — в столбце BS, они не накладываются друг на друга, поэтому изображение уменьшается.

325
01:02:38,050 --> 01:02:47,525
Если кто-то из вас любит таблицы, можете изучить внимательнее.

326
01:02:47,625 --> 01:02:55,084
После подвыборки максимумом возможны различные варианты развития архитектуры.

327
01:02:55,184 --> 01:03:00,454
Я покажу классический подход, который сейчас уже слегка устарел.

328
01:03:00,554 --> 01:03:07,490
В старых архитектурах и архитектурах для работы со структурированными данными

329
01:03:07,590 --> 01:03:14,810
вместо подвыборки максимумом использовались полносвязные слои.

330
01:03:14,910 --> 01:03:43,094
В полносвязных слоях каждая активация умножается на соответствующий ей вес и результаты складываются.

331
01:03:43,194 --> 01:03:49,490
В отличие от свёрточного слоя, здесь рассматривается всё изображение за раз, а не области 3x3,

332
01:03:51,980 --> 01:04:03,290
матрица весов по размеру совпадает с изображением.

333
01:04:03,290 --> 01:04:17,744
У архитектур с полносвязными слоями очень много весов, поэтому они медленно работают и легко переобучаются.

334
01:04:17,844 --> 01:04:28,465
Архитектура VGG-Net была первой успешной глубокой архитектурой, она содержит до 19 слоёв.

335
01:04:28,565 --> 01:04:42,930
VGG содержит полносвязный слой с 4096 активациями, связанный со скрытым слоем с 4096 активациями.

336
01:04:43,030 --> 01:04:53,180
Это уже 4096x4096x(количество свёрточных ядер слоя) весов.

337
01:04:53,180 --> 01:05:09,380
Суммарно VGG содержит около 300 миллионов весов, из которых 250 миллионов — веса полносвязных слоёв.

338
01:05:09,380 --> 01:05:13,700
Дальше в курсе мы узнаем про то, как избегать полносвязные слои при построении архитектуры.

339
01:05:15,470 --> 01:05:23,004
Все используемые нами архитектуры — ResNet и ResNeXt — не содержат больших полносвязных слоёв.

340
01:05:23,104 --> 01:05:40,280
Янет: Как выглядят фильтры для изображений с тремя цветовыми каналами?

341
01:05:40,280 --> 01:05:52,160
Если бы у нашего изображения было три цветовых канала, входной слой выглядел бы, как слой Conv1.

342
01:05:52,160 --> 01:06:00,164
В Conv1 два канала, поэтому фильтры во втором слое состоят из двух каналов.

343
01:06:00,264 --> 01:06:11,749
Если у входного изображения несколько каналов, фильтры первого слоя будут выглядеть так, как в нашем примере выглядят фильтры второго слоя.

344
01:06:11,749 --> 01:06:17,779
У полноцветных изображений три цветовых канала — красный, зелёный и синий, иногда есть альфа-канал.

345
01:06:17,779 --> 01:06:23,059
Сколько у изображения каналов, столько и будет матриц во входном слое.

346
01:06:23,059 --> 01:06:30,764
Я знаю, что Янет сейчас использует модель, обученную на полноцветных изображениях ImageNet,

347
01:06:30,864 --> 01:06:35,124
для определения костного возраста по рентгеновским снимкам, у которых только один канал.

348
01:06:35,224 --> 01:06:51,989
Для этого она дважды продублировала единственный канал снимков, чтобы создать «полноцветное» изображение.

349
01:06:52,089 --> 01:06:59,630
Получается, что при обучении модель получает избыточную информацию, так как все каналы одинаковые,

350
01:06:59,630 --> 01:07:08,640
зато так работают предобученные фильтры для полноцветных изображений.

351
01:07:08,740 --> 01:07:17,660
Сейчас на Kaggle есть соревнование по распознаванию айсбергов на спутниковых двухканальных снимках,

352
01:07:17,660 --> 01:07:30,029
в этом случае можно продублировать один из каналов или создать новый канал как среднее от двух имеющихся.

353
01:07:30,129 --> 01:07:36,794
Это не идеальное решение, но оно позволяет использовать предобученные нейронные сети.

354
01:07:36,894 --> 01:07:48,410
Однажды я использовал обученную на трёх каналах модель для работы с четырёхканальными изображениями.

355
01:07:48,410 --> 01:07:53,029
Это были спутниковые снимки, где четвёртый канал был в ближнем инфракрасном диапазоне.

356
01:07:53,029 --> 01:08:08,545
Для этого перед обучением я добавил четвёртый уровень из нулей в каждый свёрточный фильтр.

357
01:08:08,645 --> 01:08:21,500
На следующей лекции вы увидите, что при обучении модели с нуля вместо  преобученных фильтров используются матрицы случайных чисел,

358
01:08:21,600 --> 01:08:33,070
на которых потом применяется стохастический градиентный спуск с перезапуском, который улучшает эти случайные числа.

359
01:08:35,350 --> 01:08:44,985
Давайте сделаем перерыв на 7 минут и продолжим в 7:50.

360
01:08:45,085 --> 01:08:50,310
=============

361
01:08:50,310 --> 01:09:04,685
Итак, результаты подвыборки максимумом передаются в полносвязный слой.

362
01:09:04,785 --> 01:09:07,180


363
01:09:07,180 --> 01:09:11,770


364
01:09:11,770 --> 01:09:17,920


365
01:09:17,920 --> 01:09:23,970


366
01:09:23,970 --> 01:09:47,505
Для того, чтобы понять, какая из десяти цифр на изображении, нужно посчитать десять таких чисел.

367
01:09:47,605 --> 01:10:06,860
Для этого вместо одного набора полносвязных весов, то есть одного трёхмерного тензора, у нас будет десять.

368
01:10:06,960 --> 01:10:21,430
Моего терпения не хватило на то, чтобы сделать десять таких слоёв, в результате получилось бы десять таких чисел.

369
01:10:21,530 --> 01:10:40,190
Вместо одного тензора весов 2xNxM было бы 10 таких тензоров, каждый выдавал бы одно число.

370
01:10:40,190 --> 01:10:52,314
Что дальше? Давайте откроем другую демонстрацию, entropy_example.xlsx.

371
01:10:52,414 --> 01:10:59,234
Здесь два листа, первый называется softmax.

372
01:10:59,334 --> 01:11:10,820
Здесь другая задача - нужно не определить цифру, а отнести изображение к классу кошек, собак, самолётов, рыб или зданий.

373
01:11:10,820 --> 01:11:27,675
После полносвязного слоя мы получили пять чисел, выпрямитель не применялся, поэтому есть отрицательные значения.

374
01:11:27,775 --> 01:11:42,359
Я хочу перевести этим пять чисел в пять вероятностей принадлежности соответствующим классам.

375
01:11:42,459 --> 01:11:55,969
Все вероятности должны лежать между 0 и 1 и в сумме давать 1, потому что изображение точно  принадлежит какому-то из этих классов.

376
01:11:55,969 --> 01:12:01,400
Для этого вместо выпрямителя придётся использовать другую функцию активации.

377
01:12:01,400 --> 01:12:16,340
Функция активации - функция, применяемая к активации, например, выпрямитель.

378
01:12:16,340 --> 01:12:23,630
Функция активации принимает на вход одно число и возвращает одно число.

379
01:12:23,630 --> 01:12:36,115
Выпрямитель y = max(0, x) принимает число x и возвращает число y.

380
01:12:36,215 --> 01:12:44,230
Вспомните демонстрацию с первой лекции.

381
01:12:45,590 --> 01:12:55,230
Мы говорили, что каждый из слоёв - это линейная функция + нелинейная часть.

382
01:12:58,619 --> 01:13:18,210
Линейная комбинация линейных функций - тоже линейная функция, поэтому комбинация нескольких линейных слоёв - тоже линейная функция.

383
01:13:18,210 --> 01:13:25,609
Значимые результаты в глубоком обучении не достигаются только линейными функциями.

384
01:13:25,709 --> 01:13:34,769
Мы также говорили, что добавлением нелинейностей между линейными функциями можно описать сколь угодно сложные закономерности.

385
01:13:34,769 --> 01:13:47,119
Нелинейность, которую мы использовали - это выпрямитель, и функция активации и есть эта нелинейность.

386
01:13:47,219 --> 01:13:57,444
Разумеется, это всё в рамках глубокого обучения, в мире очень много различных нелинейностей.

387
01:13:57,544 --> 01:14:06,239
Итак, функция активации - любая функция, принимающая на вход одну активацию и возвращающая другую, например, выпрямитель.

388
01:14:06,339 --> 01:14:15,744
Сейчас я покажу новую функцию активации, она чуть сложнее выпрямителя.

389
01:14:15,844 --> 01:14:22,029
Она называется Softmax и появляется только на последнем слое,

390
01:14:22,129 --> 01:14:35,729
потому что всегда возвращает числа от 0 до 1, которые в сумме дают 1, то, что нам нужно.

391
01:14:35,729 --> 01:14:53,489
В принципе, можно создавать фильтры таким образом, что числа на последнем слое будут уже в формате вероятностей,

392
01:14:54,960 --> 01:15:10,170
но это добавит параметров в модель, а модели с большим количеством параметров хуже обучаются.

393
01:15:10,170 --> 01:15:29,610
Мы хотим получить вероятности от 0 до 1, в сумме дающие 1, поэтому придумываем функцию, всегда удовлетворяющую этим условиям.

394
01:15:29,610 --> 01:15:51,420
Вероятности должны быть неотрицательные, поэтому давайте для начала вычислим от них экспоненту функцией EXP().

395
01:15:51,420 --> 01:16:03,450
По-моему, раньше я уже говорил, что почти вся математика, которая нужна вам для глубокого обучения -

396
01:16:03,450 --> 01:16:14,050
это функции натурального логарифма и экспоненты, в глубоком обучении и машинном обучении они везде.

397
01:16:14,150 --> 01:16:33,090
Абсолютно необходимо знать, что ln(x*y) = ln(x) + ln(y),

398
01:16:33,090 --> 01:16:43,135
при этом не только знать, но и понимать, почему это так и почему может быть удобно превращать произведение в сумму.

399
01:16:43,235 --> 01:17:00,385
ln(x/y) = ln(x) - ln(y). Опять же, удобно осознавать, что вместо деления можно вычитать.

400
01:17:00,485 --> 01:17:17,860
ln(x) = y ⇔ e ^ y = x, то есть логарифм и экспонента - взаимно обратные функции.

401
01:17:17,960 --> 01:17:28,345
Если вы плохо знакомы с этими функциями, постройте их графики в Excel или Jupyter ноутбуке,

402
01:17:28,445 --> 01:17:38,260
поймите, как они выглядят, как ведут себя вместе.

403
01:17:38,260 --> 01:17:49,450
Здесь мы используем экспоненту, она всегда положительна, удобное свойство.

404
01:17:49,450 --> 01:18:03,965
Ещё одно удобное свойство - экспонента увеличивает разрыв у похожих чисел, делает различия виднее.

405
01:18:04,065 --> 01:18:07,850
Мы используем оба этих свойства.

406
01:18:07,950 --> 01:18:15,850
От каждого числа в столбце output берётся экспонента,

407
01:18:15,850 --> 01:18:28,120
полученные числа складываются,

408
01:18:32,340 --> 01:18:40,795
а потом каждое число из столбца exp делится на эту сумму.

409
01:18:40,895 --> 01:18:47,610
Так как мы делим каждое число на сумму всех чисел, полученные частные в сумме дадут единицу,

410
01:18:47,710 --> 01:19:00,815
и все числа лежат между 0 и 1, так как мы всегда делим на большее число и все числа положительные.

411
01:19:00,915 --> 01:19:04,840
Так работает Softmax.

412
01:19:04,840 --> 01:19:11,050
Я проделаю это для нескольких наборов случайных чисел, чтобы было понятнее.

413
01:19:11,050 --> 01:19:18,574
Видно, что большинство вероятностей близко к нулю, и обычно есть одна близкая к единице.

414
01:19:18,674 --> 01:19:30,710
Это происходит из-за второго свойства, экспонента увеличивает разрыв между числами.

415
01:19:30,810 --> 01:19:47,140
На входе в столбце output - случайные числа, а на выходе в столбце softmax - одно большое число и четыре маленьких.

416
01:19:47,140 --> 01:20:03,755
И это то, что нужно, потому что это позволит нам с уверенностью выделить один класс - кошка, собака, самолёт, рыба или здание.

417
01:20:03,855 --> 01:20:18,740
Итак, Softmax очень удобный - он преобразует числа в вероятности и выделяет из них самую высокую.

418
01:20:18,840 --> 01:20:22,600
Тут у кого-то вопрос.

419
01:20:22,600 --> 01:20:34,780
Вопрос из зала: Какую функцию активации использовать в задаче многотемной классификации?

420
01:20:37,600 --> 01:20:43,230
Удачно задали вопрос, именно это мы сейчас и обсудим.

421
01:20:45,419 --> 01:20:53,962
Для рассмотрения задачи многотемной классификации перейдём к ноутбуку lesson2-image_models.ipynb

422
01:20:54,062 --> 01:21:04,254
и посмотрим на соревнование Kaggle Planet: Understanding the Amazon from Space по разметке спутниковых снимков.

423
01:21:04,354 --> 01:21:10,659
Работа со спутниковыми снимками чем-то похожа на работу с изображениями кошек и собак,

424
01:21:10,759 --> 01:21:19,769
но есть различия. В задаче с кошками и собаками каждое изображение принадлежало строго одному классу.

425
01:21:19,769 --> 01:21:34,260
Здесь же каждый снимок принадлежит строго одному из четырёх классов погоды - например, туманная или ясная,

426
01:21:34,260 --> 01:21:50,999
и в придачу к этому может содержать некоторые признаки из списка, например, наличие полей, тропических лесов или реки на снимке.

427
01:21:50,999 --> 01:21:59,709
На этом изображении - ясная погода, поле, тропический лес и река,

428
01:21:59,809 --> 01:22:06,145
на этом - туманная погода и тропический лес.

429
01:22:06,245 --> 01:22:12,714
В задаче многотемной классификации изображение может принадлежать нескольким классам,

430
01:22:12,814 --> 01:22:18,669
и здесь не подойдёт функция Softmax, потому что ей не нравится предсказывать несколько вещей одновременно.

431
01:22:18,769 --> 01:22:28,079
Я рекомендую вам представлять, что у функций активаций есть характер, это помогает пониманию.

432
01:22:28,079 --> 01:22:36,939
Характер функции Softmax такой, что ей нравится выделять одно число, и люди часто об этом забывают -

433
01:22:37,039 --> 01:22:47,859
я видел, как достойные исследователи в известных изданиях использовали Softmax для задачи многотемной классификации,

434
01:22:47,959 --> 01:22:55,249
и это нелепо, потому что они не понимают характер своей функции активации.

435
01:22:55,249 --> 01:23:05,590
Модель для задачи многотемной классификации немного отличается от задачи двухклассовой классификации,

436
01:23:05,590 --> 01:23:10,330
но при использовании fast.ai вам ничего не придётся менять.

437
01:23:10,430 --> 01:23:15,940
Если в файле CSV с разметкой обучающей и валидационной выборок изображениям соответствует несколько классов,

438
01:23:21,880 --> 01:23:25,600
fast.ai автоматически переключится на режим многотемной классификации.

439
01:23:25,600 --> 01:23:32,425
Я покажу, как это устроено внутри, но в fast.ai вам не придётся делать это самим.

440
01:23:32,525 --> 01:23:45,710
Очевидно, при многотемной классификации нельзя использовать подход Keras к организации данных -

441
01:23:45,810 --> 01:24:04,050
одно изображение не может лежать в нескольких папках одновременно, поэтому используется подход с CSV.

442
01:24:08,155 --> 01:24:14,240
Давайте посмотрим, что происходит.

443
01:24:14,340 --> 01:24:18,965
Вот файл CSV с метками данных, вот функция get_data(), она точно такая же

444
01:24:19,065 --> 01:24:24,365
за исключением алгоритма дополнения данных aug_tfms=transforms_top_down (а не transforms_side_on).

445
01:24:24,465 --> 01:24:32,420
Я говорил, что этот алгоритм переворачивает изображение. Для квадратного изображения он создаёт 8 вариантов -

446
01:24:32,520 --> 01:24:37,355
изображение поворачивается на 0, 90, 180, 270 градусов и отражается зеркально.

447
01:24:37,455 --> 01:24:47,795
Если вы вдумаетесь, то поймёте, что это все возможные симметричные преобразования квадрата,

448
01:24:47,895 --> 01:24:57,070
это называется диэдральная группа D_4. В модуле transforms есть функция dihedral(), это объясняет её название.

449
01:24:57,170 --> 01:25:11,130
Этот алгоритм дополнения данных совершает 8 диэдральных преобразований и всё, что мы делали с кошками и собаками -

450
01:25:11,130 --> 01:25:19,765
небольшие вращения, увеличения, изменения яркости и контраста.

451
01:25:19,865 --> 01:25:28,440
Я выбрал размер изображений 256х256, функция get_data() и нужна для того, чтобы получать данные произвольного размера.

452
01:25:32,429 --> 01:25:45,745
Мы уже видели, что после получения данных можно изучать выборки в объектах data.val_ds , data.test_ds, data.train_ds.

453
01:25:45,845 --> 01:25:53,310
Также есть объекты data.val_dl, data.test_dl, data.train_dl - загрузчики данных (dl - data loader, ds - dataset).

454
01:25:53,310 --> 01:26:01,312
Эти термины пришли из PyTorch, можете загуглить их как "pytorch data set" или "pytorch data loader".

455
01:26:01,412 --> 01:26:10,614
Разница в том, что датасет взовращает одно изображение, а загрузчик данных - минибатч.

456
01:26:10,714 --> 01:26:25,560
Загрузчик данных возвращает уже дополненные данные - для этого мы передавали количество воркеров и алгоритм дополнения данных.

457
01:26:25,560 --> 01:26:37,260
Загрузчик данных не может вернуть одно изображение, только минибатч, при этом не определённый, а следующий в очереди.

458
01:26:37,260 --> 01:26:49,884
Для последовательного прохождения по объектам в Python используются генераторы и итераторы.

459
01:26:49,984 --> 01:27:02,550
Для того, чтобы сделать итератор из загрузчика данных, вызывается функция iter() стандартной библиотеки Python.

460
01:27:02,550 --> 01:27:18,800
Итератор выдаёт новый минибатч при использовании функции next() стандартной библиотеки Python.

461
01:27:18,800 --> 01:27:28,109
Мне нравится PyTorch тем, что он использует современные возможности Python как языка.

462
01:27:28,209 --> 01:27:34,859
В TensorFlow используются отдельные алгоритмы для всего,

463
01:27:34,959 --> 01:27:43,262
эта библиотека подходит ко многим платформам, но ни к одной не подходит идеально.

464
01:27:43,362 --> 01:27:53,960
Если вы хорошо знаете Python, то легко поймёте PyTorch. Если вы плохо знаете Python, то PyTorch - отличный повод узнать его лучше.

465
01:27:53,960 --> 01:28:05,690
Модуль PyTorch для работы с нейронными сетями, например, использует стандартные языковые средства Python.

466
01:28:08,090 --> 01:28:15,619
Итак, я использую функцию iter() для создания итератора и функцию next() для получения минибатчей из этого итератератора.

467
01:28:17,780 --> 01:28:20,960
Функция next() возвращает изображения в переменную x и их метки в переменную y,

468
01:28:20,960 --> 01:28:25,360

в Python функции могут возвращать несколько переменных.

469
01:28:25,360 --> 01:28:47,840
Вот переменная с разметкой. Я не передал размер минибатча, он равен bs=64 по умолчанию.

470
01:28:47,840 --> 01:28:54,854
Напоминаю, что комбинация Shift+Tab показыывает сигнатуру метода и значения по умолчанию.

471
01:28:54,954 --> 01:29:07,040
Размер минибатча 64, а размер массива меток - 64x17, есть 17 возможных классов.

472
01:29:07,040 --> 01:29:21,559
Давайте посмотрим на нулевой слой меток, для этого соединим два списка функцией zip() стандартной библиотеки Python.

473
01:29:21,559 --> 01:29:31,190
Команда zip() объединяет нулевой элемент первого списка с нулевым элементом второго, первый элемент - с первым и так далее.

474
01:29:31,190 --> 01:29:36,790
Видно, что нулевое изображение из валидационной выборки содержит

475
01:29:36,790 --> 01:29:44,841
поля, ясную погоду, тропические леса, участок выжженого леса, воду.

476
01:29:44,941 --> 01:29:57,099
Это многотемная классификация.

477
01:29:57,199 --> 01:30:04,105
Вернёмся к задаче многоклассовой классификации.

478
01:30:04,205 --> 01:30:15,684
PyTorch и fast.ai превращает метки файлов в унитарный код.

479
01:30:15,784 --> 01:30:29,699
Если модель решила, что на изображении собака, это будет выглядеть так.

480
01:30:29,699 --> 01:30:44,489
Вспомните конец демонстрации Отавио, где последний слой сравнивался с шаблонами букв A, B, C, D, E поэлементным умножением.

481
01:30:44,489 --> 01:30:53,440
Здесь то же самое - результаты работы полносвязного слоя (столбец output) передаются в Softmax,

482
01:30:53,540 --> 01:31:03,540
а результаты работы Softmax (столбец s) сравниваются с шаблоном в унитарном коде, столбец actuals - шаблон собаки.

483
01:31:03,540 --> 01:31:12,179
После этого поэлементно вычитаются столбцы softmax и actuals и в сумме получается значение функции потерь.

484
01:31:12,179 --> 01:31:21,320
На следующей неделе мы подробнее обсудим функцию потерь, но суть я уже сказал.

485
01:31:21,680 --> 01:31:32,340
Представление унитарным кодом выглядит очень неэффективно -

486
01:31:32,440 --> 01:31:52,515
вместо хранения массива [0,1,0,0,0] можно было бы пронумеровать все классы и хранить только номер класса.

487
01:31:52,615 --> 01:32:08,215
Так и происходило в задачах с кошками или собаками и породами собак, хранился номер класса,

488
01:32:08,315 --> 01:32:20,460
хотя внутри этот номер класса все равно преобразовывался в унитарный код.

489
01:32:20,560 --> 01:32:32,055
В PyTorch есть различные функции потерь для унитарного кода и классического представления.

490
01:32:32,155 --> 01:32:40,040
В fast.ai это спрятано и вам не нужно об этом беспокоиться.

491
01:32:40,040 --> 01:32:51,080
В задаче многотемной классификации используется то же представление унитарным кодом, что и в задаче многоклассовой классификации.

492
01:32:51,080 --> 01:33:03,420
Вопрос из зала: Стоит ли брать в Softmax логарифм с другим основанием?

493
01:33:03,520 --> 01:33:33,110
Нет, потому что log_a(b) = ln(b) / ln(a), это линейное преобразование, нейронные сети могут делать это сами.

494
01:33:35,450 --> 01:34:08,670
Вот одно из изображений. Оно очень тусклое, поэтому я умножил его на 1.4, чтобы увеличить яркость.

495
01:34:08,670 --> 01:34:19,710
Я хочу, чтобы вы привыкли к той мысли, что изображения - это матрицы чисел,

496
01:34:19,710 --> 01:34:25,360
если изображение тусклое, можно увеличить его яркость, домножив все элементы матрицы на число.

497
01:34:25,460 --> 01:34:37,105
Здесь видно участок выжженого леса, тропический лес, реку, возможно, поле.

498
01:34:37,205 --> 01:34:49,210
Для решения задачи многотемной классификации мы повторяем всё, что делали в задачах бинарной и многоклассовой классификаций.

499
01:34:49,310 --> 01:35:10,900
Этот датасет интересен тем, что не похож на изображения ImageNet, как и большинство датасетов, с которыми вы будете работать -

500
01:35:11,000 --> 01:35:25,650
медицинские снимки, снимки стальных труб для дальнейшей сортировки, спутниковые снимки.

501
01:35:25,650 --> 01:35:34,880
Полезно поэкспериментировать с таким датасетом, чтобы понять, как это работает.

502
01:35:34,980 --> 01:35:44,910
Я начинаю с размера изображений 64, хотя оригинальный размер - 256.

503
01:35:44,910 --> 01:35:57,160
Я не сделал этого для кошек и собак, потому что предобученная модель уже была почти идеальна.

504
01:35:57,260 --> 01:36:09,670
Если бы мы уменьшили изображения до размера 64 и переобучили бы все слои, то потеряли бы уже отличные предвычисленные веса,

505
01:36:09,770 --> 01:36:19,115
так как изображения ImageNet имеют размер 224 или 299, веса бы сбросились при обучении на других размерах.

506
01:36:19,215 --> 01:36:28,540
Здесь наоборот - в базе ImageNet нет спутниковых снимков,

507
01:36:28,640 --> 01:36:42,115
поэтому нам понадобятся только внутренние слои предобученных моделей, умеющие выделять края и углы,

508
01:36:42,215 --> 01:36:51,725
текстуры, повторяющиеся узоры, и, возможно, некоторые сложные объекты.

509
01:36:51,825 --> 01:37:04,920
Маленькие размеры изображений помогают в работе с нестандартными датасетами.

510
01:37:04,920 --> 01:37:17,280
Итак, я начал с размера 64, получил данные, обучил модель, нашёл оптимальную скорость обучения, она оказалась довольно высокой.

511
01:37:17,280 --> 01:37:30,390
Так как датасет не похож на изображения ImageNet, последний слой пришлось довольно долго обучать.

512
01:37:30,390 --> 01:37:38,090
После этого я разморозил слои и выставил дифференциальные скорости обучения,

513
01:37:38,090 --> 01:37:52,410
напоминаю, что они различаются в 3 раза, а не в 10, потому что датасет не похож на изображения ImageNet,

514
01:37:52,410 --> 01:38:04,620
и внутренние слои работают на любом датасете, в них нет особенностей изображений ImageNet.

515
01:38:04,620 --> 01:38:14,820
Опять же, на графике зависимости функции потерь от номера итерации видны циклы обучения.

516
01:38:14,820 --> 01:38:25,950
Затем я увеличил размер изображений до 128 и 256, обучил, разморозил, обучил.

517
01:38:25,950 --> 01:38:30,090
После всего применил дополнение тестовых данных.

518
01:38:30,090 --> 01:38:35,300
Как я уже сказал в прошлый раз, эта модель попала где-то на 30 место в рейтинге,

519
01:38:35,300 --> 01:38:46,595
что очень круто, потому что конкуренция в этом соревновании была высокая.

520
01:38:46,695 --> 01:38:55,130
У меня спрашивали, что делает метод .resize().

521
01:38:55,230 --> 01:39:12,810
При создании в загрузчик данных передается алгоритм приращения данных, а он содержит размер изображения.

522
01:39:12,810 --> 01:39:20,300
Таким образом, загрузчик данных меняет размер изображений при вызове.

523
01:39:21,510 --> 01:39:35,099
Это никак не относится к методу .resize(), это то, что происходит внутри загрузчика данных до того, как он отдаст изображения.

524
01:39:35,099 --> 01:39:51,300
Если на входе изображения размера 1000, их уменьшение до размера 64 займёт больше времени, чем обучение.

525
01:39:51,300 --> 01:40:14,070
Метод .resize() проходит по всем изображениям и уменьшает те, что больше значения sz * 1.3 по минимальной из сторон.

526
01:40:14,070 --> 01:40:25,240
Это делать не обязательно, но на больших изображениях это сэкономит много времени.

527
01:40:25,340 --> 01:40:37,641
На форумах Kaggle в таких случаях люди выкладывают свои скрипты уменьшения изображений.

528
01:40:37,741 --> 01:40:53,880
Повторюсь, это не обязательно, но иногда бывает удобно.

529
01:40:53,880 --> 01:41:19,170
Те, кому надоело соревнование про породы собак, могут начинать экспериментировать с соревнованием со спутниковыми снимками.

530
01:41:19,170 --> 01:41:32,570
Один момент, не относящийся к глубокому обучению. В качестве метрики я использую F-меру, а не долю правильных ответов.

531
01:41:33,980 --> 01:41:43,195
Вспомните матрицу ошибок с прошлой лекции, показывающую количество ошибок I и II рода.

532
01:41:43,295 --> 01:41:59,390
Есть много способов интерпретировать эту таблицу - ошибки какого важнее рода важнее и насколько.

533
01:41:59,390 --> 01:42:07,905
Один из способов - F-мера, где параметр beta показывает относительный вес ошибок I и II рода.

534
01:42:08,005 --> 01:42:25,184
Метрика называется f2, потому что значение параметра beta=2, эта метрика используется создателями соревнования.

535
01:42:25,284 --> 01:42:33,110
Вы можете создавать собственные метрики оценки качества модели.

536
01:42:33,110 --> 01:42:47,270
Строка "from planet import f2" значит, что функция f2 описана в модуле planet рабочей директории Jupyter ноутбука.

537
01:42:47,270 --> 01:43:13,400
В planet.py можно посмотреть на код этой функции, она использует функцию F-меры fbeta_score() из библиотеки scikit-learn.

538
01:43:13,400 --> 01:43:25,970
Вы можете написать метрику сами, она должна принимать на вход предсказания и действительные значения

539
01:43:25,970 --> 01:43:30,530
в виде одномерных массивов numpy и возвращать число.

540
01:43:33,380 --> 01:43:44,290
Любая функция, принимающая два вектора и возвращающая число, может быть метрикой.

541
01:43:46,710 --> 01:44:00,580
Эта метрика потом передаётся в метод ConvLearner.pretrained() и будет вычисляться каждую эпоху.

542
01:44:00,580 --> 01:44:22,445
Библиотека fast.ai очень гибкая - она даёт неплохие параметры по умолчанию, но их везде можно заменить своими.

543
01:44:22,545 --> 01:44:42,560
Янет: Вы обещали показать функцию активации для задачи многотемной классификации.

544
01:44:42,660 --> 01:44:47,080
Да, простите, забыл, сейчас.

545
01:44:47,080 --> 01:44:58,390
Итак, мы использовали функцию Softmax в задаче многоклассовой классификации, но в задаче многотемной классификации

546
01:44:58,390 --> 01:45:14,980
она не подойдёт, так как в Softmax все вероятности в сумме дают единицу и невозможно получить две высоких вероятности одновременно.

547
01:45:15,080 --> 01:45:19,690
Для задачи многотемной классификации в качестве функции активации используется сигмоида.

548
01:45:23,650 --> 01:45:37,490
Напомню, что fast.ai автоматически выбирает подходящую функцию активации по вашим данным.

549
01:45:37,590 --> 01:46:00,094
Сигмоида тоже использует экспоненту, но слегка иначе: y = exp(x) / (1 + exp(x)), где x - значения столбца output, y - столбца sigmoid.

550
01:46:00,194 --> 01:46:15,439
Это удобно тем, что в итоге может получиться несколько высоких значений.

551
01:46:15,439 --> 01:46:26,300
Сигмоида от отрицательных чисел даёт результат между 0 и 0.5, от положительных - между 0.5 и 1.

552
01:46:26,300 --> 01:46:49,604
Она выглядит так, у неё две асимптоты - 0 и 1, удобно для вероятностей.

553
01:46:49,704 --> 01:47:07,144
Сигмоида знакома всем, кто хоть раз строил логистическую регрессию, она очень важна для машинного обучения.

554
01:47:07,244 --> 01:47:19,869
Сигмоида и Softmax очень похожи, но сигмоида хороша для многотемной классификации, а Softmax - для многоклассовой.

555
01:47:19,869 --> 01:47:22,659
Библиотека fast.ai сама подберёт необходимую функцию активации.

556
01:47:22,659 --> 01:47:28,309
Вопрос?

557
01:47:28,409 --> 01:47:46,904
Вопрос из зала: В начале обучения мы замораживаем всю модель и обучаем только последний слой, так?

558
01:47:47,004 --> 01:48:02,904
Вопрос из зала: Но вы говорили, что нам важны только первые слои, а на последних - ненужные веса.

559
01:48:03,004 --> 01:48:16,210
Последние слои важны, предобученные веса на них - нет, поэтому важно тренировать именно последние слои.

560
01:48:16,210 --> 01:48:23,769
Первые слои, скорее всего, уже достаточно хороши.

561
01:48:23,769 --> 01:48:46,589
При создании модели заморожены предобученные свёрточные слои и разморожены полносвязные слои со случайными весами.

562
01:48:46,689 --> 01:48:58,544
При первом обучении обучаются только полносвязные случайные веса, и на датасетах, подобных ImageNet,

563
01:48:58,644 --> 01:49:12,555
этого зачастую достаточно, потому что предобученные слои уже умеют различать края, градиенты, собачьи уши и головы.

564
01:49:12,655 --> 01:49:25,565
После разморозки мы выставляем внутренним слоям более низкие скорости обучения, потому что не хотим их испортить.

565
01:49:25,665 --> 01:49:31,430
Для спутниковых снимков это не совсем так.

566
01:49:31,530 --> 01:49:40,025
Внутренние слои полезнее внешних, но их все равно нужно достаточно сильно изменить,

567
01:49:40,125 --> 01:49:52,150
поэтому скорости обучения внешних и внутренних слоёв различаются в 9 раз, а не в 1000.

568
01:49:52,150 --> 01:49:56,134
Вопрос из зала: И вы просто подбираете эти веса?

569
01:49:56,234 --> 01:50:03,989
Да. Большинство источников в интернете предлагают размораживать отдельные группы слоёв,

570
01:50:07,300 --> 01:50:18,250
и в библиотеке fast.ai это можно сделать методом .freeze_to(),

571
01:50:18,250 --> 01:50:28,179
но я считаю, что использовать дифференциальные скорости обучения гораздо удобнее.

572
01:50:28,179 --> 01:50:40,270
Вопрос из зала: Почему бы сразу с этого не начинать?

573
01:50:40,270 --> 01:50:53,890
Да, можно пропустить первый этап обучения и сразу разморозить модель, но я бы не стал, вот почему.

574
01:50:53,890 --> 01:51:03,050
Свёрточные слои содержат предвычисленные веса, это не случайные числа,

575
01:51:03,150 --> 01:51:11,170
эти веса хороши для изображений, похожих на изображения ImageNet, и лучше, чем ничего - для непохожих.

576
01:51:11,270 --> 01:51:24,050
Все полносвязные слои же содержат случайные веса, поэтому имеет смысл сначала обучить их на том, что есть.

577
01:51:24,050 --> 01:51:37,256
В противном случае при разморозке в последних слоях будут случайные числа и это может испортить первые слои.

578
01:51:37,356 --> 01:51:54,349
Вопрос из зала: Что меняется при обучении свёрточных слоёв? Свёрточные ядра?

579
01:51:54,349 --> 01:52:26,985
Да, при обучении меняются только вот эти числа, они называются веса - веса полносвязных слоёв и веса свёрточных фильтров.

580
01:52:27,085 --> 01:52:32,190
Мы ещё обсудим, как это делается с помощью стохастического градиентного спуска.

581
01:52:32,290 --> 01:52:45,239
Эти числа - активации, они вычисляются с помощью весов и активаций предыдущего слоя.

582
01:52:45,339 --> 01:53:05,966
Вопрос из зала: Когда вы начинаете обучение с изображений маленького размера, например, 64х64, как они уменьшаются?

583
01:53:06,066 --> 01:53:13,489
Это зависит от параметров, но по умолчанию

584
01:53:18,019 --> 01:53:30,004
изображение уменьшается, пока наименьшая сторона не станет равной 64, потом из центра вырезается квадрат.

585
01:53:30,104 --> 01:53:36,769
Если включено дополнение данных, квадрат вырезается не из центра, а случайно.

586
01:53:36,869 --> 01:53:50,170
Вопрос из зала: Не потеряются ли какие-то объекты в процессе обрезки в задаче многотемной классификации?

587
01:53:50,170 --> 01:53:59,289
Нет. Именно поэтому мы и используем дополнение данных, особенно дополнение тестовых данных.

588
01:53:59,289 --> 01:54:13,129
В углу спутникового снимка может быть шахта, которая не попадает в центральный квадрат, а мы сможем её увидеть.

589
01:54:13,229 --> 01:54:22,095
Вопрос из зала: Метрика и функция потерь используют разные функции?

590
01:54:22,195 --> 01:54:32,740
Да, функцию потерь мы обсудим на следующей неделе, она использует функцию перекрёстной энтропии.

591
01:54:32,840 --> 01:54:43,114
Метрика - просто число, выводящееся при обучении модели для отслеживания прогресса.

592
01:54:43,214 --> 01:55:04,030
Вопрос из зала: Могу ли я использовать модель, обученную различать кошек и собак, выявлять на изображении и кошку, и собаку?

593
01:55:04,030 --> 01:55:14,949
Я никогда этого не пробовал и не видел примеров, но не вижу этому препятствий.

594
01:55:14,949 --> 01:55:20,131
Да, в качестве функции активации надо взять сигмоиду.

595
01:55:20,231 --> 01:55:31,230
По умолчанию fast.ai поставит Softmax, укажите в параметрах, чтобы использовалась сигмоида.

596
01:55:35,349 --> 01:55:43,589
Вопрос из зала: Дифференциальные скорости обучения равномерно распределены по слоям?

597
01:55:43,689 --> 01:55:51,836
Мы ещё обсудим это, если вкратце - в библиотеке fast.ai есть понятие групп слоёв.

598
01:55:51,936 --> 01:56:03,679
В ResNet50 сотни слоёв, задавать сотни скоростей обучения неудобно, поэтому я придумал разбиение на группы.

599
01:56:03,679 --> 01:56:12,524
Последняя группа всегда состоит из полносвязных слоёв, которые мы заполняли случайными числами при создании модели.

600
01:56:12,624 --> 01:56:17,249
Другие две группы содержат примерно по половине оставшихся слоёв,

601
01:56:17,349 --> 01:56:26,630
я старался разбить их на группу слоёв, которые не стоит менять, и группу слоёв, которые можно немного изменить.

602
01:56:26,630 --> 01:56:36,314
В курсе этого не будет, но вы можете обсудить это на форуме - можно менять эту архитектуру и создавать свои группы слоёв.

603
01:56:36,414 --> 01:56:43,999
Вопрос из зала: Есть какой-то способ визуализировать модель?

604
01:56:43,999 --> 01:57:02,479
Да, методом .summary().

605
01:57:02,479 --> 01:57:09,590


606
01:57:09,590 --> 01:57:14,419
Здесь все слои и их названия, о которых я говорил раньше.

607
01:57:14,419 --> 01:57:30,135
Первый слой Conv2d-1 принимает изображения размера 64x64 с тремя цветовыми каналами.

608
01:57:30,235 --> 01:57:38,449
Обычно используют массивы 64x64x3, но в PyTorch используют массивы 3x64x64,

609
01:57:41,869 --> 01:57:53,530
некоторые вычисления GPU ускоряются при таком формате, это происходит при подготовке данных.

610
01:57:53,630 --> 01:58:10,305
-1 значит "использовать максимальный размер минибатча", в Keras для этого используется None, в PyTorch - -1.

611
01:58:10,405 --> 01:58:23,660
Итак, это четырёхмерный минибатч - его размер, количество каналов - 3, размер изображений - 64x64.

612
01:58:23,660 --> 01:58:35,240
Этот свёрточный фильтр содержит 64 ядра и уменьшает изображения до размера 32х32 -

613
01:58:35,240 --> 01:58:43,485
у свёрточных слоёв есть характеристика шаг, она позволяет уменьшать размер, как подвыборка максимумом.

614
01:58:43,585 --> 01:58:47,870
Итак, на выходе слоя - тензор 64x32x32.

615
01:58:47,870 --> 01:58:57,375
Мы ещё обсудим это во второй части курса.

616
01:58:57,475 --> 01:59:18,260
Вопрос из зала: Я пробовал обучать модель на крошечном датасете и алгоритм поиска скорости обучения нарисовал мне пустой график.

617
01:59:18,260 --> 01:59:24,630
Давайте обсудим это на форуме, если вкратце - алгоритм поиска скорости обучения проходит один минибатч за одну итерацию,

618
01:59:24,730 --> 01:59:35,530
и, если датасет очень маленький, минибатчей может просто не хватить. Попробуйте поставить размер минибатча, например, 4.

619
01:59:38,250 --> 01:59:48,160
Окей, вопросы были отличные, хоть мы и немного припозднились.

620
01:59:48,160 --> 01:59:52,690


621
01:59:52,690 --> 02:00:02,500


622
02:00:02,500 --> 02:00:10,300


623
02:00:10,300 --> 02:00:16,600


624
02:00:16,600 --> 02:00:21,850


625
02:00:21,850 --> 02:00:30,130


626
02:00:30,130 --> 02:00:37,199


627
02:00:39,960 --> 02:00:45,520


628
02:00:45,520 --> 02:00:49,449


629
02:00:51,550 --> 02:00:57,940


630
02:01:00,480 --> 02:01:05,489


631
02:01:05,489 --> 02:01:11,770


632
02:01:11,770 --> 02:01:16,210


633
02:01:16,210 --> 02:01:21,840


634
02:01:21,840 --> 02:01:31,199


635
02:01:34,810 --> 02:01:39,730


636
02:01:41,590 --> 02:01:46,179


637
02:01:46,179 --> 02:01:49,719


638
02:01:49,719 --> 02:01:55,880


639
02:01:55,880 --> 02:02:01,309


640
02:02:01,309 --> 02:02:05,749


641
02:02:05,749 --> 02:02:10,070


642
02:02:10,070 --> 02:02:14,780


643
02:02:14,780 --> 02:02:21,130


644
02:02:21,399 --> 02:02:26,360


645
02:02:28,099 --> 02:02:32,659


646
02:02:35,989 --> 02:02:40,099


647
02:02:40,099 --> 02:02:50,539


648
02:02:50,539 --> 02:02:53,780


649
02:02:53,780 --> 02:02:58,579


650
02:02:58,579 --> 02:03:03,320


651
02:03:03,320 --> 02:03:10,130


652
02:03:10,130 --> 02:03:15,769


653
02:03:15,769 --> 02:03:19,849


654
02:03:19,849 --> 02:03:24,369


655
02:03:29,059 --> 02:03:34,639


656
02:03:34,639 --> 02:03:40,189


657
02:03:40,189 --> 02:03:45,289


658
02:03:48,889 --> 02:03:52,849


659
02:03:52,849 --> 02:03:57,769


660
02:03:57,769 --> 02:04:04,010


661
02:04:04,010 --> 02:04:09,560


662
02:04:09,560 --> 02:04:14,600


663
02:04:14,600 --> 02:04:18,950


664
02:04:20,600 --> 02:04:25,000


665
02:04:25,000 --> 02:04:30,230


666
02:04:30,230 --> 02:04:36,080


667
02:04:36,080 --> 02:04:41,630


668
02:04:41,630 --> 02:04:49,100


669
02:04:49,100 --> 02:04:54,710


670
02:04:54,710 --> 02:04:59,240


671
02:04:59,240 --> 02:05:08,240


672
02:05:08,240 --> 02:05:13,690


673
02:05:14,730 --> 02:05:18,020


674
02:05:18,020 --> 02:05:24,920


675
02:05:24,920 --> 02:05:30,619


676
02:05:30,619 --> 02:05:37,340


677
02:05:37,340 --> 02:05:45,940


678
02:05:48,949 --> 02:05:54,980


679
02:05:54,980 --> 02:05:59,030


680
02:05:59,030 --> 02:06:06,710


681
02:06:06,710 --> 02:06:10,610


682
02:06:10,610 --> 02:06:15,500


683
02:06:15,500 --> 02:06:19,579


684
02:06:19,579 --> 02:06:24,409


685
02:06:24,409 --> 02:06:36,159


686
02:06:36,159 --> 02:06:44,150


687
02:06:44,150 --> 02:06:49,820


688
02:06:49,820 --> 02:06:55,639


689
02:06:55,639 --> 02:07:03,710


690
02:07:03,710 --> 02:07:08,780


691
02:07:08,780 --> 02:07:12,440


692
02:07:12,440 --> 02:07:16,880


693
02:07:16,880 --> 02:07:23,030


694
02:07:23,030 --> 02:07:28,460


695
02:07:28,460 --> 02:07:30,840


696
02:07:30,840 --> 02:07:34,469


697
02:07:34,469 --> 02:07:41,520


698
02:07:41,520 --> 02:07:48,780


699
02:07:50,909 --> 02:08:04,190


700
02:08:05,400 --> 02:08:12,270


701
02:08:12,270 --> 02:08:19,860


702
02:08:23,429 --> 02:08:26,510


703
02:08:29,940 --> 02:08:38,320


704
02:08:38,320 --> 02:08:43,360


705
02:08:43,360 --> 02:08:47,410


706
02:08:47,410 --> 02:08:51,760


707
02:08:51,760 --> 02:08:54,550


708
02:08:54,550 --> 02:08:59,740


709
02:08:59,740 --> 02:09:03,400


710
02:09:03,400 --> 02:09:10,210


711
02:09:10,210 --> 02:09:12,930


712
02:09:13,989 --> 02:09:19,239


713
02:09:19,239 --> 02:09:31,120


714
02:09:31,120 --> 02:09:35,380


715
02:09:35,380 --> 02:09:40,540


716
02:09:40,540 --> 02:09:44,380


717
02:09:44,380 --> 02:09:48,520


718
02:09:48,520 --> 02:09:55,180


719
02:09:55,180 --> 02:09:59,430


720
02:09:59,430 --> 02:10:05,760


721
02:10:09,250 --> 02:10:20,710


722
02:10:20,710 --> 02:10:24,430


723
02:10:24,430 --> 02:10:30,130


724
02:10:30,130 --> 02:10:35,530


725
02:10:35,530 --> 02:10:38,920


726
02:10:38,920 --> 02:10:43,780


727
02:10:43,780 --> 02:10:46,360


728
02:10:46,360 --> 02:10:49,380


729
02:10:49,380 --> 02:10:59,530


730
02:10:59,530 --> 02:11:04,300


731
02:11:04,300 --> 02:11:07,630


732
02:11:07,630 --> 02:11:12,970


733
02:11:12,970 --> 02:11:18,460


734
02:11:18,460 --> 02:11:22,020


735
02:11:22,740 --> 02:11:26,800


736
02:11:26,800 --> 02:11:29,950


737
02:11:29,950 --> 02:11:37,930


738
02:11:37,930 --> 02:11:42,940


739
02:11:45,130 --> 02:11:52,180


740
02:11:52,180 --> 02:11:57,630


741
02:11:57,630 --> 02:12:01,300


742
02:12:01,300 --> 02:12:05,800


743
02:12:05,800 --> 02:12:11,170


744
02:12:11,170 --> 02:12:16,420


745
02:12:16,420 --> 02:12:20,770


746
02:12:20,770 --> 02:12:26,410


747
02:12:28,420 --> 02:12:32,410


748
02:12:32,410 --> 02:12:37,540


749
02:12:37,540 --> 02:12:40,540


750
02:12:40,540 --> 02:12:45,400


751
02:12:45,400 --> 02:12:50,650


752
02:12:50,650 --> 02:12:57,580


753
02:12:57,580 --> 02:13:01,690


754
02:13:01,690 --> 02:13:09,400


755
02:13:09,400 --> 02:13:18,510


756
02:13:18,510 --> 02:13:25,780


757
02:13:28,990 --> 02:13:36,160


758
02:13:36,160 --> 02:13:40,900


759
02:13:40,900 --> 02:13:48,640


760
02:13:48,640 --> 02:13:52,300


761
02:13:52,300 --> 02:13:58,480


762
02:14:01,390 --> 02:14:08,050


763
02:14:08,050 --> 02:14:13,150


764
02:14:15,490 --> 02:14:20,620


765
02:14:20,620 --> 02:14:26,170


766
02:14:26,170 --> 02:14:29,770


767
02:14:29,770 --> 02:14:34,039


768
02:14:35,839 --> 02:14:43,609


769
02:14:43,609 --> 02:14:49,849


770
02:14:49,849 --> 02:14:53,419


771
02:14:53,419 --> 02:14:58,669


772
02:14:58,669 --> 02:15:02,899


773
02:15:02,899 --> 02:15:09,109


774
02:15:09,109 --> 02:15:13,780


775
02:15:17,689 --> 02:15:23,659


776
02:15:26,359 --> 02:15:33,019


777
02:15:33,019 --> 02:15:39,079


778
02:15:40,339 --> 02:15:47,479


779
02:15:47,479 --> 02:15:53,030


780
02:15:59,030 --> 02:16:05,869


781
02:16:05,869 --> 02:16:11,030


782
02:16:11,030 --> 02:16:17,059


783
02:16:17,059 --> 02:16:19,879


784
02:16:19,879 --> 02:16:24,619


785
02:16:24,619 --> 02:16:28,869


786
02:16:28,869 --> 02:16:34,119


