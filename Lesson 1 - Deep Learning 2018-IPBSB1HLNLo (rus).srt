1
00:00:00,489 --> 00:00:04,799
Добро пожаловать на курс глубокого обучения на практике для программистов.

2
00:00:04,799 --> 00:00:09,209
Это первая часть нашего курса, состоящего из двух частей.

3
00:00:11,110 --> 00:00:14,040
Я открываю этот курс из Института Данных в Сан Франциско.

4
00:00:16,119 --> 00:00:24,389
В этой части курса семь лекций, большинство из них длится около двух часов, эта первая лекция чуть короче.

5
00:00:26,769 --> 00:00:34,229
Наш курс введет вас в глубокое обучение на практике для получения результатов мирового класса,

6
00:00:34,660 --> 00:00:38,399
и, как предполагает название, мы сконцентрируемся на программировании.

7
00:00:38,530 --> 00:00:49,649
Но мы не собираемся упрощать. К концу курса вы изучите всю необходимую для воспроизведения результатов мирового класса теорию. Мы начнем с нуля.

8
00:00:50,829 --> 00:01:09,059
Наши видео размещены на YouTube, но мы рекомендуем смотреть их на нашем веб-сайте course.fast.ai — видео те же самые, но на нашем сайте также есть информация

9
00:01:09,340 --> 00:01:17,758
об обновлениях к библиотекам, которые вам понадобятся, дальнейшие инструкции, часто задаваемые вопросы и прочее.

10
00:01:18,640 --> 00:01:23,519
Поэтому, если вы сейчас смотрите это видео на YouTube - вы можете переключиться на course.fast.ai

11
00:01:23,740 --> 00:01:31,469
и начать смотреть там, убедившись, что вы прочитали все материалы на странице и у вас есть всё, что нужно.

12
00:01:33,220 --> 00:01:39,029
На forums.fast.ai сильное сообщество.

13
00:01:41,380 --> 00:01:58,169
Иногда вы можете не понимать, почему что-то работает определенным образом, или утыкаться в проблемы со своим компьютером, или еще что-нибудь.

14
00:01:58,479 --> 00:02:06,059
На forums.fast.ai — тысячи людей, проходящих курс вместе с вами, обсуждающих лекции и многие другие темы.

15
00:02:06,310 --> 00:02:12,360
Сейчас это самое активное сообщество по глубокому обучению в интернете — обязательно зарегистрируйтесь.

16
00:02:12,930 --> 00:02:16,890
И участвуйте в обсуждениях — так вы получите гораздо больше от курса.

17
00:02:19,689 --> 00:02:29,189
Итак, давайте начнём с написания кода. Существует подход к обучению "сверху вниз", мы обсудим его немного позже,

18
00:02:30,010 --> 00:02:36,420
но начнём применять уже сейчас. Давайте попробуем обучить нейронную сеть.

19
00:02:37,090 --> 00:02:42,149
Для того, чтобы тренировать нейронную сеть, в большинстве случаев необходим графический процессор.

20
00:02:42,849 --> 00:02:53,220
Графический процессор (GPU) — это устройство, которое компании используют, чтобы помочь вам играть в компьютерные игры.

21
00:02:54,459 --> 00:02:59,608
GPU помогают вашим компьютерам отрисовывать графику в играх гораздо быстрее, чем центральный процессор.

22
00:03:00,609 --> 00:03:07,199
Немного позже мы ещё обсудим графические процессоры, а сейчас я хочу показать, как вы можете получить доступ к выделенному GPU.

23
00:03:09,010 --> 00:03:16,260
Нам понадобятся графические процессоры от NVIDIA, потому что только они поддерживают CUDA.

24
00:03:16,690 --> 00:03:25,199
CUDA — это язык и фреймворк, который используют почти все библиотеки и практические проекты в глубоком обучении.

25
00:03:26,829 --> 00:03:35,849
Сейчас на рынке мало аналогов NVIDIA GPU, это плохо, в будущем хочется улучшения этой ситуации. Пока мы используем NVIDIA GPU.

26
00:03:37,090 --> 00:03:43,139
Скорее всего, на вашем ноутбуке такого нет — если, конечно, вы не покупали специальный игровой ноутбук.

27
00:03:44,889 --> 00:03:57,839
Поэтому, скорее всего, вам понадобится арендовать GPU. У нас есть хорошие новости — аренда GPU относительно простая и дешёвая

28
00:03:58,569 --> 00:04:09,239
Я покажу вам пару вариантов. Первый из этих вариантов, вероятно, самый простой, называется Crestle.

29
00:04:09,879 --> 00:04:20,038
Если вы зайдете на crestle.com и нажмете на Зарегистрироваться/Войти, то увидите на экране что-то вроде этого.

30
00:04:20,229 --> 00:04:29,429
Здесь есть большая кнопка Запустить Jupyter и тумблер Включить GPU. Перед запуском убедимся, что тумблер включен,

31
00:04:29,560 --> 00:04:40,619
нажмём на кнопку и увидим, что запустился Jupyter ноутбук.

32
00:04:41,139 --> 00:04:50,730
Jupyter ноутбуки в недавнем опросе были названы третьим по важности инструментом для анализа данных.

33
00:04:51,190 --> 00:04:55,799
Очень важно, чтобы вы смогли разобраться с ними, потому что все наши курсы используют Jupyter ноутбуки.

34
00:04:56,320 --> 00:04:58,260
Да, Рейчел?

35
00:04:58,260 --> 00:05:04,439
Рейчел: Я просто хотела уточнить, что у Crestle есть пробный период 10 часов, поэтому вам не придётся платить сразу.

36
00:05:08,530 --> 00:05:14,250
Да, количество бесплатных часов могло измениться, вы можете проверить это на сайте, но какое-то количество точно есть.

37
00:05:15,190 --> 00:05:21,719
Сейчас цена может быть другой, это зависит от цен на веб-сервисы Amazon, но на текущий момент это 60 центов в час.

38
00:05:23,080 --> 00:05:31,979
Приятно, что можно менять настройки и запускать ноутбук без GPU и платить в десять раз меньше.

39
00:05:34,229 --> 00:05:39,149
Мы будем использовать Jupyter ноутбуки на протяжении всего курса. Чтобы начать,

40
00:05:39,150 --> 00:05:49,450
мы найдём папку нашего курса. Перейдем в папку courses, затем переходим в папку fastai2, и вот мы на месте.

41
00:05:49,450 --> 00:05:53,399
Структура файлов может незначительно меняться со временем,

42
00:05:54,039 --> 00:05:57,719
мы будем выкладывать информацию об обновлениях на нашем сайте.

43
00:05:59,590 --> 00:06:03,510
Это была демонстрация первого варианта аренды GPU, Crestle.

44
00:06:04,360 --> 00:06:08,039
Как вы видите, всё происходит мгновенно и выглядит просто,

45
00:06:09,460 --> 00:06:18,660
но если у вас есть лишний час на то, чтобы обустроиться, есть вариант лучше - Paperspace.

46
00:06:22,690 --> 00:06:27,809
Paperspace, в отличие от Crestle, не базируется на сервисах Amazon. У них свои собственные машины.

47
00:06:32,889 --> 00:06:38,429
Если я зайду на их сайт и нажму на кнопку Новая машина,

48
00:06:39,459 --> 00:06:45,299
я смогу выбрать один из трёх датацентров. Предпочтительнее выбирать ближайший, поэтому я выберу Западное побережье,

49
00:06:46,569 --> 00:06:50,549
Linux, Ubuntu 16.

50
00:06:52,269 --> 00:07:00,279
Затем мы переходим на страницу выбора машины, здесь много опций. Оплата производится почасово,

51
00:07:00,279 --> 00:07:06,898
есть хорошая опция за 40 центов в час, это дешевле, чем Crestle,

52
00:07:06,899 --> 00:07:14,099
и быстрее. Машина за 65 центов в час будет гораздо быстрее Crestle.

53
00:07:14,499 --> 00:07:24,658
Я покажу пошагово, как начать работать с Paperspace, потому что здесь всё создается с нуля.

54
00:07:25,419 --> 00:07:32,549
Если вы закажете машину за 65 центов, возможно, вам придётся написать в Paperspace и объяснить, зачем она вам нужна —

55
00:07:32,860 --> 00:07:38,429
так компания защищается от мошенников. Если вы скажете, что вам нужны вычислительные мощности для разработки ИИ,

56
00:07:39,339 --> 00:07:45,389
они предоставят вам машину. Я возьму самую дешёвую опцию за 40 центов в час.

57
00:07:48,939 --> 00:07:51,689
Можно выбрать необходимое количество места на жёстком диске.

58
00:07:52,749 --> 00:07:57,449
Тут надо осторожнее - оплата за месяц снимается сразу при поднятии машины,

59
00:07:57,449 --> 00:08:01,378
поэтому не стоит запускать и сразу останавливать машины, потому что каждый раз снимается плата за месяц.

60
00:08:01,990 --> 00:08:09,569
Опция "250 ГБ за $7" выглядит неплохо, но нам понадобится только 50 ГБ, если хотите сэкономить, берите эту опцию.

61
00:08:11,649 --> 00:08:17,549
Последняя вещь, которую нужно будет сделать - включить публичный IP адрес, чтобы иметь доступ к машине.

62
00:08:17,919 --> 00:08:21,718
Можно отключить опцию Snapshot, чтобы сэкономить на бэкапах.

63
00:08:27,950 --> 00:08:33,970
Если нажать кнопку Создать Paperspace, где-то через минуту

64
00:08:35,360 --> 00:08:40,390
появится ваша машина, здесь видно мою машину Ubuntu 16.04.

65
00:08:41,810 --> 00:08:54,370
На вашу почту отправлен пароль, его можно скопировать, перейти к машине и ввести его, чтобы залогиниться.

66
00:08:54,950 --> 00:09:01,960
Чтобы вставить пароль, вам понадобится нажать Ctrl+Shift+V или Command+Shift+V на компьютерах Apple.

67
00:09:03,170 --> 00:09:07,479
Это слегка отличается от обычной вставки. Конечно, вы можете просто перепечатать пароль.

68
00:09:10,550 --> 00:09:17,750
У нас есть доступ к машине. Можно увеличить рабочее пространство, щелкнув на стрелочки.

69
00:09:17,750 --> 00:09:26,020
Как видите, у нас есть терминал внутри браузера, довольно удобно.

70
00:09:26,170 --> 00:09:32,979
Теперь нужно настроить машину, чтобы работать с нашим курсом. Для этого нужно ввести

71
00:09:34,790 --> 00:09:49,670
curl https://files.fast.ai/setup/paperspace | bash

72
00:09:49,670 --> 00:09:56,560
Это запустит скрипт, который установит необходимые CUDA драйвера,

73
00:09:58,160 --> 00:10:06,460
Anaconda — используемый нами дистрибутив Python, все необходимые библиотеки, другие курсы

74
00:10:07,100 --> 00:10:14,950
и данные, которые понадобятся для первой части курса. Это займёт около часа,

75
00:10:15,290 --> 00:10:17,560
после установки нужно перезагрузить машину.

76
00:10:18,170 --> 00:10:24,219
Для того, чтобы перезапустить машину Paperspace, нужно нажать на кнопку перезагрузки.

77
00:10:24,620 --> 00:10:30,969
Когда машина перезагрузится, на ней появятся

78
00:10:32,870 --> 00:10:35,710
директория anaconda3, здесь лежит ваш Python,

79
00:10:35,710 --> 00:10:44,629
директория data с данными для первой части курса, здесь данные для первой лекции - директория dogscats,

80
00:10:45,269 --> 00:10:52,369
и директория fastai, которая содержит всё необходимое для курса.

81
00:10:52,920 --> 00:10:57,050
Вам нужно перейти в папку fastai командой cd fastai.

82
00:10:57,389 --> 00:11:05,990
Периодически нужно делать git pull, чтобы убедиться, что все файлы внутри этой папки свежие.

83
00:11:06,480 --> 00:11:10,759
Еще нужно иногда проверять, что на машине стоят последние версии используемых библиотек —

84
00:11:10,769 --> 00:11:15,980
это можно сделать командой conda env update.

85
00:11:16,050 --> 00:11:24,679
Окей, убедитесь, что вы находитесь в папке fastai и выполните команду jupyter notebook.

86
00:11:26,910 --> 00:11:31,249
Jupyter ноутбук запущен на сервере.

87
00:11:31,249 --> 00:11:36,289
Теперь мы хотим к нему подключиться. Сервер подсказывает нам строку подключения.

88
00:11:37,350 --> 00:11:48,230
Если щёлкнуть по строке дважды, она скопируется в буфер обмена.

89
00:11:48,689 --> 00:11:52,879
Теперь можно вставить её, но перед этим нужно поменять localhost

90
00:11:53,730 --> 00:12:01,429
на IP адрес машины в Paperspace, его можно увидеть, уменьшив экран.

91
00:12:02,009 --> 00:12:16,369
Копируем и вставляем вместо слова localhost. Мы подключились к ноутбуку.

92
00:12:16,529 --> 00:12:23,269
Мы находимся внутри репозитория fastai, все курсы находятся в папке courses.

93
00:12:23,939 --> 00:12:27,349
Первая часть нашего курса лежит в папке dl1,

94
00:12:28,170 --> 00:12:34,100
В ней лежит Jupyter ноутбук по первой лекции, lesson1.ipynb.

95
00:12:39,410 --> 00:12:45,459
Итак, у вас запущен Jupyter ноутбук, неважно, через Crestle или через Paperspace.

96
00:12:45,460 --> 00:12:51,100
На courses.fast.ai я буду выкладывать дополнительные видео и информацию про другие способы

97
00:12:51,650 --> 00:12:55,930
запустить Jupyter ноутбук на арендованном сервере.

98
00:12:57,500 --> 00:13:06,130
Чтобы запустить ячейку в Jupyter ноутбуке, нужно выбрать эту ячейку и нажать Shift+Enter,

99
00:13:06,740 --> 00:13:14,290
или, если у вас включена панель инструментов, нажать кнопку запуска.

100
00:13:15,080 --> 00:13:22,869
Некоторые ячейки содержат код, некоторые — тест, изображения, видео. Как видите, Jupyter ноутбук —

101
00:13:23,870 --> 00:13:36,400
среда окружения, позволяющая проводить эксперименты и сразу видеть результаты,
поэтому она так популярна.

102
00:13:36,920 --> 00:13:42,550
Анализ данных по сути заключается в том, чтобы проводить эксперименты над данными.

103
00:13:44,090 --> 00:13:53,259
При запуске ячейки индикатор меняется на звёздочку при выполнении и показывает номер ячейки после выполнения.

104
00:13:53,260 --> 00:14:06,639
То же самое можно выполнить нажатием Shift+Enter. Можно продолжить нажимать ту же комбинацию и ячейки будут выполняться последовательно.

105
00:14:06,830 --> 00:14:15,220
В ячейке можно выполнить любую команду - например, 1+1 равняется 2.

106
00:14:15,560 --> 00:14:17,739
Итак, мы собираемся...

107
00:14:18,590 --> 00:14:24,849
Да, Рейчел? Рейчел: Хочу уточнить, что мы используем Python 3.

108
00:14:24,850 --> 00:14:37,540
Да, спасибо. Мы используем Python 3 и нужно переключиться на него с Python 2, если вы этого ещё не сделали. Это требуется в нашем курсе, но

109
00:14:38,660 --> 00:14:44,080
и в принципе многие библиотеки перестают поддерживать Python 2.

110
00:14:45,440 --> 00:14:47,440
Спасибо, Рейчел.

111
00:14:48,499 --> 00:14:53,988
В ноутбуке написано, откуда вы можете скачать данные для этой лекции.

112
00:14:55,379 --> 00:15:03,709
Если вы использовали Crestle или Paperspace, эти данные уже доступны и их не надо скачивать.

113
00:15:03,709 --> 00:15:06,138
В противном случае скачайте их, используя команду wget.

114
00:15:07,169 --> 00:15:17,639
Crestle медленнее Paperspace и поддерживает не все нужные нам библиотеки,

115
00:15:17,639 --> 00:15:23,718
поэтому при использовании Crestle вам нужно будет исполнить ещё две ячейки.

116
00:15:24,029 --> 00:15:31,480
Видно, что строки в ячейках закомментированы, перед выполнением нужно их откомментировать.

117
00:15:31,680 --> 00:15:37,220
Я использую Paperspace, поэтому не буду этого делать.

118
00:15:38,640 --> 00:15:47,928
Итак, мы видим переменную окружения {PATH}, её значение равно data/dogscats/.

119
00:15:47,929 --> 00:15:52,579
Эта переменная была создана для вас. Я использую восклицательный знак, чтобы

120
00:15:53,849 --> 00:16:00,139
показать, что эта ячейка должна исполнять не Python, а bash.

121
00:16:00,139 --> 00:16:04,938
Я хочу запустить shell, исполнить команду на bash. Внутри фигурных скобок —

122
00:16:05,759 --> 00:16:11,058
переменная Python, которая вставляется в команду bash.

123
00:16:11,339 --> 00:16:13,848
Что внутри нашей рабочей директории?

124
00:16:14,099 --> 00:16:21,079
Обучающая выборка и валидационная выборка. Если вам незнакомы эти термины,

125
00:16:21,539 --> 00:16:27,079
ознакомьтесь с нашим практическим курсом "Машинное обучение",

126
00:16:27,149 --> 00:16:35,448
в нём рассказываются основы того, как настраивать и запускать проекты машинного обучения.

127
00:16:36,659 --> 00:16:40,369
Рейчел: Рекомендуете пройти курс "Машинное обучение" перед тем, как проходить этот?

128
00:16:41,009 --> 00:16:53,269
Многие студенты, проходящие параллельно курс "Машинное обучение", сказали, что им понравилось, поэтому можете посмотреть.

129
00:16:55,799 --> 00:16:59,148
Оба курса говорят про похожие вещи, но различаются.

130
00:16:59,149 --> 00:17:05,689
Люди, которые прошли оба, говорят, что они дополняют друг друга, но я бы не сказал, что проходить оба обязательно.

131
00:17:06,659 --> 00:17:11,149
Тем не менее, если вам незнакомы термины тренировочная и валидационная выборка —

132
00:17:11,150 --> 00:17:23,270
погуглите, мы предполагаем, что базовые понятия машинного обучения вам известны.

133
00:17:23,279 --> 00:17:26,719
Рейчел: У меня в блоге есть целый пост на эту тему.

134
00:17:26,720 --> 00:17:29,809
Да, ссылка на него будет на course.fast.ai.

135
00:17:29,990 --> 00:17:36,289
В принципе наша философия на fast.ai  — учить вещи по ходу дела,

136
00:17:36,809 --> 00:17:49,789
иначе вы никогда не доберётесь до по-настоящему интересных вещей.
Рейчел: Да, я думаю, в глубоком обучении это особенно заметно.

137
00:17:50,460 --> 00:18:00,409
В директории valid — папки cats и dogs, в папке cats — пачка изображений.

138
00:18:01,409 --> 00:18:15,079
Это классический подход представления начальных данных для задачи классификации изображений —

139
00:18:15,419 --> 00:18:23,560
изображения с котами лежат в папке cats, изображения с собаками в папке dogs.

140
00:18:23,600 --> 00:18:36,960
С размеченными таким способом изображениями работает Keras, это классический способ хранить файлы.

141
00:18:36,960 --> 00:18:44,000
Можно увидеть пример изображения с котом, набрав plt.imgshow(img).

142
00:18:45,929 --> 00:18:57,049
Это форматирование строки, использующееся в Python 3.6, очень удобно, мы часто такое используем.

143
00:18:58,590 --> 00:19:05,149
Вот кошка, но нас интересует не она, а то, из каких данных она состоит.

144
00:19:05,789 --> 00:19:23,870
Файл имеет размерность 198x179x3, это трёхмерная матрица. Вот первые четыре ряда и колонки.

145
00:19:24,930 --> 00:19:42,349
Видно, что каждая пара квадратных скобок содержит три числа, которые характеризуют цвет пикселя в системе RGB, от 0 до 255.

146
00:19:43,320 --> 00:19:56,629
Идея состоит в том, чтобы научиться на основе наших данных предсказывать, кошка или собака закодирована такими числами.

147
00:19:56,630 --> 00:20:17,150
Это довольно сложно сделать — когда этот датасет был выложен на конкурсе Kaggle в 2012 году, точность 80% считалась хорошей,

148
00:20:17,370 --> 00:20:20,060
компьютеры плохо умели отличать котов от собак.

149
00:20:21,180 --> 00:20:34,550
Давайте тренировать модель. Этих трёх строк кода достаточно для простой модели.

150
00:20:35,250 --> 00:20:50,780
Давайте запустим ячейку и подождём её выполнения.

151
00:20:51,690 --> 00:20:59,630
Я указал значение параметра epochs=3 в методе fit, это значит, что модель рассмотрит каждое изображение трижды (3 прогона).

152
00:20:59,670 --> 00:21:11,329
При выполнении ячейки выводится точность на каждом из трёх прогонов, последний столбец — доля правильных ответов на валидационной выборке.

153
00:21:12,180 --> 00:21:23,359
Другие две колонки обсудим позже, это значения функции потерь на обучающей и валидационной выборке. Нулевая колонка - номер прогона.

154
00:21:23,700 --> 00:21:38,450
Доля правильных ответов получается больше 90% за 17 секунд — сильное улучшение с 2012 года.

155
00:21:39,420 --> 00:21:49,020
Эти три строки кода выиграли бы соревнование Kaggle - точность 80% считалась хорошей, а победитель достиг точности 98.9%, у нас же — почти 99%.

156
00:21:49,020 --> 00:22:07,250
Вас может удивить, что мы смогли превзойти уровень победителя соревнования Kaggle в 2012 за 17 секунд и три строки кода.

157
00:22:08,340 --> 00:22:23,389
Многие люди считают, что глубокое обучение требует большого количества времени, ресурсов и данных, и в этом курсе вы поймёте, что в общем случае это не так.

158
00:22:24,330 --> 00:22:53,749
Этот код простой, потому что использует нашу библиотеку fast.ai - в ней мы собираем все лучшие современные практики после тестирования на различных датасетах и тюнинга.

159
00:22:53,790 --> 00:23:03,380
Наша библиотека позволяет автоматически выбирать лучший подход к задаче.

160
00:23:04,050 --> 00:23:07,430
Именно благодаря ей мы и смогли написать этот код всего в три строчки.

161
00:23:08,040 --> 00:23:18,720
Библиотека fast.ai работает быстро, потому что она разработана на базе PyTorch —

162
00:23:18,720 --> 00:23:25,430
разработанной Facebook гибкой библиотеки для проведения расчётов для машинного обучения.

163
00:23:27,630 --> 00:23:41,749
Большинству людей привычнее TensorFlow, потому что Google его продвигает, но лучшие из моих знакомых исследователей перешли на PyTorch. Да, Рейчел?

164
00:23:42,500 --> 00:23:47,479
Рейчел: Про PyTorch мы ещё будем говорить позже.
Да, я надеюсь, что

165
00:23:48,929 --> 00:24:02,089
fast.ai вам понравится тем, что вы можете контролировать использование подобранных нами практик и легко написать что-то своё —

166
00:24:02,700 --> 00:24:12,049
алгоритм приращения данных, функцию потерь, архитетуру нейронной сети. Всё это мы сделаем в этом курсе.

167
00:24:12,210 --> 00:24:22,099
Чтобы понять, как выглядит модель, посмотрим на валидационную выборку.

168
00:24:22,620 --> 00:24:28,279
Целевая переменная y — массив из нулей и единиц.

169
00:24:28,379 --> 00:24:34,039
Как видно, нули показывают принадлежность к классу cats, единицы — классу dogs.

170
00:24:34,039 --> 00:24:44,209
Работа ведётся с двумя объектами — data, который содержит обучающую и валидационную выборки, и model, который содержит модель.

171
00:24:44,669 --> 00:24:47,809
В любой момент можно посмотреть, как устроены данные.

172
00:24:49,350 --> 00:24:57,780
Чтобы получить предсказания на основе валидационной выборки, вызовем метод predict().

173
00:24:57,780 --> 00:25:05,239
Посмотрим на первые десять предсказаний. Первый столбец - логарифм вероятности, что на изображении кошка, второй — что собака.

174
00:25:05,549 --> 00:25:19,908
В PyTorch   большинство моделей возвращают логарифм вероятности вместо самой вероятности, позже мы обсудим, почему.

175
00:25:20,100 --> 00:25:28,830
Чтобы перевести вероятности в привычный формат, вызовем метод numpy.exp().

176
00:25:28,830 --> 00:25:36,289
Мы используем numpy и предполагаем, что вы с ним работали.

177
00:25:36,870 --> 00:25:43,039
Если это не так, просмотрите пост на course.fast.ai про основы numpy.

178
00:25:43,440 --> 00:25:54,859
С помощью numpy Python быстро и эффективно выполняет вычисления, операции с массивами и тому  подобное.

179
00:25:56,090 --> 00:26:02,110
Итак, мы получаем вероятности с помощью метода numpy.exp().

180
00:26:02,390 --> 00:26:07,420
В этих ячейках - функции для вывода картинок, можете изучить их, если интересно.

181
00:26:08,750 --> 00:26:20,139
С их помощью можно отрисовать правильно распознанные изображения.

182
00:26:20,140 --> 00:26:29,409
Напоминаю, что 1 — собака, 0 — кошка, поэтому вероятность больше 0.5 — собака, меньше 0.5 — кошка.

183
00:26:30,320 --> 00:26:32,320
Посмотрим на неправильно распознанные изображения.

184
00:26:32,510 --> 00:26:40,299
Видно, что есть изображения, которых вообще не должно быть в датасете,

185
00:26:41,480 --> 00:26:48,399
но, очевидно, это изображение, классифицированное как собака — совсем не собака, есть очевидные ошибки.

186
00:26:51,230 --> 00:27:02,379
Также можно посмотреть, какие кошки, по мнению модели, больше всего похожи на кошек, и то же для собак.

187
00:27:03,860 --> 00:27:18,579
Интереснее смотреть на то, каких кошек и собак модель посчитала больше всего непохожими на себя.

188
00:27:19,130 --> 00:27:22,510
Видно, что в датасете есть странные изображения, тут вроде действительно есть собака. Да, Рейчел?

189
00:27:22,510 --> 00:27:26,710
Рейчел: Расскажи про то, почему ты смотришь на свои данные.

190
00:27:27,950 --> 00:27:38,590
Да, сейчас. Последняя ячейка с картинками — самые спорные изображения, вероятность близка к 0.5.

191
00:27:38,590 --> 00:27:44,169
Модель не знает, что делать с такими изображениями - и это неудивительно.

192
00:27:46,310 --> 00:27:56,649
Так вот, про данные. Первое, что я делаю после построения модели - пробую посмотреть, что она делает.

193
00:27:57,800 --> 00:28:05,769
Если я хочу усовершенствовать модель, нужно улучшить вещи, которые она делает хорошо и исправить те, которые она делает плохо.

194
00:28:07,640 --> 00:28:14,509
В процессе разглядывания модели я выяснил, что в датасете есть лишние изображения,

195
00:28:16,470 --> 00:28:22,760
и увидел, что модели ещё есть куда развиваться.

196
00:28:23,310 --> 00:28:44,150
Например, здесь очевидно собака. Но изображение широкое и невысокое, а модель бьёт изображение на квадратики и работает с ними.

197
00:28:45,320 --> 00:28:53,180
Возможно, для улучшения модели нам придется применить приращение данных — про это мы поговорим позже.

198
00:28:55,470 --> 00:29:22,789
Ура, у нас есть классификатор. Попробуйте найти пару картинок, положить их в разные папки и посмотреть, что случится, на наших трёх строках кода.

199
00:29:23,250 --> 00:29:37,970
Вы увидите, что модель хорошо сработает и на ваших изображениях — если это обычные фотографии,

200
00:29:38,880 --> 00:29:48,140
а не снимки с микроскопа, томографические снимки или тому подобное, мы обсудим этот нюанс позже.

201
00:29:48,140 --> 00:29:53,089
Для обычных фотографий используйте наши три строки кода, можете поменять переменную PATH на вашу директорию и получить готовый классификатор.

202
00:29:54,810 --> 00:30:06,469


203
00:30:07,230 --> 00:30:23,270
Один студент взял эти три строки, по десять изображений людей, играющих в крикет и бейсбол соответственно, и построил почти идеальный классификатор.

204
00:30:23,970 --> 00:30:40,640
Также он построил модель на семи изображениях канадской валюты и семи — американской и получил стопроцентную точность.

205
00:30:40,860 --> 00:30:48,320
Вы тоже можете скачать из Google пару изображений, попробовать, посмотреть, что работает и рассказать про свои успехи и неудачи на нашем форуме.

206
00:30:52,320 --> 00:31:04,500
Итак, мы только что натренировали нейронную сеть, но не объяснили, что такое сеть и что значит тренировать.

207
00:31:04,500 --> 00:31:11,149
Это демонстрирует подход к обучению "сверху вниз", о котором говорилось раньше.

208
00:31:11,580 --> 00:31:23,480
Идея в том, чтобы сначала показать вам, как обучить классификатор, и по ходу дела углубляться в теорию,

209
00:31:24,420 --> 00:31:35,089
вместо того чтобы отдалять этот момент три года, выдавая всю необходимую теорию маленькими порциями,

210
00:31:35,090 --> 00:31:42,750
как это часто делают в преподавании технических предметов.

211
00:31:42,750 --> 00:31:53,330
По ходу курса будут появляться новые проблемы. Например, на следующей лекции

212
00:31:53,330 --> 00:32:06,830
вместо обычных фотографий мы рассмотрим спутниковые снимки. На них наша модель будет работать хуже,

213
00:32:07,020 --> 00:32:20,460
мы посмотрим, что надо изменить, поймём, почему это нужно сделать и какие библиотеки для этого нужны.

214
00:32:20,460 --> 00:32:31,730
Таким образом, с каждой новой задачей мы будем лучше понимать теорию и овладевать библиотеками,

215
00:32:32,310 --> 00:32:45,000
а в конце с нуля создадим все элементы нейронной сети мирового класса.

216
00:32:45,850 --> 00:32:48,730
В этом общая идея. Да, Рейчел?

217
00:32:48,730 --> 00:32:57,450
Рейчел: Гарвардский профессор Дэвид Перкинс называет этот подход "игра полностью".

218
00:32:57,450 --> 00:33:01,769
Да, "игра полностью" — это как баскетбол или музыка.

219
00:33:01,770 --> 00:33:09,450
Знакомясь с баскетболом, вы приходите на игру, пробуете играть сами, и, возможно,

220
00:33:09,700 --> 00:33:15,569
спустя годы наконец начинаете изучать физику закручивания мяча в полёте.

221
00:33:15,610 --> 00:33:22,170
То же и с музыкой — вам дают музыкальный инструмент и вы пробуете играть на нем,

222
00:33:22,170 --> 00:33:29,159
и только годы спустя узнаете про квинтовый круг тональностей и каденции.

223
00:33:30,460 --> 00:33:37,679
Подход такой, да, мы вдохновлялись идеями Дэвида Перкинса и других.

224
00:33:38,710 --> 00:33:48,599
Ещё один способ понять эту идею - представить себе задачу как множество слоёв, которые мы будем снимать один за другим,

225
00:33:48,910 --> 00:33:52,800
и делать это вместе - вы будете экспериментировать, это программистский подход.

226
00:33:53,380 --> 00:33:57,030
Структура курса такая:

227
00:33:57,910 --> 00:34:01,859
сегодня мы посмотрим на свёрточные нейронные сети (CNN),

228
00:34:01,860 --> 00:34:07,709
потом посмотрим, как использовать нейронные сети для интерпретации структурированных данных,

229
00:34:07,710 --> 00:34:11,189
затем на рекуррентные нейронные сети (RNN) в анализе текста и, наконец, на рекомендательные системы.

230
00:34:12,280 --> 00:34:17,969
Затем возьмём эти четыре темы и пройдёмся по ним углубленно в другом порядке.

231
00:34:17,970 --> 00:34:22,140
Таким образом, к концу четвёртого блока вы узнаете, как

232
00:34:23,500 --> 00:34:32,250
построить классификатор мирового уровня, разработать программу для анализа структурированных данных,

233
00:34:32,770 --> 00:34:36,659
классификатор текста мирового уровня и рекомендательную систему мирового уровня.

234
00:34:37,090 --> 00:34:41,279
В дальнейших частях вы будете делать те же вещи, но узнаете их глубже —

235
00:34:41,280 --> 00:34:47,550
что именно они делают, как они работают, что можно поменять, как их можно применять в различных ситуациях —

236
00:34:48,130 --> 00:34:56,739
опять же, это будут рекомендательная система, изучение структурированных данных, изображения и анализ текста.

237
00:34:56,740 --> 00:35:06,110
Смысл такой структуры в том, что студенты обычно пересматривают видео-лекции несколько раз подряд,

238
00:35:06,110 --> 00:35:18,310
при этом просматривая весь курс подряд, а не повторяя каждую лекцию сразу после просмотра.

239
00:35:19,460 --> 00:35:23,740
Это помогает сначала уловить общую суть, а потом вернуться назад к уточнению деталей.

240
00:35:24,020 --> 00:35:39,070
Поэтому я вам советую смотреть лекции без излишней концентрации на деталях.

241
00:35:41,510 --> 00:35:52,269
За сегодняшнюю лекцию вы с минимальным количеством строк кода и минимальным количеством деталей

242
00:35:52,270 --> 00:36:01,749
обучите классификатор изображений, в конкретном случае для разделения изображений кошек и собак.

243
00:36:03,200 --> 00:36:15,800
На второй лекции рассмотрим спутниковые снимки и посмотрим, какие объекты на них присутствуют —

244
00:36:15,900 --> 00:36:23,420
это задача мультиклассовой классификации.

245
00:36:23,420 --> 00:36:39,610
К третьей лекции перейдём к самому широко применимому навыку — работа со структурированными данными, например, таблицами в базах данных.

246
00:36:39,610 --> 00:36:48,800
Работать будем с этими данными по продажам — признаками будут разные магазины, даты, наличие или отсутствие праздников,

247
00:36:48,800 --> 00:36:55,600
а предсказывать будем будущие продажи.

248
00:36:56,510 --> 00:37:05,140
На четвертой лекции перейдем к тексту и выясним, что люди думают про фильм Zombiegeddon —

249
00:37:05,360 --> 00:37:16,659
по аналогии с классификаторами картинок можно создавать классификаторы текста.

250
00:37:19,100 --> 00:37:23,860
На пятой лекции рассмотрим совместную фильтрацию — она в основном используется в рекомендательных системах.

251
00:37:24,320 --> 00:37:32,769
Работать будем с данными, содержащими оценки фильмов людьми, вот примеры.

252
00:37:33,440 --> 00:37:45,340
Простой способ представить эти данные — в виде такой таблицы.

253
00:37:45,340 --> 00:37:55,690
Предсказывать будем рейтинг фильма для тех пользователей, которые его ещё не видели.

254
00:37:55,970 --> 00:37:59,470
Совместная фильтрация помогает решать проблему того, какой контент показать посетителям вашего сайта,

255
00:37:59,540 --> 00:38:03,910
какую книгу или фильм порекомендовать для чтения/просмотра.

256
00:38:05,840 --> 00:38:20,890
На шестой лекции мы вернёмся к анализу текстов и научимся генерировать афоризмы в духе Ницше.

257
00:38:21,320 --> 00:38:27,309
Например, отрывок "Вероятно, что каждая жизнь значений крови соития, когда она чувствует беспринципность и его права, и импульс, любовь!" —

258
00:38:27,310 --> 00:38:39,160
не настоящий Ницше, а афоризм в его стиле, созданный рекуррентной нейронной сетью.

259
00:38:41,060 --> 00:38:44,680
На седьмой лекции мы вернёмся к компьютерному зрению и обучим модель  не только различать кошек и собак,

260
00:38:45,230 --> 00:38:50,680
но и понимать, где на изображении они находятся, с помощью таких тепловых карт.

261
00:38:50,810 --> 00:38:57,790
В этой же лекции мы напишем свою архитектуру нейронной сети, на экране — ResNet,

262
00:38:57,890 --> 00:39:09,910
пример архитектуры, которую мы будем использовать сегодня и которую построим с нуля позже.

263
00:39:09,910 --> 00:39:21,099
Итак, такими и будут этапы нашего курса, и на каждом этапе мы будем углубляться в технические детали.

264
00:39:24,559 --> 00:39:41,119
Многие студенты с прошлых запусков курса говорили, что потратили слишком много времени на иучение теории

265
00:39:41,119 --> 00:39:55,119
и слишком мало времени на практическую часть. Люди жалеют, что не вняли нашим советам экспериментировать с ячейками кода.

266
00:39:55,670 --> 00:39:59,319
На экране комментарии с нашего форума:

267
00:39:59,319 --> 00:40:07,750
"Надо было больше времени тратить на код в ноутбуках, запускать его и смотреть, что получается."

268
00:40:10,430 --> 00:40:21,579
Идея, что через программистский подход можно научиться создавать модели мирового класса,

269
00:40:21,579 --> 00:40:23,619
сильно отличается от рекомендаций, которые можно найти на других форумах.

270
00:40:24,920 --> 00:40:35,949
Пользователь с Hacker News говорит, что лучший способ стать ML-специалистом — выучить всю математику, C и C++,

271
00:40:36,500 --> 00:40:41,979
параллельное программирование, воплощать все алгоритмы сначала на чистом C... И только потом начать заниматься машинным обучением.

272
00:40:42,500 --> 00:40:50,260
Если вы хотите хороших практических результатов, мы советуем делать ровно наоборот.

273
00:40:50,900 --> 00:40:59,979
Да, Рейчел? Рейчел: Хочу уточнить, что на экране сейчас — вредные советы, они убивают всю мотивацию у людей.

274
00:41:00,049 --> 00:41:09,140
Да. К текущему моменту уже десятки тысяч закончили этот курс и многие из них сейчас

275
00:41:09,140 --> 00:41:22,869
занимаются исследованиями в лабораториях, участвуют в программе Google Brain Residency, создают патенты на основе глубокого обучения.

276
00:41:23,450 --> 00:41:27,730
Подход "сверху вниз" работает отлично.

277
00:41:27,859 --> 00:41:47,419
Уточню одну вещь про уже построенную нами модель — первый запуск длится дольше 17 секунд по двум причинам.

278
00:41:47,849 --> 00:41:57,359
Первая — сначала из интернета скачивается уже обученная модель, это занимает одну-две минуты.

279
00:41:57,359 --> 00:42:08,569
Вторая — при первом запуске вычисляются и кэшируются необходимые промежуточные данные, минуты полторы.

280
00:42:09,180 --> 00:42:17,839
Поэтому первый запуск может занять три-четыре минуты, но последующие запуски ячейки займут около 20 секунд.

281
00:42:18,569 --> 00:42:38,058
Пример с кошками и собаками может показаться вам скучным — вы и сами умеете это делать, но спектр применения таких алгоритмов широкий.

282
00:42:39,720 --> 00:42:56,359
Например, в корне модели AlphaGo, победившей лучших игроков мира в го — то же, что и в нашей модели.

283
00:42:56,880 --> 00:43:07,220
Модель обучали на тысячах выигрышных и проигрышных позициях на доске,

284
00:43:08,099 --> 00:43:17,450
и в итоге получился классификатор изображений, позволяющий отделять плохие позиции от хороших.

285
00:43:17,730 --> 00:43:25,730
А это самый важный навык при игре в го — понимать, какой ход лучше сделать.

286
00:43:27,809 --> 00:43:39,980
Один из наших студентов оформил пару патентов на свою работу по выявлению мошенничества.

287
00:43:40,880 --> 00:43:52,549
На многих сайтах отслеживаются движения курсора мыши для предотвращения мошенничества,

288
00:43:53,339 --> 00:44:01,788
он взял движения курсоров, записал траектории с учётом скорости движения как картинки

289
00:44:02,579 --> 00:44:06,379
и построил классификатор изображений, который принимал эти траектории и говорил,

290
00:44:07,049 --> 00:44:18,889
намеревается ли управляющий курсором человек смошенничать. И результаты были неплохие.

291
00:44:20,130 --> 00:44:26,240
Как видите, многие задачи сводимы к задаче классификации изображений.

292
00:44:26,519 --> 00:44:46,279
Это один из примеров использования глубокого обучения. Глубокое обучение и машинное обучение — не одно и то же.

293
00:44:47,400 --> 00:44:50,389
Скорее, глубокое обучение — это раздел машинного обучения.

294
00:44:50,819 --> 00:44:56,778
Артур Сэмюэл изобрёл машинное обучение.

295
00:44:57,089 --> 00:45:06,980
В конце 50-х годов он научил IBM обыгрывать себя в шашки.

296
00:45:07,859 --> 00:45:15,679
Он заставил машину играть с собой и отслеживать, какие ходы ведут к победе, а какие к поражению,

297
00:45:16,049 --> 00:45:19,309
и использовал эти результаты для написания своей программы.

298
00:45:19,710 --> 00:45:34,639
В 1962 он сказал, что наступит день, когда большинство программ будет написано с использованием машинного обучения.

299
00:45:35,400 --> 00:45:41,180
Я думаю, что этот момент ещё не настал, но мы на верном пути.

300
00:45:41,789 --> 00:45:50,599
Традиционное машинное обучение было очень сложным и требовало много знаний и времени.

301
00:45:51,630 --> 00:45:57,559
Например, вычислительная патология.

302
00:45:58,560 --> 00:46:08,419
Эндрю Бэк, когда он ещё был в Стэнфорде — сейчас он в Гарварде, — работал над проблемой распознавания рака молочной железы.

303
00:46:09,360 --> 00:46:23,300
Он взял снимки биопсий молочной железы и вместе с командой патологов выявил различные признаки,

304
00:46:24,030 --> 00:46:45,890
влияющие на то, выживет пациент или нет — признаки вроде связи между эпителиальными клетками и тому подобное.

305
00:46:45,890 --> 00:46:59,660
Они придумали сотни признаков, команда программистов разработала способы выявлять эти признаки,

306
00:47:00,390 --> 00:47:06,949
и на их основе построили модель логистической регрессии, предсказывающую, выживет пациент или нет.

307
00:47:07,170 --> 00:47:31,130
Модель предсказывала лучше, чем живые патологи, но на это ушли годы работы большой команды экспертов.

308
00:47:31,920 --> 00:47:39,780
Хочется как-то попроще.

309
00:47:39,780 --> 00:47:53,010
Специфичная для задачи модель, требующая ручного выделения признаков экспертами в области — это неудобно.

310
00:47:53,010 --> 00:48:03,259
Мы попробуем найти функцию, которая сможет решить любую задачу при правильном выставлении параметров,

311
00:48:03,260 --> 00:48:11,210
разработать способ задавать эти параметры, и сделать нашу модель быстрой и масштабируемой.

312
00:48:11,610 --> 00:48:20,509
Если у нас будет такая модель, то не придётся привлекать экспертов и тратить время на ручное выделение признаков.

313
00:48:20,880 --> 00:48:27,230
Это за нас сделает модель.

314
00:48:27,330 --> 00:48:39,019
Как вы могли догадаться, алгоритмы, обладающие этими тремя признаками — это алгоритмы глубокого обучения.

315
00:48:40,560 --> 00:48:42,590
Рассмотрим эти признаки по очереди.

316
00:48:43,560 --> 00:48:49,519
Функция, лежащая в основе алгоритмов глубокого обучения, называется нейронная сеть.

317
00:48:50,460 --> 00:49:03,229
Позже мы построим с нуля свою нейронную сеть, пока достаточно знания того, что нейронная сеть состоит из

318
00:49:04,230 --> 00:49:19,789
перемежающихся линейных и нелинейных слоёв. Универсальная теорема аппроксимации гласит, что

319
00:49:20,010 --> 00:49:31,909
нейронная сеть с одним скрытым слоем может аппроксимировать любую непрерывную функцию с любой точностью.

320
00:49:32,400 --> 00:49:37,160
Поэтому нейронная сеть действительно удовлетворяет как функция первому признаку алгоритму глубокого обучения.

321
00:49:38,520 --> 00:49:56,689
Для нахождения необходимых параметров во втором признаке мы используем градиентный спуск.

322
00:49:56,690 --> 00:50:11,719
Для каждого набора параметров мы знаем качество предсказания модели и пытаемся найти оптимальный набор,

323
00:50:12,150 --> 00:50:20,220
немного меняя его, то есть двигаемся по поверхности возможных потерь вниз, как шарик, скатывающийся с горки.

324
00:50:20,220 --> 00:50:50,480
На этом рисунке итоговый результат зависит от точки начала, но для большинства задач глубокого обучения локальный минимум один.

325
00:50:51,900 --> 00:51:02,749
Итак, градиентный спуск подходит в качестве нахождения оптимального набора параметров.

326
00:51:04,830 --> 00:51:14,239
Проблема в том, что это нужно делать быстро. Здесь нам помогают GPU.

327
00:51:15,060 --> 00:51:23,929
На экране график прироста скорости GPU и CPU в гигафлопсах за последние несколько лет,

328
00:51:25,230 --> 00:51:31,459
GPU — красная и зелёная линии, CPU — синяя, шкала логарифмическая.

329
00:51:31,770 --> 00:52:06,890
Видно, что GPU примерно в 10 раз быстрее CPU. Сегодня GTX 1080 стоит $700, а E5-2699, который медленнее в десять раз — $4115.

330
00:52:08,340 --> 00:52:25,610
Видно, что GPU помогут быстро и дёшево подбирать параметры нейронных сетей, они завершают список признаков.

331
00:52:27,750 --> 00:52:52,689
Универсальная теорема аппроксимации полагает, что у нейронной сети только один скрытый слой, как показано здесь,

332
00:52:53,210 --> 00:53:10,059
но в такой конфигурации сложность вычислений растёт экспоненционально, третий признак теряется.

333
00:53:11,359 --> 00:53:29,259
Если добавить несколько скрытых слоёв, можно улучшить точность для более сложных проблем —

334
00:53:29,990 --> 00:53:36,490
и вот тут машинное обучение переходит в глубокое обучение, глубокое обучение - нейронные сети с несколькими скрытыми слоями.

335
00:53:41,119 --> 00:53:51,220
Google начал инвестировать в глубокое обучение в 2012 году, пригласив отца глубокого обучения Джеффри Хинтона

336
00:53:53,060 --> 00:54:07,300
и его лучшего студента Алекса Крижевского в команду, которая в будущем стала Google Brain.

337
00:54:08,660 --> 00:54:23,170
Алгоритмы глубокого обучения - мощные и гибкие, поэтому количество задействующих их проектов Google начало расти.

338
00:54:23,480 --> 00:54:30,939
График на экране кончается около 2016, но я знаю, что экспоненциальный рост продолжился.

339
00:54:31,460 --> 00:54:37,480
Теперь, как видите, Google использует глубокое обучение почти во всех своих продуктах.

340
00:54:38,180 --> 00:54:53,500
Интересно наблюдать за тем, как простое определение алгоритма глубокого обучения тремя признаками

341
00:54:53,990 --> 00:55:01,660
вырастает так сильно, когда большая компания в это вкладывается.

342
00:55:03,200 --> 00:55:15,820
Например, при чтении письма в Gmail вам предлагается несколько готовых ответов —

343
00:55:16,370 --> 00:55:26,530
Google использует глубокое обучение для чтения письма и генерации возможных откликов.

344
00:55:26,570 --> 00:55:33,610
Это отличный пример того, что раньше было невозможно.

345
00:55:34,610 --> 00:55:49,900
Ещё один пример — недавно Microsoft начали инвестировать в глубокое обучение. Теперь в Skype можно

346
00:55:50,210 --> 00:55:57,880
говорить фразу на английском, и Skype переведёт её вашему собеседнику на китайский или испанский,

347
00:55:58,340 --> 00:56:03,340
и наоборот — и всё это в режиме реального времени.

348
00:56:04,190 --> 00:56:09,129
Опять же, мы не смогли бы сделать это без глубокого обучения.

349
00:56:12,020 --> 00:56:18,680
Другой интересный вопрос — как можно соединить глубокое обучение и человеческий опыт.

350
00:56:18,680 --> 00:56:26,139
Вот пример программы Neural Doodle, она была выпущена пару лет назад —

351
00:56:26,140 --> 00:56:33,339
она берёт на вход ваш набросок и переводит его в стиль выбранного художника.

352
00:56:34,040 --> 00:56:42,729
Вот картина, которая получилась при переводе скетча в стиль художника-импрессиониста.

353
00:56:43,970 --> 00:56:50,560
Я думаю, это отличный пример сочетания глубокого обучения и человеческого опыта.

354
00:56:54,340 --> 00:57:08,190
Несколько лет назад я хотел поэкспериментировать с применением глубокого обучения для решения важных проблем

355
00:57:08,740 --> 00:57:20,309
и выбрал диагностику рака лёгких. Оказывается, ранняя диагностика узелков в легких повышает шансы на выживание в 10 раз,

356
00:57:20,860 --> 00:57:27,510
поэтому важно уметь это делать. Я нашёл ещё троих человек без опыта работы в медицинской среде,

357
00:57:28,330 --> 00:57:34,319
мы нашли датасет, состоящий из томографических снимков и использовали свёрточные нейронные сети —

358
00:57:35,020 --> 00:57:38,670
очень похожие на сети из сегодняшней лекции про разделение кошек и собак —

359
00:57:39,490 --> 00:57:46,470
для предсказывания наличия недоброкачественной опухоли на снимке.

360
00:57:46,510 --> 00:57:50,669
Пару месяцев спустя наша модель стала допускать ошибки I и II рода (false positive и false negative) реже,

361
00:57:50,860 --> 00:58:03,840
чем команда из четырёх радиологов. Мы запустили стартап и это вылилось в довольно успешную компанию Enlitic.

362
00:58:04,750 --> 00:58:13,380
С тех пор стало популярным использовать глубокое обучение для медицинской диагностики.

363
00:58:14,380 --> 00:58:30,660
Я заметил, что сейчас глубокое обучение мало где используется, но при первых попытках внедрения

364
00:58:30,880 --> 00:58:45,299
даёт фантастические результаты, и какое-то время спустя все в данной сфере начинают его использовать.

365
00:58:46,300 --> 00:58:57,700
Здесь я набросал пару идей для применения глубокого обучения — это вещи,

366
00:58:57,700 --> 00:59:06,150
на которые люди тратят много времени и сил, которые можно упростить. Список не полон,

367
00:59:06,180 --> 00:59:11,460
наверняка в вашей компании есть сферы, где можно применить глубокое обучение.

368
00:59:13,269 --> 00:59:15,869


369
00:59:16,569 --> 00:59:22,139


370
00:59:22,539 --> 00:59:29,609


371
00:59:30,069 --> 00:59:34,679


372
00:59:36,009 --> 00:59:38,699


373
00:59:40,230 --> 00:59:42,230


374
00:59:42,730 --> 00:59:44,319


375
00:59:44,319 --> 00:59:50,459


376
00:59:50,829 --> 00:59:56,699


377
00:59:57,489 --> 01:00:03,779


378
01:00:04,620 --> 01:00:08,120


379
01:00:10,920 --> 01:00:16,760


380
01:00:17,460 --> 01:00:23,540


381
01:00:23,549 --> 01:00:28,379


382
01:00:28,809 --> 01:00:31,619


383
01:00:32,140 --> 01:00:37,349


384
01:00:38,680 --> 01:00:40,420


385
01:00:40,420 --> 01:00:44,460


386
01:00:45,190 --> 01:00:48,839


387
01:00:48,839 --> 01:00:52,768


388
01:00:53,410 --> 01:00:58,710


389
01:00:59,980 --> 01:01:07,319


390
01:01:10,690 --> 01:01:17,730


391
01:01:18,510 --> 01:01:20,580


392
01:01:21,580 --> 01:01:23,969


393
01:01:24,820 --> 01:01:28,889


394
01:01:29,950 --> 01:01:32,820


395
01:01:33,640 --> 01:01:39,540


396
01:01:39,940 --> 01:01:43,380


397
01:01:43,990 --> 01:01:51,120


398
01:01:51,880 --> 01:01:58,409


399
01:01:58,570 --> 01:02:01,229


400
01:02:01,570 --> 01:02:04,229


401
01:02:04,600 --> 01:02:10,829


402
01:02:12,070 --> 01:02:14,639


403
01:02:15,280 --> 01:02:17,170


404
01:02:17,170 --> 01:02:24,060


405
01:02:25,450 --> 01:02:31,590


406
01:02:32,200 --> 01:02:33,610


407
01:02:33,610 --> 01:02:36,120


408
01:02:36,840 --> 01:02:41,260


409
01:02:41,260 --> 01:02:46,020


410
01:02:46,800 --> 01:02:51,440


411
01:02:51,440 --> 01:02:52,060


412
01:02:52,060 --> 01:02:58,350


413
01:02:58,660 --> 01:03:04,020


414
01:03:05,560 --> 01:03:12,600


415
01:03:12,960 --> 01:03:15,480


416
01:03:19,080 --> 01:03:24,020


417
01:03:24,820 --> 01:03:31,260


418
01:03:31,660 --> 01:03:38,430


419
01:03:38,890 --> 01:03:46,799


420
01:03:47,079 --> 01:03:53,279


421
01:03:54,220 --> 01:03:56,549


422
01:03:57,099 --> 01:04:02,279


423
01:04:03,040 --> 01:04:10,439


424
01:04:10,839 --> 01:04:15,629


425
01:04:16,180 --> 01:04:22,589


426
01:04:24,849 --> 01:04:28,558


427
01:04:30,849 --> 01:04:36,539


428
01:04:37,510 --> 01:04:38,980


429
01:04:38,980 --> 01:04:43,230


430
01:04:43,540 --> 01:04:48,269


431
01:04:48,910 --> 01:04:53,639


432
01:04:54,400 --> 01:04:58,770


433
01:04:59,530 --> 01:05:01,559


434
01:05:02,980 --> 01:05:07,559


435
01:05:10,809 --> 01:05:12,839


436
01:05:13,839 --> 01:05:15,839


437
01:05:15,849 --> 01:05:23,129


438
01:05:23,290 --> 01:05:25,919


439
01:05:26,200 --> 01:05:31,659


440
01:05:32,330 --> 01:05:35,919


441
01:05:36,080 --> 01:05:42,850


442
01:05:43,100 --> 01:05:48,400


443
01:05:49,100 --> 01:05:56,220


444
01:05:56,920 --> 01:05:59,100


445
01:06:02,090 --> 01:06:04,809


446
01:06:04,810 --> 01:06:12,759


447
01:06:13,820 --> 01:06:18,699


448
01:06:18,700 --> 01:06:26,260


449
01:06:27,080 --> 01:06:29,080


450
01:06:29,600 --> 01:06:34,479


451
01:06:34,670 --> 01:06:41,080


452
01:06:41,660 --> 01:06:47,530


453
01:06:48,440 --> 01:06:49,730


454
01:06:49,730 --> 01:06:51,730


455
01:06:56,870 --> 01:06:58,870


456
01:07:00,230 --> 01:07:02,919


457
01:07:03,830 --> 01:07:07,360


458
01:07:07,970 --> 01:07:12,939


459
01:07:12,940 --> 01:07:14,940


460
01:07:15,530 --> 01:07:18,549


461
01:07:19,580 --> 01:07:21,610


462
01:07:22,730 --> 01:07:24,730


463
01:07:26,000 --> 01:07:27,410


464
01:07:27,410 --> 01:07:32,950


465
01:07:32,950 --> 01:07:35,079


466
01:07:35,080 --> 01:07:40,930


467
01:07:46,430 --> 01:07:48,430


468
01:07:49,250 --> 01:07:50,650


469
01:07:50,650 --> 01:07:58,569


470
01:07:58,570 --> 01:07:59,960


471
01:07:59,960 --> 01:08:04,990


472
01:08:05,330 --> 01:08:12,460


473
01:08:12,740 --> 01:08:14,979


474
01:08:15,500 --> 01:08:17,500


475
01:08:18,200 --> 01:08:21,130


476
01:08:21,980 --> 01:08:23,980


477
01:08:24,950 --> 01:08:26,950


478
01:08:29,900 --> 01:08:36,279


479
01:08:36,950 --> 01:08:43,990


480
01:08:44,810 --> 01:08:49,780


481
01:08:50,150 --> 01:08:53,979


482
01:08:54,710 --> 01:08:58,660


483
01:08:59,270 --> 01:09:05,830


484
01:09:06,320 --> 01:09:09,039


485
01:09:09,560 --> 01:09:16,580


486
01:09:17,100 --> 01:09:22,729


487
01:09:22,730 --> 01:09:27,649


488
01:09:29,310 --> 01:09:32,959


489
01:09:37,050 --> 01:09:41,449


490
01:09:43,080 --> 01:09:44,670


491
01:09:44,670 --> 01:09:45,960


492
01:09:45,960 --> 01:09:52,700


493
01:09:52,830 --> 01:09:56,990


494
01:09:57,390 --> 01:10:02,780


495
01:10:03,660 --> 01:10:10,789


496
01:10:11,310 --> 01:10:12,900


497
01:10:12,900 --> 01:10:15,290


498
01:10:16,230 --> 01:10:20,300


499
01:10:20,910 --> 01:10:24,649


500
01:10:25,800 --> 01:10:28,819


501
01:10:29,940 --> 01:10:34,129


502
01:10:34,170 --> 01:10:38,390


503
01:10:39,030 --> 01:10:42,199


504
01:10:43,080 --> 01:10:50,450


505
01:10:51,060 --> 01:10:54,800


506
01:10:55,170 --> 01:11:01,399


507
01:11:02,670 --> 01:11:08,120


508
01:11:09,450 --> 01:11:11,450


509
01:11:12,030 --> 01:11:14,449


510
01:11:15,030 --> 01:11:20,780


511
01:11:21,810 --> 01:11:24,919


512
01:11:25,560 --> 01:11:27,120


513
01:11:27,120 --> 01:11:30,289


514
01:11:32,760 --> 01:11:36,409


515
01:11:39,240 --> 01:11:41,240


516
01:11:41,240 --> 01:11:45,080


517
01:11:45,200 --> 01:11:50,860


518
01:11:50,870 --> 01:11:54,950


519
01:11:56,250 --> 01:11:59,419


520
01:11:59,420 --> 01:12:03,350


521
01:12:03,350 --> 01:12:09,950


522
01:12:10,530 --> 01:12:13,519


523
01:12:13,980 --> 01:12:19,430


524
01:12:20,040 --> 01:12:22,160


525
01:12:23,400 --> 01:12:26,450


526
01:12:27,120 --> 01:12:33,530


527
01:12:34,830 --> 01:12:39,109


528
01:12:39,110 --> 01:12:44,839


529
01:12:45,900 --> 01:12:53,150


530
01:12:53,790 --> 01:12:57,560


531
01:12:58,500 --> 01:13:00,589


532
01:13:01,620 --> 01:13:05,329


533
01:13:05,940 --> 01:13:07,560


534
01:13:07,560 --> 01:13:10,850


535
01:13:12,210 --> 01:13:19,700


536
01:13:20,640 --> 01:13:23,569


537
01:13:23,570 --> 01:13:31,430


538
01:13:31,680 --> 01:13:35,359


539
01:13:36,150 --> 01:13:41,429


540
01:13:42,310 --> 01:13:44,310


541
01:13:48,130 --> 01:13:50,969


542
01:13:51,520 --> 01:13:57,629


543
01:13:58,480 --> 01:14:00,480


544
01:14:00,760 --> 01:14:05,760


545
01:14:07,780 --> 01:14:14,429


546
01:14:14,530 --> 01:14:21,600


547
01:14:21,940 --> 01:14:23,650


548
01:14:23,650 --> 01:14:26,609


549
01:14:27,550 --> 01:14:29,550


550
01:14:29,679 --> 01:14:31,679


551
01:14:33,460 --> 01:14:36,779


552
01:14:37,449 --> 01:14:43,709


553
01:14:44,260 --> 01:14:47,130


554
01:14:48,370 --> 01:14:50,640


555
01:14:52,929 --> 01:14:56,279


556
01:14:59,530 --> 01:15:03,239


557
01:15:04,179 --> 01:15:06,040


558
01:15:06,040 --> 01:15:08,040


559
01:15:08,080 --> 01:15:10,409


560
01:15:14,590 --> 01:15:20,580


561
01:15:25,090 --> 01:15:27,090


562
01:15:27,100 --> 01:15:31,769


563
01:15:32,500 --> 01:15:36,089


564
01:15:37,510 --> 01:15:39,510


565
01:15:40,540 --> 01:15:42,540


566
01:15:43,090 --> 01:15:45,090


567
01:15:45,340 --> 01:15:47,050


568
01:15:47,050 --> 01:15:50,489


569
01:15:51,130 --> 01:15:53,130


570
01:15:53,530 --> 01:15:54,670


571
01:15:54,670 --> 01:15:56,130


572
01:15:56,130 --> 01:16:03,210


573
01:16:03,720 --> 01:16:05,600


574
01:16:05,620 --> 01:16:08,309


575
01:16:08,309 --> 01:16:15,080


576
01:16:15,610 --> 01:16:16,630


577
01:16:16,630 --> 01:16:20,219


578
01:16:20,770 --> 01:16:22,770


579
01:16:23,739 --> 01:16:29,099


580
01:16:30,010 --> 01:16:33,030


581
01:16:33,030 --> 01:16:38,460


582
01:16:38,619 --> 01:16:42,059


583
01:16:44,320 --> 01:16:46,320


584
01:16:48,190 --> 01:16:53,730


585
01:16:54,400 --> 01:17:00,480


586
01:17:00,880 --> 01:17:07,859


587
01:17:08,679 --> 01:17:12,658


588
01:17:13,179 --> 01:17:15,959


589
01:17:15,960 --> 01:17:22,710


590
01:17:22,710 --> 01:17:29,669


591
01:17:29,670 --> 01:17:36,659


592
01:17:38,500 --> 01:17:46,409


593
01:17:47,560 --> 01:17:51,509


594
01:17:52,599 --> 01:17:57,239


595
01:17:58,210 --> 01:18:04,019


596
01:18:04,599 --> 01:18:06,010


597
01:18:06,010 --> 01:18:12,479


598
01:18:13,119 --> 01:18:15,119


599
01:18:16,269 --> 01:18:20,429


600
01:18:21,309 --> 01:18:25,139


601
01:18:25,809 --> 01:18:31,018


602
01:18:31,019 --> 01:18:34,589


603
01:18:34,989 --> 01:18:38,908


604
01:18:39,519 --> 01:18:41,519


605
01:18:41,620 --> 01:18:46,620


606
01:18:49,560 --> 01:18:55,040


607
01:18:56,320 --> 01:19:02,130


608
01:19:03,070 --> 01:19:10,349


609
01:19:11,889 --> 01:19:17,399


610
01:19:17,949 --> 01:19:22,978


611
01:19:23,409 --> 01:19:27,478


612
01:19:28,360 --> 01:19:32,969


613
01:19:33,940 --> 01:19:36,509


614
01:19:37,989 --> 01:19:39,880


615
01:19:39,880 --> 01:19:41,829


616
01:19:41,829 --> 01:19:43,809


617
01:19:43,809 --> 01:19:48,869


618
01:19:49,510 --> 01:19:51,929


619
01:19:53,380 --> 01:19:55,329


620
01:19:55,329 --> 01:20:02,669


621
01:20:02,670 --> 01:20:06,929


622
01:20:07,479 --> 01:20:09,779


623
01:20:10,780 --> 01:20:12,380


624
01:20:12,380 --> 01:20:18,000


625
01:20:18,000 --> 01:20:23,540


626
01:20:24,219 --> 01:20:29,609


627
01:20:30,639 --> 01:20:32,939


628
01:20:33,000 --> 01:20:39,029


629
01:20:39,460 --> 01:20:43,679


630
01:20:44,619 --> 01:20:51,689


631
01:20:51,690 --> 01:20:53,690


632
01:20:53,920 --> 01:20:59,790


633
01:21:00,639 --> 01:21:02,819


634
01:21:04,480 --> 01:21:08,669


635
01:21:08,670 --> 01:21:16,440


636
01:21:17,020 --> 01:21:21,810


637
01:21:21,810 --> 01:21:27,359


638
01:21:27,360 --> 01:21:32,279


639
01:21:33,929 --> 01:21:38,969


640
01:21:39,940 --> 01:21:44,730


641
01:21:45,790 --> 01:21:47,790


642
01:21:48,730 --> 01:21:55,589


643
01:21:56,710 --> 01:22:03,960


644
01:22:05,050 --> 01:22:10,139


645
01:22:10,960 --> 01:22:14,849


646
01:22:15,119 --> 01:22:20,369


647
01:22:21,150 --> 01:22:21,510


648
01:22:21,510 --> 01:22:23,500


649
01:22:23,500 --> 01:22:29,720


650
01:22:31,740 --> 01:22:35,100


651
01:22:35,860 --> 01:22:39,690


652
01:22:39,690 --> 01:22:44,669


653
01:22:45,520 --> 01:22:47,969


654
01:22:48,700 --> 01:22:50,700


655
01:22:51,130 --> 01:22:52,990


656
01:22:52,990 --> 01:22:54,990


657
01:22:55,420 --> 01:22:58,379


658
01:22:59,470 --> 01:23:05,699


659
01:23:07,390 --> 01:23:12,569


660
01:23:14,170 --> 01:23:16,589


661
01:23:18,880 --> 01:23:22,560


662
01:23:22,560 --> 01:23:29,189


663
01:23:29,740 --> 01:23:33,719


664
01:23:34,480 --> 01:23:35,760


665
01:23:35,760 --> 01:23:39,960


666
01:23:39,960 --> 01:23:42,270


667
01:23:44,800 --> 01:23:50,190


668
01:23:50,490 --> 01:23:57,570


669
01:23:58,150 --> 01:24:04,170


670
01:24:04,420 --> 01:24:07,350


671
01:24:09,280 --> 01:24:10,930


672
01:24:10,930 --> 01:24:16,380


673
01:24:16,840 --> 01:24:17,850


674
01:24:17,850 --> 01:24:23,489


675
01:24:24,070 --> 01:24:26,070


676
01:24:26,800 --> 01:24:33,179


677
01:24:34,170 --> 01:24:34,900


678
01:24:34,900 --> 01:24:38,340


679
01:24:39,010 --> 01:24:41,010


680
01:24:41,680 --> 01:24:46,200


681
01:24:46,450 --> 01:24:50,099


682
01:24:50,890 --> 01:24:54,360


683
01:24:54,940 --> 01:25:00,450


684
01:25:00,580 --> 01:25:03,660


685
01:25:03,970 --> 01:25:08,939


686
01:25:09,910 --> 01:25:14,760


687
01:25:15,700 --> 01:25:20,669


688
01:25:20,890 --> 01:25:23,490


689
01:25:24,100 --> 01:25:27,510


690
01:25:27,630 --> 01:25:32,069


691
01:25:32,230 --> 01:25:37,080


692
01:25:37,870 --> 01:25:43,019


693
01:25:43,210 --> 01:25:49,950


694
01:25:50,680 --> 01:25:52,680


695
01:25:53,230 --> 01:25:57,930
Я думаю, этой информации хватит для начала.

696
01:25:58,390 --> 01:26:04,499


697
01:26:04,500 --> 01:26:10,830


698
01:26:11,260 --> 01:26:17,939


699
01:26:19,330 --> 01:26:20,890


700
01:26:20,890 --> 01:26:24,780


701
01:26:24,940 --> 01:26:28,770


702
01:26:29,470 --> 01:26:33,899
Спасибо за просмотр, встретимся с вами на следующей лекции.

