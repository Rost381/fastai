1
00:00:00,489 --> 00:00:04,799
Добро пожаловать на курс глубокого обучения на практике для программистов.

2
00:00:04,799 --> 00:00:09,209
Это первая часть нашего курса, состоящего из двух частей.

3
00:00:11,110 --> 00:00:14,040
Я открываю этот курс из Института Данных в Сан Франциско.

4
00:00:16,119 --> 00:00:24,389
В этой части курса семь лекций, большинство из них длится около двух часов, эта первая лекция чуть короче.

5
00:00:26,769 --> 00:00:34,229
Наш курс введёт вас в глубокое обучение на практике для получения результатов мирового класса,

6
00:00:34,660 --> 00:00:38,399
и, как предполагает название, мы сконцентрируемся на программировании.

7
00:00:38,530 --> 00:00:49,649
Но мы не собираемся упрощать. К концу курса вы изучите всю необходимую для воспроизведения результатов мирового класса теорию. Мы начнём с нуля.

8
00:00:50,829 --> 00:01:09,059
Наши видео размещены на YouTube, но мы рекомендуем смотреть их на нашем веб-сайте course.fast.ai — видео те же самые, но на сайте также есть информация

9
00:01:09,340 --> 00:01:17,758
об обновлениях к библиотекам, которые вам понадобятся, дальнейшие инструкции, часто задаваемые вопросы и прочее.

10
00:01:18,640 --> 00:01:23,519
Поэтому, если вы сейчас смотрите это видео на YouTube — вы можете переключиться на course.fast.ai

11
00:01:23,740 --> 00:01:31,469
и начать смотреть там, убедившись, что вы прочитали все материалы на странице и у вас есть всё, что нужно.

12
00:01:33,220 --> 00:01:39,029
На forums.fast.ai сильное сообщество.

13
00:01:41,380 --> 00:01:58,169
На протяжении курса у вас могут возникать проблемы с пониманием материала или технические проблемы.

14
00:01:58,479 --> 00:02:06,059
На forums.fast.ai — тысячи людей, проходящих курс вместе с вами, обсуждающих лекции и многие другие темы.

15
00:02:06,310 --> 00:02:12,360
Сейчас это самое активное сообщество по глубокому обучению в интернете — обязательно зарегистрируйтесь.

16
00:02:12,930 --> 00:02:16,890
И участвуйте в обсуждениях — так вы получите гораздо больше от курса.

17
00:02:19,689 --> 00:02:29,189
Итак, давайте начнём с написания кода. Существует подход к обучению «сверху вниз», мы обсудим его немного позже,

18
00:02:30,010 --> 00:02:36,420
но начнём применять уже сейчас. Давайте попробуем обучить нейронную сеть.

19
00:02:37,090 --> 00:02:42,149
Для того, чтобы обучить нейронную сеть, в большинстве случаев необходим графический процессор.

20
00:02:42,849 --> 00:02:53,220
Графический процессор (GPU) — это устройство, которое компании используют, чтобы помочь вам играть в компьютерные игры.

21
00:02:54,459 --> 00:02:59,608
GPU помогают вашим компьютерам отрисовывать графику в играх гораздо быстрее, чем CPU.

22
00:03:00,609 --> 00:03:07,199
Немного позже мы ещё обсудим графические процессоры, а сейчас я хочу показать, как вы можете получить доступ к выделенному GPU.

23
00:03:09,010 --> 00:03:16,260
Нам понадобятся графические процессоры от NVIDIA, потому что только они поддерживают CUDA.

24
00:03:16,690 --> 00:03:25,199
CUDA — это язык и фреймворк, который используют почти все библиотеки и практические проекты в глубоком обучении.

25
00:03:26,829 --> 00:03:35,849
Сейчас на рынке мало аналогов NVIDIA GPU, это плохо, в будущем хочется улучшения этой ситуации. Пока мы используем NVIDIA GPU.

26
00:03:37,090 --> 00:03:43,139
Скорее всего, на вашем ноутбуке такого нет — если, конечно, вы не покупали специальный игровой ноутбук.

27
00:03:44,889 --> 00:03:57,839
Поэтому, скорее всего, вам понадобится арендовать GPU. У нас есть хорошие новости — это просто и дешёво.

28
00:03:58,569 --> 00:04:09,239
Я покажу вам пару вариантов. Первый из этих вариантов, вероятно, самый простой, называется Crestle.

29
00:04:09,879 --> 00:04:20,038
Если вы зайдёте на crestle.com и нажмёте на Зарегистрироваться/Войти, то увидите на экране что-то вроде этого.

30
00:04:20,229 --> 00:04:29,429
Здесь есть большая кнопка Запустить Jupyter и тумблер Включить GPU. Перед запуском убедимся, что тумблер включён,

31
00:04:29,560 --> 00:04:40,619
нажмём на кнопку и увидим, что запустился Jupyter ноутбук.

32
00:04:41,139 --> 00:04:50,730
Jupyter ноутбуки в недавнем опросе были названы третьим по важности инструментом для анализа данных.

33
00:04:51,190 --> 00:04:55,799
Очень важно с ними разобраться, потому что все наши курсы используют Jupyter ноутбуки.

34
00:04:56,320 --> 00:04:58,260
Да, Рейчел?

35
00:04:58,260 --> 00:05:04,439
Рейчел: Я просто хотела уточнить, что у Crestle есть пробный период 10 часов, поэтому вам не придётся платить сразу.

36
00:05:08,530 --> 00:05:14,250
Да, количество бесплатных часов могло измениться, вы можете проверить это на сайте, но какое-то количество точно есть.

37
00:05:15,190 --> 00:05:21,719
Сейчас цена может быть другой, это зависит от цен на веб-сервисы Amazon, но на текущий момент это 59 центов в час.

38
00:05:23,080 --> 00:05:31,979
Приятно, что можно менять настройки и запускать ноутбук без GPU и платить в десять раз меньше.

39
00:05:34,229 --> 00:05:39,149
Мы будем использовать Jupyter ноутбуки на протяжении всего курса. Чтобы начать,

40
00:05:39,150 --> 00:05:49,450
мы найдём папку нашего курса. Перейдём в папку courses, затем переходим в папку fastai2, и вот мы на месте.

41
00:05:49,450 --> 00:05:53,399
Структура файлов может незначительно меняться со временем,

42
00:05:54,039 --> 00:05:57,719
мы будем выкладывать информацию об обновлениях на нашем сайте.

43
00:05:59,590 --> 00:06:03,510
Это была демонстрация первого варианта аренды GPU, Crestle.

44
00:06:04,360 --> 00:06:08,039
Как вы видите, всё происходит мгновенно и выглядит просто,

45
00:06:09,460 --> 00:06:18,660
но если у вас есть лишний час на то, чтобы обустроиться, есть вариант лучше — Paperspace.

46
00:06:22,690 --> 00:06:27,809
Paperspace, в отличие от Crestle, не базируется на сервисах Amazon. У них свои собственные машины.

47
00:06:32,889 --> 00:06:38,429
Если я зайду на их сайт и нажму на кнопку Новая машина,

48
00:06:39,459 --> 00:06:45,299
я смогу выбрать один из трёх датацентров. Предпочтительнее выбирать ближайший, поэтому я выберу Западное побережье,

49
00:06:46,569 --> 00:06:50,549
Linux, Ubuntu 16.

50
00:06:52,269 --> 00:07:00,279
Затем мы переходим на страницу выбора машины, здесь много опций. Оплата производится почасово,

51
00:07:00,279 --> 00:07:06,898
есть хорошая опция за 40 центов в час, это дешевле, чем Crestle,

52
00:07:06,899 --> 00:07:14,099
и быстрее. Машина за 65 центов в час будет гораздо быстрее Crestle.

53
00:07:14,499 --> 00:07:24,658
Я покажу пошагово, как начать работать с Paperspace, потому что здесь всё создаётся с нуля.

54
00:07:25,419 --> 00:07:32,549
Если вы закажете машину за 65 центов, возможно, вам придётся написать в Paperspace и объяснить, зачем она вам нужна —

55
00:07:32,860 --> 00:07:38,429
так компания защищается от мошенников. Если вы скажете, что это для курса fast.ai,

56
00:07:39,339 --> 00:07:45,389
они предоставят вам машину. Я возьму самую дешёвую опцию за 40 центов в час.

57
00:07:48,939 --> 00:07:51,689
Можно выбрать необходимое количество места на жёстком диске.

58
00:07:52,749 --> 00:07:57,449
Тут надо осторожнее — оплата за месяц снимается сразу при запуске машины,

59
00:07:57,449 --> 00:08:01,378
поэтому не стоит запускать и сразу останавливать машины, потому что каждый раз снимается плата за месяц.

60
00:08:01,990 --> 00:08:09,569
Опция «250 ГБ за $7» выглядит неплохо, но нам понадобится только 50 ГБ, если хотите сэкономить, берите эту опцию.

61
00:08:11,649 --> 00:08:17,549
Последняя вещь, которую нужно будет сделать — включить публичный IP адрес, чтобы иметь доступ к машине.

62
00:08:17,919 --> 00:08:21,718
Можно отключить опцию Snapshot, чтобы сэкономить на бэкапах.

63
00:08:27,950 --> 00:08:33,970
Если нажать кнопку Создать Paperspace, где-то через минуту

64
00:08:35,360 --> 00:08:40,390
появится ваша машина, здесь видно мою машину Ubuntu 16.04.

65
00:08:41,810 --> 00:08:54,370
На вашу почту отправлен пароль для доступа к машине.

66
00:08:54,950 --> 00:09:01,960
Чтобы вставить пароль, вам понадобится нажать Ctrl+Shift+V или Command+Shift+V на компьютерах Apple.

67
00:09:03,170 --> 00:09:07,479
Это слегка отличается от обычной вставки. Конечно, вы можете просто перепечатать пароль.

68
00:09:10,550 --> 00:09:17,750
У нас есть доступ к машине. Можно увеличить рабочее пространство, нажав на стрелочки.

69
00:09:17,750 --> 00:09:26,020
Как видите, у нас есть терминал внутри браузера, довольно удобно.

70
00:09:26,170 --> 00:09:32,979
Теперь нужно настроить машину, чтобы работать с нашим курсом. Для этого нужно ввести

71
00:09:34,790 --> 00:09:49,670
curl http://files.fast.ai/setup/paperspace | bash

72
00:09:49,670 --> 00:09:56,560
Это запустит скрипт, который установит необходимые CUDA драйвера,

73
00:09:58,160 --> 00:10:06,460
Anaconda — используемый нами дистрибутив Python, все необходимые библиотеки, другие курсы

74
00:10:07,100 --> 00:10:14,950
и данные, которые понадобятся для первой части курса. Это займёт около часа,

75
00:10:15,290 --> 00:10:17,560
после установки нужно перезагрузить машину.

76
00:10:18,170 --> 00:10:24,219
Для того, чтобы перезапустить машину Paperspace, нужно нажать на кнопку перезагрузки.

77
00:10:24,620 --> 00:10:30,969
Когда машина перезагрузится, на ней появятся

78
00:10:32,870 --> 00:10:35,710
директория anaconda3, здесь лежит ваш Python,

79
00:10:35,710 --> 00:10:44,629
директория data с данными для первой части курса, здесь данные для первой лекции — директория dogscats,

80
00:10:45,269 --> 00:10:52,369
и директория fastai, которая содержит всё необходимое для курса.

81
00:10:52,920 --> 00:10:57,050
Вам нужно перейти в папку fastai командой cd fastai.

82
00:10:57,389 --> 00:11:05,990
Периодически нужно делать git pull, чтобы убедиться, что все файлы внутри этой папки свежие.

83
00:11:06,480 --> 00:11:10,759
Ещё нужно иногда проверять, что на машине стоят последние версии используемых библиотек —

84
00:11:10,769 --> 00:11:15,980
это можно сделать командой conda env update.

85
00:11:16,050 --> 00:11:24,679
Окей, убедитесь, что вы находитесь в папке fastai, и выполните команду jupyter notebook.

86
00:11:26,910 --> 00:11:31,249
Jupyter ноутбук запущен на сервере.

87
00:11:31,249 --> 00:11:36,289
Теперь мы хотим к нему подключиться. Сервер подсказывает нам строку подключения.

88
00:11:37,350 --> 00:11:48,230
Если щёлкнуть по строке дважды, она скопируется в буфер обмена.

89
00:11:48,689 --> 00:11:52,879
Теперь можно вставить её, но перед этим нужно поменять localhost

90
00:11:53,730 --> 00:12:01,429
на IP адрес машины в Paperspace, его можно увидеть, уменьшив экран.

91
00:12:02,009 --> 00:12:16,369
Копируем и вставляем вместо слова localhost. Мы подключились к ноутбуку.

92
00:12:16,529 --> 00:12:23,269
Мы находимся внутри git-репозитория fastai, все курсы находятся в папке courses.

93
00:12:23,939 --> 00:12:27,349
Первая часть нашего курса лежит в папке dl1,

94
00:12:28,170 --> 00:12:34,100
В ней лежит Jupyter ноутбук по первой лекции, lesson1.ipynb.

95
00:12:39,410 --> 00:12:45,459
Итак, у вас запущен Jupyter ноутбук, неважно, через Crestle или через Paperspace.

96
00:12:45,460 --> 00:12:51,100
На courses.fast.ai я буду выкладывать дополнительные видео и информацию про другие способы

97
00:12:51,650 --> 00:12:55,930
запустить Jupyter ноутбук на арендованном сервере.

98
00:12:57,500 --> 00:13:06,130
Чтобы запустить ячейку в Jupyter ноутбуке, нужно выбрать эту ячейку и нажать Shift+Enter,

99
00:13:06,740 --> 00:13:14,290
или, если у вас включена панель инструментов, нажать кнопку запуска.

100
00:13:15,080 --> 00:13:22,869
Некоторые ячейки содержат код, некоторые — тест, изображения, видео. Как видите, Jupyter ноутбук —

101
00:13:23,870 --> 00:13:36,400
среда окружения, позволяющая проводить эксперименты и сразу видеть результаты,
поэтому она так популярна.

102
00:13:36,920 --> 00:13:42,550
Анализ данных по сути заключается в том, чтобы проводить эксперименты над данными.

103
00:13:44,090 --> 00:13:53,259
При запуске ячейки индикатор меняется на звёздочку при выполнении и показывает номер ячейки после выполнения.

104
00:13:53,260 --> 00:14:06,639
То же самое можно выполнить нажатием Shift+Enter. Можно продолжить нажимать ту же комбинацию и ячейки будут выполняться последовательно.

105
00:14:06,830 --> 00:14:15,220
В ячейке можно выполнить любую команду — например, 1+1 равняется 2.

106
00:14:15,560 --> 00:14:17,739
Итак, мы собираемся...

107
00:14:18,590 --> 00:14:24,849
Да, Рейчел? Рейчел: Хочу уточнить, что мы используем Python 3.

108
00:14:24,850 --> 00:14:37,540
Да, спасибо. Мы используем Python 3 и нужно переключиться на него с Python 2, если вы этого ещё не сделали. Это требуется в нашем курсе,

109
00:14:38,660 --> 00:14:44,080
и в принципе многие библиотеки перестают поддерживать Python 2.

110
00:14:45,440 --> 00:14:47,440
Спасибо, Рейчел.

111
00:14:48,499 --> 00:14:53,988
В ноутбуке написано, откуда вы можете скачать данные для этой лекции.

112
00:14:55,379 --> 00:15:03,709
Если вы использовали Crestle или Paperspace и запустили скрипт, эти данные уже доступны и их не надо скачивать.

113
00:15:03,709 --> 00:15:06,138
В противном случае скачайте их, используя команду wget.

114
00:15:07,169 --> 00:15:17,639
Crestle медленнее Paperspace и поддерживает не все нужные нам библиотеки,

115
00:15:17,639 --> 00:15:23,718
поэтому при использовании Crestle вам нужно будет исполнить ещё две ячейки.

116
00:15:24,029 --> 00:15:31,480
Строки в ячейках закомментированы, перед выполнением нужно их откомментировать.

117
00:15:31,680 --> 00:15:37,220
Я использую Paperspace, поэтому не буду этого делать.

118
00:15:38,640 --> 00:15:47,928
Итак, мы видим переменную окружения {PATH}, её значение равно data/dogscats/.

119
00:15:47,929 --> 00:15:52,579
Эта переменная была создана для вас. Я использую восклицательный знак, чтобы

120
00:15:53,849 --> 00:16:00,139
показать, что эта ячейка должна исполнять не Python, а bash.

121
00:16:00,139 --> 00:16:04,938
Я хочу запустить shell, исполнить команду на bash. Внутри фигурных скобок —

122
00:16:05,759 --> 00:16:11,058
переменная Python, которая вставляется в команду bash.

123
00:16:11,339 --> 00:16:13,848
Что внутри нашей рабочей директории?

124
00:16:14,099 --> 00:16:21,079
Обучающая выборка и валидационная выборка. Если вам незнакомы эти термины,

125
00:16:21,539 --> 00:16:27,079
ознакомьтесь с нашим практическим курсом «Машинное обучение»,

126
00:16:27,149 --> 00:16:35,448
в нём рассказываются основы того, как настраивать и запускать проекты машинного обучения.

127
00:16:36,659 --> 00:16:40,369
Рейчел: Рекомендуете пройти курс «Машинное обучение» перед тем, как проходить этот?

128
00:16:41,009 --> 00:16:53,269
Многие студенты, проходящие параллельно курс «Машинное обучение», сказали, что им понравилось, поэтому можете посмотреть.

129
00:16:55,799 --> 00:16:59,148
Оба курса говорят про похожие вещи, но различаются.

130
00:16:59,149 --> 00:17:05,689
Люди, которые прошли оба, говорят, что они дополняют друг друга, но я бы не сказал, что проходить оба обязательно.

131
00:17:06,659 --> 00:17:11,149
Тем не менее, если вам незнакомы термины тренировочная и валидационная выборка —

132
00:17:11,150 --> 00:17:23,270
погуглите, мы предполагаем, что базовые понятия машинного обучения вам известны.

133
00:17:23,279 --> 00:17:26,719
Рейчел: У меня в блоге есть целый пост на эту тему.

134
00:17:26,720 --> 00:17:29,809
Да, ссылка на него будет на course.fast.ai.

135
00:17:29,990 --> 00:17:36,289
В принципе наша философия на fast.ai — узнавать новое по ходу дела.

136
00:17:36,809 --> 00:17:39,979
Да,  иначе вы никогда не доберётесь до по-настоящему интересных вещей.

137
00:17:40,079 --> 00:17:49,789
Рейчел: Да, я думаю, в глубоком обучении это особенно заметно.

138
00:17:50,460 --> 00:18:00,409
В директории valid — папки cats и dogs, в папке cats — пачка изображений.

139
00:18:01,409 --> 00:18:15,079
Это традиционный подход представления начальных данных для задачи классификации изображений —

140
00:18:15,419 --> 00:18:23,560
изображения с котами лежат в папке cats, изображения с собаками в папке dogs.

141
00:18:23,600 --> 00:18:36,960
С размеченными таким способом изображениями работает Keras, это классический способ хранить файлы.

142
00:18:36,960 --> 00:18:44,000
Можно увидеть пример изображения с котом, набрав plt.imgshow(img).

143
00:18:45,929 --> 00:18:57,049
Это форматирование строки в стиле  Python 3.6, очень удобно, мы часто такое используем.

144
00:18:58,590 --> 00:19:05,149
Вот кошка, но нас интересует не она, а то, из каких данных она состоит.

145
00:19:05,789 --> 00:19:23,870
Изображение  имеет размерность 198x179x3, это трёхмерная матрица. Вот первые четыре ряда и колонки.

146
00:19:24,930 --> 00:19:42,349
Видно, что каждая пара квадратных скобок содержит три числа от 0 до 255, которые характеризуют цвет пикселя в системе RGB.

147
00:19:43,320 --> 00:19:56,629
Идея в том, чтобы научиться на основе наших данных предсказывать, кошка или собака закодирована такими числами.

148
00:19:56,630 --> 00:20:17,150
Это довольно сложно сделать — когда этот датасет был выложен на конкурсе Kaggle в 2012 году, точность 80% считалась хорошей,

149
00:20:17,370 --> 00:20:20,060
компьютеры плохо умели отличать котов от собак.

150
00:20:21,180 --> 00:20:34,550
Давайте обучать  модель. Этих трёх строк кода достаточно для простой модели.

151
00:20:35,250 --> 00:20:50,780
Давайте запустим ячейку и подождём её выполнения.

152
00:20:51,690 --> 00:21:02,509
Я указал количество эпох в методе learn.fit равным 3, это значит, что модель рассмотрит каждое изображение трижды.

153
00:21:02,609 --> 00:21:11,329
При выполнении ячейки выводится точность в каждой эпохе, последний столбец — доля правильных ответов на валидационной выборке.

154
00:21:12,180 --> 00:21:23,359
Другие две колонки обсудим позже, это значения функции потерь на обучающей и валидационной выборках. Нулевая колонка — номер эпохи.

155
00:21:23,700 --> 00:21:38,450
Доля правильных ответов получается больше 90%, на обучение ушло 17 секунд — сильное улучшение с 2012 года.

156
00:21:39,420 --> 00:21:49,020
Эти три строки кода выиграли бы соревнование Kaggle — победитель достиг точности 98.9%, у нас же — почти 99%.

157
00:21:49,020 --> 00:22:07,250
Вас может удивить, что мы смогли превзойти уровень победителя соревнования Kaggle в 2012 за 17 секунд и три строки кода.

158
00:22:08,340 --> 00:22:23,389
Многие люди считают, что глубокое обучение требует большого количества времени, ресурсов и данных, и в этом курсе вы поймёте, что в общем случае это не так.

159
00:22:24,330 --> 00:22:53,749
Этот код простой, потому что использует нашу библиотеку fast.ai — в ней мы собираем все лучшие современные практики после тестирования на различных датасетах и тюнинга.

160
00:22:53,790 --> 00:23:03,380
Наша библиотека позволяет автоматически выбирать лучший подход к задаче.

161
00:23:04,050 --> 00:23:07,430
Именно благодаря ей мы и смогли написать этот код всего в три строчки.

162
00:23:08,040 --> 00:23:18,720
Библиотека fast.ai работает быстро, потому что она разработана на базе PyTorch —

163
00:23:18,720 --> 00:23:25,430
разработанной Facebook гибкой библиотеки для проведения расчётов для машинного обучения.

164
00:23:27,630 --> 00:23:41,749
Большинству людей привычнее TensorFlow, потому что Google его продвигает, но лучшие из моих знакомых исследователей перешли на PyTorch. Да, Рейчел?

165
00:23:42,500 --> 00:23:47,479
Рейчел: Про PyTorch мы ещё будем говорить позже.
Да, я надеюсь, что

166
00:23:48,929 --> 00:24:02,089
fast.ai вам понравится тем, что вы можете контролировать использование подобранных нами практик и легко написать что-то своё —

167
00:24:02,700 --> 00:24:12,049
алгоритм приращения данных, функцию потерь, архитетуру нейронной сети. Всё это мы сделаем в этом курсе.

168
00:24:12,210 --> 00:24:22,099
Чтобы понять, как выглядит модель, посмотрим на валидационную выборку.

169
00:24:22,620 --> 00:24:28,279
Целевая переменная y — массив из нулей и единиц.

170
00:24:28,379 --> 00:24:34,039
Как видно, нули показывают принадлежность к классу cats, единицы — классу dogs.

171
00:24:34,039 --> 00:24:44,209
Работа ведётся с двумя объектами — data, который содержит обучающую и валидационную выборки, и learn, который содержит модель.

172
00:24:44,669 --> 00:24:47,809
В любой момент можно посмотреть, как устроены данные.

173
00:24:49,350 --> 00:24:57,780
Чтобы получить предсказания на основе валидационной выборки, вызовем метод predict().

174
00:24:57,780 --> 00:25:05,239
Посмотрим на первые десять предсказаний. Первый столбец — логарифм вероятности того, что на изображении кошка, второй — что собака.

175
00:25:05,549 --> 00:25:19,908
В PyTorch большинство моделей возвращают логарифм вероятности вместо самой вероятности, позже мы обсудим, почему.

176
00:25:20,100 --> 00:25:28,830
Чтобы перевести вероятности в привычный формат, вызовем метод numpy.exp().

177
00:25:28,830 --> 00:25:36,289
Мы используем numpy и предполагаем, что вы с ним работали.

178
00:25:36,870 --> 00:25:43,039
Если это не так, просмотрите пост про основы numpy на course.fast.ai.

179
00:25:43,440 --> 00:25:54,859
С помощью numpy Python быстро и эффективно выполняет вычисления, операции с массивами и тому  подобное.

180
00:25:56,090 --> 00:26:02,110
Итак, мы получаем вероятности с помощью метода numpy.exp().

181
00:26:02,390 --> 00:26:07,420
В этих ячейках - функции для вывода картинок, можете изучить их, если интересно.

182
00:26:08,750 --> 00:26:20,139
С их помощью можно отрисовать правильно распознанные изображения.

183
00:26:20,140 --> 00:26:29,409
Напоминаю, что 1 — собака, 0 — кошка, поэтому вероятность больше 0.5 — собака, меньше 0.5 — кошка.

184
00:26:30,320 --> 00:26:32,320
Посмотрим на неправильно распознанные изображения.

185
00:26:32,510 --> 00:26:40,299
Видно, что есть изображения, которых вообще не должно быть в датасете,

186
00:26:41,480 --> 00:26:48,399
но, очевидно, это изображение, классифицированное как собака — совсем не собака, есть грубые ошибки.

187
00:26:51,230 --> 00:27:02,379
Также можно посмотреть, какие кошки, по мнению модели, больше всего похожи на кошек, и то же для собак.

188
00:27:03,860 --> 00:27:18,579
Интереснее смотреть на то, каких кошек и собак модель посчитала больше всего непохожими на себя.

189
00:27:19,130 --> 00:27:22,510
Видно, что в датасете есть странные изображения, тут вроде действительно есть собака. Да, Рейчел?

190
00:27:22,510 --> 00:27:26,710
Рейчел: Расскажи про то, почему ты смотришь на свои данные.

191
00:27:27,950 --> 00:27:38,590
Да, сейчас. Последняя ячейка с картинками — самые спорные изображения, вероятность близка к 0.5.

192
00:27:38,590 --> 00:27:44,169
Модель не знает, что делать с такими изображениями — и это неудивительно.

193
00:27:46,310 --> 00:27:56,649
Так вот, про данные. Первое, что я делаю после построения модели — пробую посмотреть, что она делает.

194
00:27:57,800 --> 00:28:05,769
Если я хочу усовершенствовать модель, нужно улучшить вещи, которые она делает хорошо и исправить те, которые она делает плохо.

195
00:28:07,640 --> 00:28:14,509
В процессе разглядывания модели я выяснил, что в датасете есть лишние изображения,

196
00:28:16,470 --> 00:28:22,760
и увидел, что модели ещё есть куда развиваться.

197
00:28:23,310 --> 00:28:44,150
Например, здесь очевидно собака. Но изображение широкое и невысокое, а модель перед работой обрезает изображение до квадратного.

198
00:28:45,320 --> 00:28:53,180
Возможно, для улучшения модели нам придётся применить приращение данных — про это мы поговорим позже.

199
00:28:55,470 --> 00:29:22,789
Итак, у нас есть классификатор. Попробуйте найти пару картинок, положить их в разные папки и прогнать на них те же три строки кода.

200
00:29:23,250 --> 00:29:37,970
Вы увидите, что модель хорошо сработает и на ваших изображениях — если это обычные фотографии,

201
00:29:38,880 --> 00:29:48,140
а не снимки с микроскопа, томографические снимки или тому подобное, мы обсудим этот нюанс позже.

202
00:29:48,140 --> 00:30:06,469
Для обычных фотографий используйте наши три строки кода, можете поменять переменную PATH на вашу директорию и получить готовый классификатор.

203
00:30:07,230 --> 00:30:23,270
Один студент взял эти три строки, по десять изображений людей, играющих в крикет и бейсбол соответственно, и построил почти идеальный классификатор.

204
00:30:23,970 --> 00:30:40,640
Также он построил модель на семи изображениях канадской валюты и семи — американской и получил стопроцентную точность.

205
00:30:40,860 --> 00:30:48,320
Вы тоже можете скачать из Google пару изображений, попробовать, посмотреть, что работает и рассказать про свои успехи и неудачи на нашем форуме.

206
00:30:52,320 --> 00:31:04,500
Итак, мы только что обучили нейронную сеть, но не объяснили, что это значит.

207
00:31:04,500 --> 00:31:11,149
Это демонстрирует подход к обучению «сверху вниз», о котором говорилось раньше.

208
00:31:11,580 --> 00:31:23,480
Идея в том, чтобы сначала показать вам, как обучить классификатор, и по ходу дела углубляться в теорию,

209
00:31:24,420 --> 00:31:35,089
вместо того, чтобы отдалять этот момент три года, выдавая всю необходимую теорию маленькими порциями,

210
00:31:35,090 --> 00:31:42,750
как это часто делают в преподавании технических предметов.

211
00:31:42,750 --> 00:31:53,330
По ходу курса будут появляться новые проблемы. Например, на следующей лекции

212
00:31:53,330 --> 00:32:06,830
вместо обычных фотографий мы рассмотрим спутниковые снимки. На них наша модель будет работать хуже,

213
00:32:07,020 --> 00:32:20,460
мы посмотрим, что надо изменить, поймём, почему это нужно сделать и какие библиотеки для этого нужны.

214
00:32:20,460 --> 00:32:31,730
Таким образом, с каждой новой задачей мы будем лучше понимать теорию и овладевать библиотеками,

215
00:32:32,310 --> 00:32:45,000
а в конце с нуля создадим все элементы нейронной сети мирового класса.

216
00:32:45,850 --> 00:32:48,730
В этом общая идея. Да, Рейчел?

217
00:32:48,730 --> 00:32:57,450
Рейчел: Гарвардский профессор Дэвид Перкинс называет этот подход «вся игра».

218
00:32:57,450 --> 00:33:01,769
Да, «вся игра» — это как баскетбол или музыка.

219
00:33:01,770 --> 00:33:09,450
Знакомясь с баскетболом, вы приходите на игру, пробуете играть сами, и, возможно,

220
00:33:09,700 --> 00:33:15,569
спустя годы наконец начинаете изучать физику закручивания мяча в полёте.

221
00:33:15,610 --> 00:33:22,170
То же и с музыкой — вам дают музыкальный инструмент и вы пробуете играть на нем,

222
00:33:22,170 --> 00:33:29,159
и только годы спустя узнаете про квинтовый круг тональностей и каденции.

223
00:33:30,460 --> 00:33:37,679
Подход такой, да, мы вдохновлялись идеями Дэвида Перкинса и других.

224
00:33:38,710 --> 00:33:48,599
Ещё один способ понять эту идею — представить себе задачу как множество слоёв, которые мы будем снимать один за другим,

225
00:33:48,910 --> 00:33:52,800
и в процессе вы будете экспериментировать, это программистский подход.

226
00:33:53,380 --> 00:33:57,030
Структура курса такая:

227
00:33:57,910 --> 00:34:01,859
сегодня мы посмотрим на свёрточные нейронные сети (CNN),

228
00:34:01,860 --> 00:34:07,709
потом посмотрим, как использовать нейронные сети для интерпретации структурированных данных,

229
00:34:07,710 --> 00:34:11,189
затем на рекуррентные нейронные сети (RNN) в анализе текста и, наконец, на рекомендательные системы.

230
00:34:12,280 --> 00:34:17,969
Затем возьмём эти четыре темы и пройдёмся по ним углубленно в другом порядке.

231
00:34:17,970 --> 00:34:22,140
Таким образом, к концу четвёртого блока вы узнаете, как

232
00:34:23,500 --> 00:34:32,250
построить классификатор мирового уровня, разработать программу для анализа структурированных данных,

233
00:34:32,770 --> 00:34:36,659
классификатор текста мирового уровня и рекомендательную систему мирового уровня.

234
00:34:37,090 --> 00:34:41,279
В дальнейших частях вы будете делать те же вещи, но узнаете их глубже —

235
00:34:41,280 --> 00:34:47,550
что именно они делают, как они работают, что можно поменять, как их можно применять в различных ситуациях —

236
00:34:48,130 --> 00:34:56,739
опять же, это будут рекомендательная система, изучение структурированных данных, изображения и анализ текста.

237
00:34:56,740 --> 00:35:06,110
Смысл такой структуры в том, что студенты обычно пересматривают видео-лекции несколько раз подряд,

238
00:35:06,110 --> 00:35:18,310
при этом просматривая весь курс подряд, а не повторяя каждую лекцию сразу после просмотра.

239
00:35:19,460 --> 00:35:23,740
Это помогает сначала уловить общую суть, а потом вернуться назад к уточнению деталей.

240
00:35:24,020 --> 00:35:39,070
Поэтому я советую вам смотреть лекции без лишней концентрации на деталях.

241
00:35:41,510 --> 00:35:52,269
За сегодняшнюю лекцию вы с минимальным количеством строк кода и минимальным количеством деталей

242
00:35:52,270 --> 00:36:01,749
обучите классификатор изображений, в конкретном случае для разделения изображений кошек и собак.

243
00:36:03,200 --> 00:36:15,800
На второй лекции рассмотрим спутниковые снимки и посмотрим, какие объекты на них присутствуют —

244
00:36:15,900 --> 00:36:23,420
это задача мультиклассовой классификации.

245
00:36:23,420 --> 00:36:39,610
К третьей лекции перейдём к самому широко применимому навыку — работа со структурированными данными, например, таблицами в базах данных.

246
00:36:39,610 --> 00:36:48,800
Работать будем с этими данными по продажам — признаками будут разные магазины, даты, наличие или отсутствие праздников,

247
00:36:48,800 --> 00:36:55,600
а предсказывать будем будущие продажи.

248
00:36:56,510 --> 00:37:05,140
На четвёртой лекции перейдём к тексту и выясним, что люди думают про фильм Zombiegeddon —

249
00:37:05,360 --> 00:37:16,659
по аналогии с классификаторами картинок можно создавать классификаторы текста.

250
00:37:19,100 --> 00:37:23,860
На пятой лекции рассмотрим коллаборативную фильтрацию — она в основном используется в рекомендательных системах.

251
00:37:24,320 --> 00:37:32,769
Работать будем с данными, содержащими оценки фильмов людьми, вот примеры.

252
00:37:33,440 --> 00:37:45,340
Простой способ представить эти данные — в виде такой таблицы.

253
00:37:45,340 --> 00:37:55,690
Предсказывать будем рейтинг фильма для тех пользователей, которые его ещё не видели.

254
00:37:55,970 --> 00:37:59,470
Коллаборативная фильтрация помогает решать проблему того, какой контент показать посетителям вашего сайта,

255
00:37:59,540 --> 00:38:03,910
какую книгу или фильм порекомендовать для чтения/просмотра.

256
00:38:05,840 --> 00:38:20,890
На шестой лекции мы вернёмся к анализу текстов и научимся генерировать афоризмы в духе Ницше.

257
00:38:21,320 --> 00:38:27,309
Например, отрывок «Вероятно, что каждая жизнь значений крови соития, когда она чувствует беспринципность и его права, и импульс, любовь?» —

258
00:38:27,310 --> 00:38:39,160
не настоящий Ницше, а афоризм в его стиле, созданный рекуррентной нейронной сетью.

259
00:38:41,060 --> 00:38:44,680
На седьмой лекции мы вернёмся к компьютерному зрению и обучим модель

260
00:38:45,230 --> 00:38:50,680
не только различать кошек и собак, но и понимать, где на изображении они находятся, с помощью таких тепловых карт.

261
00:38:50,810 --> 00:38:57,790
В этой же лекции мы напишем свою архитектуру нейронной сети, на экране — ResNet,

262
00:38:57,890 --> 00:39:09,910
пример архитектуры, которую мы будем использовать сегодня и которую построим с нуля позже.

263
00:39:09,910 --> 00:39:21,099
Итак, такими и будут этапы нашего курса, и на каждом этапе мы будем всё больше углубляться в технические детали.

264
00:39:24,559 --> 00:39:41,119
Многие студенты с прошлых запусков курса говорили, что потратили слишком много времени на иучение теории

265
00:39:41,119 --> 00:39:55,119
и слишком мало времени на практическую часть. Люди жалеют, что не вняли нашим советам экспериментировать с ячейками кода.

266
00:39:55,670 --> 00:39:59,319
На экране комментарии с нашего форума:

267
00:39:59,319 --> 00:40:07,750
«Надо было больше времени тратить на код в ноутбуках, запускать его и смотреть, что получается.»

268
00:40:10,430 --> 00:40:21,579
Идея, что через программистский подход можно научиться создавать модели мирового класса,

269
00:40:21,579 --> 00:40:24,619
сильно отличается от рекомендаций, которые можно найти на других форумах.

270
00:40:25,920 --> 00:40:35,949
Пользователь с Hacker News говорит, что лучший способ стать ML-специалистом — выучить всю математику, C и C++,

271
00:40:36,500 --> 00:40:41,979
параллельное программирование, воплощать все алгоритмы сначала на чистом C... И только потом начать заниматься машинным обучением.

272
00:40:42,500 --> 00:40:50,260
Если вы хотите хороших практических результатов, мы советуем делать ровно наоборот.

273
00:40:50,900 --> 00:40:59,979
Да, Рейчел? Рейчел: Хочу уточнить, что на экране сейчас — вредные советы, они убивают всю мотивацию у людей.

274
00:41:00,049 --> 00:41:09,140
Да. К текущему моменту уже десятки тысяч закончили этот курс и многие из них сейчас

275
00:41:09,140 --> 00:41:22,869
занимаются исследованиями в лабораториях, участвуют в программе Google Brain Residency, создают патенты на основе глубокого обучения.

276
00:41:23,450 --> 00:41:27,730
Подход «сверху вниз» работает отлично.

277
00:41:27,859 --> 00:41:47,419
Уточню одну вещь про уже построенную нами модель — первый запуск длится дольше 17 секунд по двум причинам.

278
00:41:47,849 --> 00:41:57,359
Первая — сначала из интернета скачивается уже обученная модель, это занимает одну-две минуты.

279
00:41:57,359 --> 00:42:08,569
Вторая — при первом запуске вычисляются и кэшируются необходимые промежуточные данные, минуты полторы.

280
00:42:09,180 --> 00:42:17,839
Поэтому первый запуск может занять три-четыре минуты, но последующие запуски ячейки займут около 20 секунд.

281
00:42:18,569 --> 00:42:38,058
Пример с кошками и собаками может показаться вам бесполезным — вы и сами умеете это делать, но спектр применения таких алгоритмов широкий.

282
00:42:39,720 --> 00:42:56,359
Например, в корне модели AlphaGo, победившей лучших игроков мира в го — то же, что и в нашей модели.

283
00:42:56,880 --> 00:43:07,220
Модель обучали на тысячах выигрышных и проигрышных позиций на доске,

284
00:43:08,099 --> 00:43:17,450
и в итоге получился классификатор изображений, позволяющий отделять плохие позиции от хороших.

285
00:43:17,730 --> 00:43:25,730
А это самый важный навык при игре в го — понимать, какой ход лучше сделать.

286
00:43:27,809 --> 00:43:39,980
Один из наших студентов оформил пару патентов на свою работу по выявлению мошенничества.

287
00:43:40,880 --> 00:43:52,549
На многих сайтах отслеживаются движения курсора мыши для предотвращения мошенничества,

288
00:43:53,339 --> 00:44:01,788
он взял движения курсоров, записал траектории с учётом скорости движения как картинки

289
00:44:02,579 --> 00:44:06,379
и построил классификатор изображений, который принимал эти траектории и говорил,

290
00:44:07,049 --> 00:44:18,889
намеревается ли управляющий курсором человек смошенничать. И результаты были неплохие.

291
00:44:20,130 --> 00:44:26,240
Как видите, многие задачи сводимы к задаче классификации изображений.

292
00:44:26,519 --> 00:44:46,279
Это один из примеров использования глубокого обучения. Глубокое обучение и машинное обучение — не одно и то же.

293
00:44:47,400 --> 00:44:50,389
Скорее, глубокое обучение — это раздел машинного обучения.

294
00:44:50,819 --> 00:44:56,778
Артур Сэмюэл изобрёл машинное обучение.

295
00:44:57,089 --> 00:45:06,980
В конце 50-х годов он научил IBM обыгрывать себя в шашки.

296
00:45:07,859 --> 00:45:15,679
Он заставил машину играть с собой и отслеживать, какие ходы ведут к победе, а какие к поражению,

297
00:45:16,049 --> 00:45:19,309
и использовал эти результаты для написания своей программы.

298
00:45:19,710 --> 00:45:34,639
В 1962 он сказал, что наступит день, когда большинство программ будет написано с использованием машинного обучения.

299
00:45:35,400 --> 00:45:41,180
Я думаю, что этот момент ещё не настал, но мы на верном пути.

300
00:45:41,789 --> 00:45:50,599
Традиционное машинное обучение было очень сложным и требовало много знаний и времени.

301
00:45:51,630 --> 00:45:57,559
Например, вычислительная диагностика.

302
00:45:58,560 --> 00:46:08,419
Эндрю Бек, когда он ещё был в Стэнфорде, — сейчас он в Гарварде, — работал над проблемой распознавания рака молочной железы.

303
00:46:09,360 --> 00:46:23,300
Он взял снимки биопсий молочной железы и вместе с командой патологов выявил различные признаки,

304
00:46:24,030 --> 00:46:45,890
влияющие на то, выживет пациент или нет — признаки вроде связи между ближайшими  эпителиальными клетками.

305
00:46:45,890 --> 00:46:59,660
Они придумали сотни признаков, команда программистов разработала способы выявлять эти признаки,

306
00:47:00,390 --> 00:47:06,949
и на их основе построили модель логистической регрессии, предсказывающую, выживет пациент или нет.

307
00:47:07,170 --> 00:47:31,130
Модель предсказывала лучше, чем живые патологи, но на это ушли годы работы большой команды экспертов.

308
00:47:31,920 --> 00:47:39,780
Хочется как-то попроще.

309
00:47:39,780 --> 00:47:53,010
Специфичная для задачи модель, требующая ручного выделения признаков экспертами в области — это неудобно.

310
00:47:53,010 --> 00:48:03,259
Мы попробуем найти функцию, которая сможет решить любую задачу при правильном выставлении параметров,

311
00:48:03,260 --> 00:48:11,210
разработать способ задавать эти параметры, и сделать нашу модель быстрой и масштабируемой.

312
00:48:11,610 --> 00:48:20,509
Если у нас будет такая модель, то не придётся привлекать экспертов и тратить время на ручное выделение признаков.

313
00:48:20,880 --> 00:48:27,230
Это за нас сделает модель.

314
00:48:27,330 --> 00:48:39,019
Как вы могли догадаться, алгоритмы, обладающие этими тремя признаками — это алгоритмы глубокого обучения.

315
00:48:40,560 --> 00:48:42,590
Рассмотрим эти признаки по очереди.

316
00:48:43,560 --> 00:48:49,519
Функция, лежащая в основе алгоритмов глубокого обучения, называется нейронная сеть.

317
00:48:50,460 --> 00:49:03,229
Позже мы построим с нуля свою нейронную сеть, пока достаточно знания того, что нейронная сеть состоит

318
00:49:04,230 --> 00:49:19,789
из перемежающихся линейных и нелинейных слоёв. Универсальная теорема аппроксимации гласит, что

319
00:49:20,010 --> 00:49:31,909
нейронная сеть с одним скрытым слоем может аппроксимировать любую непрерывную функцию с любой точностью.

320
00:49:32,400 --> 00:49:37,160
Поэтому нейронная сеть действительно удовлетворяет как функция первому признаку алгоритмов глубокого обучения.

321
00:49:38,520 --> 00:49:56,689
Для нахождения необходимых параметров во втором признаке мы используем градиентный спуск.

322
00:49:56,690 --> 00:50:11,719
Для каждого набора параметров мы знаем значение функции потерь и пытаемся найти оптимальный набор,

323
00:50:12,150 --> 00:50:20,220
немного меняя его, то есть двигаемся по поверхности возможных потерь вниз, как шарик, скатывающийся с горки.

324
00:50:20,220 --> 00:50:50,480
На этом рисунке итоговый результат зависит от точки начала, но для большинства задач глубокого обучения локальный минимум всего один.

325
00:50:51,900 --> 00:51:02,749
Итак, градиентный спуск подходит в качестве нахождения оптимального набора параметров.

326
00:51:04,830 --> 00:51:14,239
Проблема в том, что это нужно делать быстро. Здесь нам помогают GPU.

327
00:51:15,060 --> 00:51:23,929
На экране график прироста скорости GPU и CPU в гигафлопсах за последние несколько лет,

328
00:51:25,230 --> 00:51:31,459
GPU — красная и зелёная линии, CPU — синяя, шкала логарифмическая.

329
00:51:31,770 --> 00:52:06,890
Видно, что GPU примерно в 10 раз быстрее CPU. Сегодня GTX 1080 стоит $700, а E5-2699, который медленнее в 10 раз — $4115.

330
00:52:08,340 --> 00:52:25,610
Видно, что GPU помогут быстро и дёшево подбирать параметры нейронных сетей, они завершают список признаков.

331
00:52:27,750 --> 00:52:52,689
Универсальная теорема аппроксимации полагает, что у нейронной сети только один скрытый слой, как показано здесь,

332
00:52:53,210 --> 00:53:10,059
но в такой конфигурации сложность вычислений растёт экспоненционально, третий признак не выполняется.

333
00:53:11,359 --> 00:53:29,259
Если добавить несколько скрытых слоёв, можно улучшить точность и сохранить скорость для более сложных проблем —

334
00:53:29,990 --> 00:53:36,490
и вот тут машинное обучение переходит в глубокое обучение, глубокое обучение — нейронные сети с несколькими скрытыми слоями.

335
00:53:41,119 --> 00:53:51,220
Google начал инвестировать в глубокое обучение в 2012 году, пригласив основателя глубокого обучения Джеффри Хинтона

336
00:53:53,060 --> 00:54:07,300
и его лучшего студента Алекса Крижевского в команду, которая в будущем стала Google Brain.

337
00:54:08,660 --> 00:54:23,170
Алгоритмы глубокого обучения — мощные и гибкие, поэтому количество задействующих их проектов Google начало расти.

338
00:54:23,480 --> 00:54:30,939
График на экране кончается около 2016, но я знаю, что экспоненциальный рост продолжился.

339
00:54:31,460 --> 00:54:37,480
Теперь, как видите, Google использует глубокое обучение почти во всех своих продуктах.

340
00:54:38,180 --> 00:54:53,500
Интересно наблюдать за тем, как простое определение алгоритма глубокого обучения через три признака

341
00:54:53,990 --> 00:55:01,660
вырастает во что-то колоссальное, когда большая компания в это вкладывается.

342
00:55:03,200 --> 00:55:15,820
Например, при чтении письма в Gmail вам предлагается несколько готовых ответов —

343
00:55:16,370 --> 00:55:26,530
здесь Google использует глубокое обучение для чтения письма и генерации возможных откликов.

344
00:55:26,570 --> 00:55:33,610
Это отличный пример того, что раньше было невозможно.

345
00:55:34,610 --> 00:55:49,900
Ещё один пример — недавно Microsoft начали инвестировать в глубокое обучение. Теперь в Skype можно

346
00:55:50,210 --> 00:55:57,880
сказать фразу на английском, и Skype переведёт её вашему собеседнику на китайский или испанский,

347
00:55:58,340 --> 00:56:03,340
и наоборот — и всё это в режиме реального времени.

348
00:56:04,190 --> 00:56:09,129
Опять же, мы не смогли бы сделать это без глубокого обучения.

349
00:56:12,020 --> 00:56:18,680
Другой интересный вопрос — способы объединить глубокое обучение и человеческий опыт.

350
00:56:18,680 --> 00:56:26,139
Вот пример программы Neural Doodle, она была выпущена пару лет назад —

351
00:56:26,140 --> 00:56:33,339
она берёт на вход ваш набросок и переводит его в стиль выбранного художника.

352
00:56:34,040 --> 00:56:42,729
Вот картина, которая получилась при переводе наброска в стиль художника-импрессиониста.

353
00:56:43,970 --> 00:56:50,560
Я думаю, это отличный пример сочетания глубокого обучения и человеческого опыта.

354
00:56:54,340 --> 00:57:08,190
Несколько лет назад я хотел поэкспериментировать с применением глубокого обучения для решения важных проблем

355
00:57:08,740 --> 00:57:20,309
и выбрал диагностику рака лёгких. Оказывается, ранняя диагностика узелков в лёгких повышает шансы на выживание в 10 раз,

356
00:57:20,860 --> 00:57:27,510
поэтому важно уметь это делать. Я нашёл ещё троих человек без опыта работы в медицинской среде,

357
00:57:28,330 --> 00:57:34,319
мы нашли датасет, состоящий из томографических снимков, и использовали свёрточные нейронные сети,

358
00:57:35,020 --> 00:57:38,670
очень похожие на сети из сегодняшней лекции про разделение изображений кошек и собак,

359
00:57:39,490 --> 00:57:46,470
для предсказывания наличия недоброкачественной опухоли на снимке.

360
00:57:46,510 --> 00:57:50,669
Пару месяцев спустя наша модель стала допускать ошибки I и II рода (false positive и false negative) реже,

361
00:57:50,860 --> 00:58:03,840
чем команда из четырёх радиологов. Мы запустили стартап, и это вылилось в довольно успешную компанию Enlitic.

362
00:58:04,750 --> 00:58:13,380
С тех пор стало популярным использовать глубокое обучение для медицинской диагностики.

363
00:58:14,380 --> 00:58:30,660
Я заметил, что сейчас глубокое обучение мало где используется, но при первых попытках внедрения

364
00:58:30,880 --> 00:58:45,299
даёт фантастические результаты, и какое-то время спустя все в данной сфере начинают его использовать.

365
00:58:46,300 --> 00:58:57,700
Здесь я набросал пару идей для применения глубокого обучения — это вещи,

366
00:58:57,700 --> 00:59:06,150
на которые люди тратят много времени и сил, которые можно упростить. Список не полон,

367
00:59:06,180 --> 00:59:11,460
наверняка в вашей компании есть сферы, где можно применить глубокое обучение.

368
00:59:13,269 --> 00:59:22,139
Давайте посмотрим, что на самом деле произошло, когда мы обучили модель.

369
00:59:22,539 --> 00:59:29,609
Как я уже говорил, то, что мы создали, наывается свёрточная нейронная сеть (CNN),

370
00:59:30,069 --> 00:59:34,679
и её ключевой элемент — свёртка.

371
00:59:36,009 --> 00:59:50,459
Вот отличная демонстрация CNN с нашего сайта Explained Visually — ссылка в углу экрана.

372
00:59:50,829 --> 01:00:03,779
Слева — сильно увеличенное изображение лица, справа — результат свёртки. Видно, что

373
01:00:04,620 --> 01:00:16,760
этот алгоритм свёртки находит верхнюю и нижнюю границы предметов на изображении.

374
01:00:17,460 --> 01:00:31,619
Как это работает? Для каждого пиксела модель рассматривает область 3х3 пиксела, умножает значение

375
01:00:32,140 --> 01:00:38,250
каждого пиксела в области по шкале greyscale на соответствующее число в матрице,

376
01:00:38,350 --> 01:00:51,900
складывает результаты и получает новый оттенок серого.

377
01:00:52,000 --> 01:00:58,710
Эту матрицу называют ядром, её размерность может быть какой угодно, но обычно — 3х3.

378
01:00:59,980 --> 01:01:07,319
В данном случае ядро состоит из значений 1, 2, 1, 0, 0, 0, -1, -2, -1.

379
01:01:10,690 --> 01:01:28,889
После выполнения такого алгоритма получается изображение, которое видно справа.

380
01:01:29,950 --> 01:01:43,380
Низкие значения становятся высокими, высокие низкими,

381
01:01:43,990 --> 01:01:51,120
светлые сверху и темные снизу области становятся светлыми и так далее — так работает алгоритм.

382
01:01:51,880 --> 01:01:58,004
Это линейное преобразование, а значит, оно может быть одним из слоёв нейронной сети

383
01:01:58,104 --> 01:02:04,229
в соответствии с данным ранее определением.

384
01:02:04,600 --> 01:02:10,829
Позже мы ещё посмотрим на свёрточные нейронные сети.

385
01:02:12,070 --> 01:02:24,060
После линейного слоя мы добавим нелинейный.

386
01:02:25,450 --> 01:02:33,610
Оранжевая функция в верхнем углу — нелинейная функция, воздействующая на входные данные.

387
01:02:33,610 --> 01:02:46,020
Конкретно эта называется сигмоида, у неё форма буквы S, она часто используется в нейронных сетях.

388
01:02:46,800 --> 01:02:52,060
Вместо сигмоиды мы почти везде используем выпрямитель (ReLU, rectified linear unit).

389
01:02:52,060 --> 01:03:04,020
Выпрямитель зануляет отрицательные значения и не меняет положительные.

390
01:03:05,560 --> 01:03:15,480
Формула выглядит как y = max(x, 0).

391
01:03:19,080 --> 01:03:31,260
Неважно, используете ли вы сигмоиду, выпрямитель или что-то ещё, главное — комбинация линейного и нелинейного слоя,

392
01:03:31,660 --> 01:03:38,430
позволяющая проводить сложные преобразования типа тех, что вы видите на экране.

393
01:03:38,890 --> 01:03:46,799
Демонстрация взята с сайта neuralnetworksanddeeplearning.com, ссылка в углу.

394
01:03:47,079 --> 01:04:02,279
Суть в том, что изменение линейных множителей позволяет менять форму итогового сложного преобразования.

395
01:04:03,040 --> 01:04:10,439
В этом суть универсальной теоремы аппроксимации — нелинейный слой после линейного

396
01:04:10,839 --> 01:04:15,629
позволяет создавать преобразования любой сложности.

397
01:04:16,180 --> 01:04:22,589
Именно поэтому нейронные сети могут решить любую вычислительную задачу.

398
01:04:24,849 --> 01:04:38,980
Итак, мы знаем, что изменение параметров влечёт изменение формы финального преобразования,

399
01:04:38,980 --> 01:04:43,230
и хотим понять, как нужно поменять параметры, чтобы получить нужную нам форму.

400
01:04:43,540 --> 01:04:48,269
Как говорилось раньше, в этом нам поможет градиентный спуск.

401
01:04:48,910 --> 01:05:01,559
Вот так с помощью градиентного спуска можно решить проблему линейной регрессии.

402
01:05:02,980 --> 01:05:15,839
Идею можно продемонстрировать задачей нахождения минимума параболической функции.

403
01:05:15,849 --> 01:05:31,659
Для этого случайным образом выберем точку на оси X и вычислим значение функции в этой точке.

404
01:05:32,330 --> 01:05:42,850
После этого найдём точку, в которой значеие функции чуть меньше — она может быть слева или справа от начальной точки.

405
01:05:43,100 --> 01:05:59,100
Чтобы понять, куда двигаться, вычислим производную, или градиент, функции в этой точке,

406
01:06:02,090 --> 01:06:12,759
он показывает, в каком направлении нужно двигаться — здесь влево. Сдвигаемся влево, получаем новую точку,

407
01:06:13,820 --> 01:06:26,260
повторяем процесс вычисления градиента и движения в обратную от него сторону,

408
01:06:27,080 --> 01:06:29,080
и с каждым шагом приближаемся всё ближе к минимуму.

409
01:06:29,600 --> 01:06:41,080
Алгоритм такой: сначала выбираем начальное приближение x, а все следующие точки вычисляем по формуле

410
01:06:41,660 --> 01:07:02,919
x_n+1 = x_n + dy/dx_n * l, где l - длина шага.

411
01:07:03,830 --> 01:07:27,410
Если l взять слишком большим, алгоритм может разойтись.

412
01:07:27,410 --> 01:07:41,225
Параметр l называется скоростью обучения, мы часто будем его обсуждать.

413
01:07:41,325 --> 01:07:59,960
На этом примере случайно взятая линия методом градиентного спуска подгоняется под точки на графике.

414
01:07:59,960 --> 01:08:12,460
Свёртка, нелинейность и градиентный спуск сами по себе звучат не очень интересно,

415
01:08:12,740 --> 01:08:21,130
но при большом количестве слоёв свертки можно получить интересные результаты.

416
01:08:21,980 --> 01:08:36,279
Можно проиллюстрировать процесс работы CNN — на экране показана статья Мэтта Зайлера и Роба Фергюса,

417
01:08:36,950 --> 01:08:43,990
в которой они смогли визуализировать каждый слой свёрточной нейронной сети.

418
01:08:44,810 --> 01:08:53,979
Слой 1 — девять примеров свёрточных фильтров уже обученной нейронной сети.

419
01:08:54,710 --> 01:09:05,830
Эти фильтры отвечают за распознавание диагональных линий, или сетки, или простых градиентов.

420
01:09:06,320 --> 01:09:16,580
Для каждого из девяти фильтров авторы статьи показали части различных изображений, которые активируют эти фильтры.

421
01:09:17,100 --> 01:09:32,959
Фильтры первого слоя появились в процессе градиентного спуска, то есть для каждого из них была вычислена матрица 3х3.

422
01:09:37,050 --> 01:09:52,700
Второй слой делает несколько попыток скомбинировать фильтры из первого слоя для получения новых фильтров.

423
01:09:52,830 --> 01:09:56,990
Справа аналогично показаны примеры изображений, которые активируют эти фильтры.

424
01:09:57,390 --> 01:10:12,900
Например, один фильтр активируется изображениями заката, другой — круглыми объектами,

425
01:10:12,900 --> 01:10:20,300
что-то активируется повторяющимися горизонтальными линиями, или углами, и так далее.

426
01:10:20,910 --> 01:10:24,649
По сути происходит комбинация свойств фильтров на предыдущем слое.

427
01:10:25,800 --> 01:10:50,450
После следующей итерации, на третьем слое, фильтры уже могут видеть текст, лепестки цветов и человеческие лица.

428
01:10:51,060 --> 01:11:08,120
На пятом слое фильтры могут распознать глаза птиц и насекомых и одноколёсные велосипеды.

429
01:11:09,450 --> 01:11:14,449
Итак, мы начали с простых девяти фильтров, но смогли достичь удивительных результатов

430
01:11:15,030 --> 01:11:27,120
в силу универсальной теоремы аппроксимации и достаточного количества скрытых слоёв.

431
01:11:27,120 --> 01:11:36,409
Именно это и происходило, когда мы обучали нашу модель для разделения кошек и собак.

432
01:11:39,240 --> 01:11:54,950
Ранее мы обсудили, как можно увидеть работу модели — что она различает хорошо, что плохо, в чём не уверена.

433
01:11:56,250 --> 01:12:09,950
Давайте обсудим параметр скорости обучения l, который я упоминал раньше.

434
01:12:10,530 --> 01:12:22,160
В скобках первое число — скорость обучения, то, на что надо умножать градиент при каждом шаге градиентного спуска.

435
01:12:23,400 --> 01:12:33,530
Мы обсудили, почему она не должна быть слишком большой, но не стоит делать с точностью до наоборот —

436
01:12:34,830 --> 01:12:44,839
если скорость будет слишком маленькой, алгоритм будет очень долго сходиться.

437
01:12:45,900 --> 01:13:00,589
Очень важно правильно подобрать это значение, и это долго мучало специалистов глубокого обучения,

438
01:13:01,620 --> 01:13:10,850
пока в прошлом году не появился алгоритм, позволяющий автоматически подобрать хорошую скорость обучения.

439
01:13:12,210 --> 01:13:23,569
К сожалению, алгоритм остался почти незамеченным, хотя он очень простой и полезный.

440
01:13:23,570 --> 01:13:35,359
В нашей библиотеке fast.ai он вызывается методом lr_find() (learning rate finder).

441
01:13:36,150 --> 01:13:44,310
Создатель алгоритма — Лэсли Смит, его статья называется Cyclical Learning Rates for Training Neural Networks, идея заключается в следующем:

442
01:13:48,130 --> 01:13:57,629
Как и в обычном градиентном спуске, сначала выберем случайное начальное приближение.

443
01:13:58,480 --> 01:14:14,429
Затем сделаем очень маленький, порядка 1e-7, шаг в направлении уменьшения градиента.

444
01:14:14,530 --> 01:14:26,609
Каждый следующий шаг увеличим вдвое — 2e-7, 4e-7, 8e-7, 10e-6 и так далее.

445
01:14:27,550 --> 01:14:43,709
Шаги становятся всё больше и больше, и в какой-то момент функция потерь начнёт резко падать,

446
01:14:44,260 --> 01:15:06,040
затем алгоритм разойдётся и функция потерь резко вырастет.

447
01:15:06,040 --> 01:15:31,769
Оптимальная скорость обучения найдётся рядом с областью, где функция потерь падала быстрее всего.

448
01:15:32,500 --> 01:15:47,050
График зависимости скорости обучения от времени/номера итерации будет выглядеть так,

449
01:15:47,050 --> 01:15:54,670
график зависимости функции потерь от скорости обучения — так:

450
01:15:54,670 --> 01:16:08,309
под функцией потерь я подразумеваю различие между предсказанием и истинным значением минимума,

451
01:16:08,309 --> 01:16:22,770
поэтому сначала функция медленно уменьшалась, потом резко скакнула вниз и обратно вверх.

452
01:16:23,739 --> 01:16:42,059
На последнем графике нас интересует не точка минимума, а точка, где стремление к минимуму было максимальным.

453
01:16:44,320 --> 01:17:00,480
Если вы создадите объект learn наподобие того, что мы уже делали, и вызовете метод lr_find(), начнётся обучение модели,

454
01:17:00,880 --> 01:17:15,959
но оно остановится, когда функция потерь станет слишком большой — как видите, здесь она

455
01:17:15,960 --> 01:17:37,484
останавливается на 84 процентах. Метод sched.plot_lr() покажет зависимость скорости обучения от номера итерации.

456
01:17:37,584 --> 01:17:46,409
Здесь используется экспоненциальная зависимость, но Лэсли Смит предлагал ещё и линейную,

457
01:17:47,560 --> 01:17:57,239
я последнее время использую экспоненциальную, но склоняюсь к тому, чтобы перейти на линейную.

458
01:17:58,210 --> 01:18:12,479
Метод sched.plot() покажет последний график из тех, что я рисовал — зависимость функции потерь от скорости обучения.

459
01:18:13,119 --> 01:18:20,429
Нас интересует точка, в которой функция потерь низкая, но ещё продолжает падать с хорошей точностью —

460
01:18:21,309 --> 01:18:34,589
значение 1e-2 подойдёт, а 1е-1 и 1е-3 — нет.

461
01:18:34,989 --> 01:18:46,620
В примере раньше скорость обучения 0.01 была выбрана именно таким образом.

462
01:18:49,560 --> 01:18:55,040
Осталось выбрать ещё одно число — количество эпох.

463
01:18:56,320 --> 01:19:27,478
В данном примере их три, в процессе обучения модель трижды просмотрела весь датасет небольшими порциями по 64 картинки.

464
01:19:28,360 --> 01:19:36,509
В конце каждой эпохи мы выводили долю правильных ответов модели и значения функции потерь на обучающей и валидационной выборках.

465
01:19:37,989 --> 01:19:55,329
Перед обучением модели нужно выбрать количество эпох, и тут всё довольно просто — их может быть сколько угодно.

466
01:19:55,329 --> 01:20:12,380
Если их будет слишком много, доля правильных ответов начнёт уменьшаться — это переобучение, мы обсудим его позже.

467
01:20:12,380 --> 01:20:23,540
Если у вас сложная модель или много данных, обучение может занимать много времени, поэтому можно уменьшить количество эпох.

468
01:20:24,219 --> 01:20:29,609
В общем, количество эпох определяется довольно просто.

469
01:20:30,639 --> 01:20:43,679
Ваша цель на этой неделе — запустить эти три строки кода и посмотреть, как они работают на различных наборах изображений,

470
01:20:44,619 --> 01:20:53,690
фотографиях с вашего компьютера, картинок из Google,

471
01:20:53,920 --> 01:21:02,819
на каких датасетах модель работает хорошо или плохо, какая нужна скорость обучения для различных изображений,

472
01:21:04,480 --> 01:21:16,440
сколько нужно эпох, как скорость обучения влияет на долю правильных ответов и тому подобное.

473
01:21:17,020 --> 01:21:21,810
Экспериментируйте и лучше поймёте, как всё устроено —

474
01:21:21,810 --> 01:21:27,359
как выглядит целевая переменная, что значит принадлежность к классу,

475
01:21:27,360 --> 01:21:38,969
если вы раньше не работали с numpy — потренируйтесь, уже на следующей лекции будет гораздо больше технических деталей.

476
01:21:39,940 --> 01:21:47,790
Очень важно научиться работать с numpy, fast.ai и другими библиотеками.

477
01:21:48,730 --> 01:21:55,589
Вот некоторые возможности Jupyter ноутбуков, которые вам в этом помогут.

478
01:21:56,710 --> 01:22:14,849
Если вы забыли название метода, нажмите Tab и увидите список возможных методов.

479
01:22:15,119 --> 01:22:29,720
Если вы забыли аргументы метода, нажмите Shift+Tab для вывода его сигнатуры.

480
01:22:31,740 --> 01:22:54,990
Вот сигнатура функции np.exp(). Если нажать Shift+Tab+Tab, показывается полная документация метода.

481
01:22:55,420 --> 01:23:05,699
Если нажать Shift+Tab+Tab+Tab, документация выведется в новом окне.

482
01:23:07,390 --> 01:23:16,589
Этого также можно достичь, поставив вопросительный знак перед названием метода.

483
01:23:18,880 --> 01:23:29,189
На протяжении курса мы часто будем смотреть на исходный код некоторых методов, чтобы лучше понять, как они работают.

484
01:23:29,740 --> 01:23:50,190
Это достигается двумя вопросительными знаками перед названием метода.

485
01:23:50,490 --> 01:24:04,170
Вы обнаружите, что все методы в библиотеке fast.ai занимают меньше половины экрана, большинство из них короче шести строк.

486
01:24:04,420 --> 01:24:17,850
Метод learn.predict вызывает метод learn.predict_with_targs, который вызывает функцию predict_with_tags(),

487
01:24:17,850 --> 01:24:23,489
которая проходит по данным и возвращает предсказания.

488
01:24:24,070 --> 01:24:41,010
Итак, «??» — получить исходный код, «?» — посмотреть документацию, Shift+Tab — показать параметры, +Tab несколько раз — показать документацию.

489
01:24:41,680 --> 01:25:00,450
Клавиша H вызывает табличку с горячими клавишами Jupyter ноутбука, можно посмотреть, что он умеет.

490
01:25:00,580 --> 01:25:14,760
Я считаю, что тут всё полезно, поэтому советую студентам изучать 4-5 новых комбинаций в день.

491
01:25:15,700 --> 01:25:34,140
Важно — когда закончите работать, не забудьте остановить машины Paperspace и Crestle, чтобы не переплачивать за простой.

492
01:25:34,240 --> 01:25:52,680
Просто закрыть браузер недостаточно, убедитесь, что машины действительно выключены.

493
01:25:53,230 --> 01:25:57,930
Я думаю, для начала хватит.

494
01:25:58,390 --> 01:26:28,770
Не забывайте про форумы, читайте информацию на course.fast.ai, чтобы быть в курсе происходящего.

495
01:26:29,470 --> 01:26:33,899
Спасибо за просмотр, встретимся с вами на следующей лекции.

