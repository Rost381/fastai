1
00:00:00,250 --> 00:00:04,350
Добро пожаловать на вторую лекцию курса Глубокое обучение.

2
00:00:06,940 --> 00:00:18,719
На прошлой неделе мы успешно обучили неплохой классификатор изображений, давайте кратко пройдёмся по основным понятиям.

3
00:00:21,580 --> 00:00:57,389
Видно экран? Приглушим свет? Да, так нормально.

4
00:01:02,440 --> 00:01:22,259
Напоминаю, что мы использовали три строки кода, работающие с датасетом в указанной директории,

5
00:01:23,049 --> 00:01:41,710
изображения были разделены на обучающую и валидационную выборки и разделены на кошек и собак внутри каждой выборки.

6
00:01:41,810 --> 00:01:55,470
Это один из двух способов организации данных для обучения модели.

7
00:01:55,780 --> 00:02:09,148
По сообщениям на форуме я вижу, что на протяжении недели вы пробовали создавать новые классификаторы со своими датасетами.

8
00:02:10,090 --> 00:02:24,959
Для начала этого кода достаточно — если вы создадите свой датасет из нескольких сотен или тысяч изображений

9
00:02:25,569 --> 00:02:31,679
и запустите эти три строки кода, вы получите классификатор изображений.

10
00:02:31,680 --> 00:02:36,460
В третьей колонке вывода вы увидите долю правильных ответов вашего классификатора.

11
00:02:37,420 --> 00:02:51,660
Мы смотрели, как работает модель — в чём она не уверена, в чём ошибается, поняли, что это полезная информация.

12
00:02:52,810 --> 00:03:05,970
Потом мы узнали про необходимость фиксировать скорость обучения, здесь она равна 0.01,

13
00:03:07,120 --> 00:03:15,509
позже мы изучим обосновывающую этот параметр теорию, а пока сконцентрируемся на практике.

14
00:03:18,790 --> 00:03:20,790
Да, Янет?

15
00:03:23,680 --> 00:03:27,540
Янет: Вас не видно на видео.
Да, теперь видно, я повернул камеру.

16
00:03:30,760 --> 00:03:35,910
Янет: Расскажите про значение чисел в колонках на экране.

17
00:03:36,640 --> 00:03:45,959
Эти три? Мы ещё обсудим первую и вторую колонки, третья — доля правильных ответов.

18
00:03:47,110 --> 00:03:53,429
Нулевая колонка — количество эпох, то есть сколько раз модель просмотрела весь датасет.

19
00:03:54,610 --> 00:04:09,944
Первая колонка — значение функции потерь на обучающей выборке, на которой обучается модель,

20
00:04:10,044 --> 00:04:22,739
вторая — значение функции потерь на валидационной выборке, которую мы используем, чтобы оценить качество модели.

21
00:04:25,400 --> 00:04:39,430
Ещё раз: номер эпохи, потери на обучающей выборке, потери на валидационнной выборке, доля правильных ответов.

22
00:04:45,399 --> 00:04:48,599
Так, теперь к скорости обучения.

23
00:04:54,520 --> 00:05:08,218
Скорость обучения показывает, как быстро мы стремимся к решению.

24
00:05:08,219 --> 00:05:18,449
Хорошая аналогия — поиск минимума выпуклой функции.

25
00:05:19,029 --> 00:05:24,509
В процессе глубокого обучения решается похожая задача.

26
00:05:26,349 --> 00:05:33,329
У функции могут быть сотни миллионов параметров, но они все устроены одинаково.

27
00:05:33,330 --> 00:05:44,459
По этой функции сразу видно, что её минимум находится здесь, давайте посмотрим, какой алгоритм может это вычислить.

28
00:05:44,619 --> 00:05:51,569
Давайте выберем случайную точку на оси и найдём соответствующее ей значение функции потерь.

29
00:05:51,999 --> 00:06:05,759
Вычислим градиент, это ответ на вопрос «В какую сторону надо идти, чтобы идти вниз, и с какой скоростью?».

30
00:06:06,519 --> 00:06:20,909
Сделаем шаг в направлении от градиента, пропорциональный его величине.

31
00:06:21,219 --> 00:06:30,718
Коэффициент пропорциональности, на который мы домножаем градиент для получения длины шага, и есть скорость обучения.

32
00:06:31,209 --> 00:06:48,419
Если скорость обучения мала, алгоритм будет сходиться, но очень медленно.

33
00:06:48,459 --> 00:07:00,929
Если скорость обучения слишком велика, алгоритм разойдётся.

34
00:07:01,300 --> 00:07:12,930
Если вы обучаете нейронную сеть и функция потерь начинает резко увеличиваться, значит, скорость обучения слишком велика.

35
00:07:14,050 --> 00:07:20,520
Если она слишком низкая, это не так страшно — просто придётся долго ждать.

36
00:07:21,120 --> 00:07:36,089
Для нахождения оптимальной скорости обучения мы используем алгоритм поиска скорости обучения.

37
00:07:36,590 --> 00:07:52,350
Напомню, что изображения просматриваются минибатчами по 64 или 128 штуки за раз.

38
00:07:52,920 --> 00:08:02,850
После каждого минибатча алгоритм поиска скорости обучения увеличивает скорость обучения вдвое.

39
00:08:02,850 --> 00:08:12,180
Мы начинаем с очень маленькой скорости обучения и постепеннно увеличиваем её,

40
00:08:12,670 --> 00:08:19,070
пока она не станет слишком большой, на этом моменте функция потерь резко вырастет.

41
00:08:19,370 --> 00:08:26,249
Вот график зависимости функции потерь от скорости обучения.

42
00:08:27,250 --> 00:08:35,100
При маленьких скоростях обучения функция потерь высокая, при увеличении скорости потерь она уменьшается, а потом опять растёт.

43
00:08:35,380 --> 00:09:12,299
Числа на горизонтальной оси записаны в экспоненциальном виде: 10^-1 = 0.1 = 1e-1, 10^-2 = 0.01 = 1e-2 .

44
00:09:15,100 --> 00:09:32,160
Игнорируйте значение функции потерь при поиске скорости обучения, это самая высокая точка на графике.

45
00:09:32,160 --> 00:09:38,999
Значение имеет только график зависимости функции потерь от скорости обучения.

46
00:09:39,670 --> 00:09:47,380
Точка минимума на графике — слишком высокая скорость обучения, в этой точке она уже не улучшается.

47
00:09:47,380 --> 00:09:58,110
Я обычно использую скорость обучения на порядок меньше этой точки, в данном случае 1е-2.

48
00:09:58,150 --> 00:10:08,460
Поэтому здесь стоит 1е-2.

49
00:10:10,180 --> 00:10:24,660
Важно понять, что правильный подбор одной только скорости обучения уже даст хорошие результаты.

50
00:10:24,820 --> 00:10:41,790
И это очень важная мысль — в других учебниках или курсах вы можете узнать про десятки гиперпараметров,

51
00:10:41,950 --> 00:10:52,150
и их довольно сложно подбирать, а библиотека fast.ai делает всё возможное автоматически.

52
00:10:52,150 --> 00:10:56,400
Потом мы узнаем о других параметрах, которые помогут немного улучшить результаты,

53
00:10:57,760 --> 00:11:22,229
но на самом деле скорость обучения — ключевой параметр, хоть люди и считают, что глубокое обучение гораздо сложнее.

54
00:11:22,300 --> 00:11:41,990
Алгоритму около полутора лет, его автор не очень популярен, поэтому его статья почти никому не известна.

55
00:11:42,829 --> 00:12:00,589
Автор алгоритма — Лэсли Смит, расскажите о его изобретении своим коллегам.

56
00:12:01,709 --> 00:12:10,008
Я видел статью No More Pesky Learning Rates, в которой описан менее продуктивный метод.

57
00:12:10,009 --> 00:12:17,899
Большую часть истории глубокого обучения подбирать скорость обучения было действительно сложно.

58
00:12:19,019 --> 00:12:27,079
Метод простой — найдите самую низкую точку, поделите соответствующее значение на десять и используйте его,

59
00:12:27,079 --> 00:12:34,300
если не сработает, поделите ещё на десять, но мне обычно хватает.

60
00:12:40,160 --> 00:12:52,428
Вопрос из зала: Чем этот подход лучше градиентного спуска с инерцией?

61
00:12:58,559 --> 00:13:03,498
Отличный вопрос. На протяжении курса мы узнаем о различных способах улучшить градиентный спуск,

62
00:13:03,929 --> 00:13:09,129
таких, как градиентный спуск с инерцией, Adam (Adaptive Moment Estimation) и других,

63
00:13:09,129 --> 00:13:17,149
но это не повлияет на практику — библиотека fast.ai сама подбирает необходимые оптимизации градиентного спуска.

64
00:13:17,149 --> 00:13:34,489
Метод нахождения скорости обучения использует Adam, но это другое — сначала подбирается скорость обучения,

65
00:13:34,490 --> 00:13:43,129
и только потом оптимизируется градиентный спуск, эти две вещи не связаны.

66
00:13:43,129 --> 00:14:00,589
Идея сначала выбирать скорость обучения, а потом оптимизировать градиентный спуск не нова, но почему-то её никто не использует.

67
00:14:05,800 --> 00:14:16,420
Вопрос из зала: Алгоритм Adam меняет скорость обучения на каждой итерации, зачем её тогда подбирать?

68
00:14:19,040 --> 00:14:29,649
Мы рассмотрим Adam позже, если вкратце — да, в Adam скорость обучения зависит от предыдущих значений градиента,

69
00:14:30,410 --> 00:14:53,080
но она всё ещё имеет смысл как отдельная величина, как и в других методах с динамической скоростью обучения.

70
00:14:55,640 --> 00:15:08,649
Самое важное для улучшения качества модели — давать ей достаточно данных для обучения.

71
00:15:09,290 --> 00:15:18,640
Есть проблема переобучения — у модели могут быть сотни миллионов параметров, и, если она обучается слишком долго,

72
00:15:19,070 --> 00:15:26,679
она начинает придавать большое значение особенностям датасета, а не общим закономерностям,

73
00:15:26,750 --> 00:15:32,829
которые применимы и к обучающей, и к валидационной выборке.

74
00:15:33,529 --> 00:15:38,199
Чтобы избежать переобучения, нужно предоставить модели больше данных для обучения.

75
00:15:38,329 --> 00:15:49,119
Очевидный способ — собрать больше данных, но проще применить дополнение данных (data augmentation), чтобы создать новые данные из существующих.

76
00:15:50,540 --> 00:15:57,530
Дополнение данных во многих курсах опускают или оставляют на конец как дополнительный материал,

77
00:15:57,630 --> 00:16:02,260
хотя это ключевая техника для улучшения качества модели.

78
00:16:04,779 --> 00:16:09,849
Дополнение данных встроено в библиотеку fast.ai и его просто применять.

79
00:16:09,850 --> 00:16:14,050
Мы ещё обсудим код, но общая идея такова —

80
00:16:14,740 --> 00:16:22,630
в наших трёх строках кода в первой строке в метод ImageClassifierData.from_paths() передавалась рабочая директория PATH,

81
00:16:22,630 --> 00:16:31,838
а также архитектура нейронной сети arch и размер sz, до которого обрезаются изображения перед обработкой.

82
00:16:32,180 --> 00:16:37,839
К этим параметрам мы добавим ещё один, указывающий алгоритм дополнения данных.

83
00:16:38,600 --> 00:16:51,819
Я продемонстрирую, как это работает. Мы разберём код позже.

84
00:16:53,180 --> 00:17:02,169
Здесь алгоритм дополнения данных шесть раз проходит через весь датасет и выводит результат для одного изображения.

85
00:17:02,779 --> 00:17:14,828
Видно, что эта кошка находится левее, эта — правее, эта отражена по горизонтали и так далее.

86
00:17:16,520 --> 00:17:24,309
Для различных типов изображений нужны различные алгоритмы дополнения данных — в задаче распознавания букв и цифр

87
00:17:25,520 --> 00:17:30,400
отражение по горизонтали не сработало бы, потому что изображение меняет свой смысл,

88
00:17:31,040 --> 00:17:40,329
а в задаче распознавания кошек и собак неразумно включать вертикальное отражение, потому что обычно кошки не вверх ногами.

89
00:17:40,550 --> 00:17:50,859
В соревновании Kaggle по распознаванию айсбергов на спутниковых снимках, наоборот, разумно отражать вертикально,

90
00:17:51,110 --> 00:17:56,500
потому что не имеет значения, с какой стороны спутника находится асйберг.

91
00:17:58,250 --> 00:18:05,069
Один из алгоритмов дополнения данных — transform_on_side, который предполагает, что снимок был сделан сбоку,

92
00:18:05,590 --> 00:18:09,939
поэтому его можно отражать горизонтально, но не вертикально.

93
00:18:10,010 --> 00:18:13,749
Такой алгоритм отражает изображения горизонтально, поворачивает их на маленький угол,

94
00:18:14,390 --> 00:18:28,190
слегка меняет яркость и контрастность изображения, немного приближает, отдаляет и сдвигает центр изображения.

95
00:18:30,210 --> 00:18:39,910
Вопрос из зала: Расскажите ещё раз, почему минимум кривой потерь не подходит при выборе скорости обучения.

96
00:18:39,910 --> 00:18:54,590
Вопрос из зала: И ещё — работает ли алгоритм поиска скорости обучения для каждой свёрточной нейронной сети.

97
00:18:58,050 --> 00:19:03,919
Люди, рядом с которыми есть свободное место, поднимите руку, пожалуйста.

98
00:19:10,650 --> 00:19:21,709
К вопросу о том, почему при выборе скорости обучения мы берём не минимум на графике, а точку перед минимумом.

99
00:19:24,660 --> 00:19:56,700
Вспомним алгоритм: мы начинаем с маленького шага и каждый раз удваиваем его, двигаясь вдоль градиента.

100
00:19:56,700 --> 00:20:06,949
Цель не в том, чтобы найти минимум, а в том, чтобы понять, какая скорость обучения позволяет нам быстрее всего спускаться.

101
00:20:07,530 --> 00:20:20,300
В точке минимума функция потерь минимальна, но скорость обучения уже слишком большая, алгоритм начинает расходиться.

102
00:20:20,460 --> 00:20:30,410
Поэтому мы отходим чуть назад к моменту, где функция потерь выше.

103
00:20:30,720 --> 00:20:40,699
Это график зависимости скорости обучения от номера итерации, каждая итерация — новый минибатч, скорость обучения всегда растёт.

104
00:20:41,249 --> 00:20:47,029
Это график зависимости функции потерь от скорости обучения, в точке минимума скорость обучения уже слишком высокая,

105
00:20:47,789 --> 00:20:52,309
поэтому мы немного её уменьшаем, чтобы попасть в оптимальную область.

106
00:20:54,389 --> 00:20:58,968
Позже мы узнаем про стохастический градиентный спуск с перезапуском,

107
00:20:59,159 --> 00:21:13,189
который покажет, что здесь можно взять скорость обучения 1е-3 и модель будет обучаться быстрее, но,

108
00:21:13,190 --> 00:21:20,389
как мы увидим дальше, это может ухудшить способность модели обобщать.

109
00:21:20,399 --> 00:21:26,209
Вопрос из зала: Скорость обучения должна быть высокой?

110
00:21:27,059 --> 00:21:29,059


111
00:21:29,849 --> 00:21:43,639
Ну, вот график, при увеличении номера итерации скорость обучения всегда увеличивается,

112
00:21:44,039 --> 00:21:51,199
а на этом графике в минимальной точке она уже слишком большая.

113
00:21:51,450 --> 00:21:57,289
Вопрос из зала: Я спросил, потому что вы сначала сказали, что 1е-1 это слишком много

114
00:21:58,019 --> 00:22:05,529
и надо выбрать 1е-2, а потом сказали, что надо увеличить это число на порядок.

115
00:22:05,549 --> 00:22:21,228
Я не собирался это сказать, извините, если оговорился. Я имел в виду уменьшение скорости обучения, возможно, сказал не то.

116
00:22:23,159 --> 00:22:35,720
Вопрос из зала: Раньше вы говорили, что все локальные минимумы одинаковые, и на этом графике это тоже видно, за этим стоит какая-то теория?

117
00:22:37,020 --> 00:22:48,500
Нет, этот график не демонстрирует этот факт. Этот график просто показывает, что существует оптимальная скорость обучения.

118
00:22:49,500 --> 00:23:00,110
Тот факт, что все локальные минимумы одинаковы — совсем про другое, мы к этому ещё вернёмся.

119
00:23:02,909 --> 00:23:20,720
Янет: Сколько раз нужно подбирать скорость обучения? Каждую эпоху?

120
00:23:24,030 --> 00:23:37,470
Хороший вопрос, Янет. Я выбираю скорость обучения в самом начале, и иногда после размораживания слоёв, мы это ещё обсудим.

121
00:23:37,470 --> 00:23:58,160
Идея в том, чтобы выбирать скорость обучения, если вы поменяли что-то значительное в модели и она стала хуже обучаться.

122
00:23:58,920 --> 00:24:06,950
Хуже вы точно не сделаете, алгоритм поиска довольно быстрый.

123
00:24:08,160 --> 00:24:09,085
Отличный вопрос.

124
00:24:09,185 --> 00:24:23,119
Возвращаемся к дополнению данных. В этот метод можно передавать различные алгоритмы дополнения данных,

125
00:24:23,820 --> 00:24:36,920
позже мы создадим свои алгоритмы , но пока остановимся на этом.

126
00:24:37,290 --> 00:24:53,780
Изображение при преобразовании может быть приближено, отдалено, повёрнуто, сдвинуто, или отражено —

127
00:24:54,420 --> 00:25:04,460
технически мы не создаём новые данные, но это помогает свёрточной нейронной сети лучше обучаться.

128
00:25:05,130 --> 00:25:24,260
Мы говорим модели — если редактировать изображение таким способом, оно не изменится.

129
00:25:25,830 --> 00:25:39,950
Итак, в метод ImageClassifierData.from_paths() передаётся алгоритм дополнения данных, мы ещё это обсудим.

130
00:25:41,410 --> 00:25:49,850
Теперь обучим модель, вызвав метод .fit().

131
00:25:49,850 --> 00:26:00,639
Сейчас дополнение данных никак не влияет, потому что мы указали параметр precompute=True, мы это ещё обсудим.

132
00:26:03,170 --> 00:26:16,819
Вспомните демонстрацию, где показывались различные уровни нейронной сети. Каждому результату классификации —

133
00:26:17,820 --> 00:26:48,610
середине цветка, или глазу птицы — соответствует активация, которая говорит, с какой вероятностью на изображении есть этот объект.

134
00:26:49,520 --> 00:27:04,630
Параметр precompute=True значит, что наша модель заранее была обучена на полутора миллионах изображений базы ImageNet

135
00:27:04,630 --> 00:27:20,770
Это значит, что модель сохранила все активации с предпоследнего уровня, то есть информацию типа

136
00:27:20,770 --> 00:27:31,479
«это — на столько-то процентов глаз, это — на столько-то процентов собака, это — мохнатое ухо».

137
00:27:32,270 --> 00:27:45,489
Мы называем это предвычисленные активации,

138
00:27:46,040 --> 00:27:57,199
на их основе можно быстро обучать простые линейные модели.

139
00:27:57,200 --> 00:28:07,008
Экспериментируя, вы могли заметить, что первый запуск кода занимает пару минут,

140
00:28:07,590 --> 00:28:13,849
а у меня уходит 5-10 секунд — это из-за того, что модель использует предвычисленные активации.

141
00:28:13,949 --> 00:28:22,249
Если вы используете свой компьютер или сервер Amazon, скачать предвычисленные активации надо будет один раз,

142
00:28:22,470 --> 00:28:39,739
если вы используете Crestle — каждый раз при перезапуске машины.

143
00:28:40,200 --> 00:28:47,449
Во всех случаях, кроме Crestle, это нужно делать всего один раз для каждого датасета.

144
00:28:49,110 --> 00:29:05,089
Проблема в том, что с предвычисленными активациями не работает дополнение данных —

145
00:29:05,090 --> 00:29:11,809
для каждого изображения кошки уже вычислены активации, и наши преобразования ничего не меняют.

146
00:29:12,749 --> 00:29:20,929
Поэтому мы ставим precompute=False и запускаем ещё несколько эпох.

147
00:29:21,720 --> 00:29:33,799
Видно, что доля правильных ответов от эпохи к эпохе не увеличивается — и это плохо, зато

148
00:29:34,679 --> 00:29:46,249
уменьшаются потери на обучающей выборке и почти не меняются потери на валидацонной, то есть не происходит переобучения.

149
00:29:46,649 --> 00:29:58,039
Когда потери на обучающей выборке сильно меньше потерь на валидационной, происходит переобучение, мы это ещё обсудим.

150
00:29:58,039 --> 00:30:07,069
Если модель гораздо лучше предсказывает обучающую выборку, чем валидационную, она плохо обобщает.

151
00:30:07,780 --> 00:30:16,289
Мы избежали переобучения, но и доля правильных ответов не стала сильно выше — надо ещё что-нибудь придумать.

152
00:30:16,870 --> 00:30:24,240
Перед этим я хочу ещё кое-что показать. Я добавил параметр длины цикла cycle_len=1.

153
00:30:24,400 --> 00:30:40,800
Параметр длины цикла указывает на то, что здесь используется стохастический градиентный спуск с перезапуском (SGDR).

154
00:30:41,440 --> 00:31:05,129
Идея SGDR в том, что при приближении к оптимальной точке можно уменьшить скорость обучения, чтобы точнее в неё попасть.

155
00:31:05,470 --> 00:31:23,050
На этом  участке зависимость скорости обучения от номера итерации может выглядеть так.

156
00:31:24,260 --> 00:31:39,160
Этот алгоритм называется алгоритм имитации отжига, он очень популярен.

157
00:31:39,920 --> 00:31:58,809
Обычно его применяют так: просто понижают выбранную скорость обучения на порядок каждый раз, когда она перестаёт работать.

158
00:31:59,210 --> 00:32:09,010
Это стандартный подход, всё приходится делать руками, это неудобно.

159
00:32:09,530 --> 00:32:15,280
Гораздо проще выбрать функцию, по которой будет меняться скорость обучения.

160
00:32:16,010 --> 00:32:30,650
Хорошая функция — половина периода косинуса. Когда оптимальная точка ещё далеко, скорость обучения велика,

161
00:32:30,650 --> 00:32:37,999
при приближении к оптимальной точке она сначала резко падает, а потом начинает падать сильно медленнее.

162
00:32:38,910 --> 00:32:48,680
Это называется имитация отжига по косинусу, если кто-то забыл — вот так выглядит косинус и мы берём его часть.

163
00:32:49,440 --> 00:32:53,270
Мы будем использовать имитацию отжига по косинусу.

164
00:32:54,570 --> 00:33:06,949
Проблема в том, что мы работаем в многомерном пространстве — у нас сотни миллионов измерений. На примере трёхмерного пространства:

165
00:33:08,010 --> 00:33:23,509
есть много плоских участков, не обязательно являющихся локальными минимумами.

166
00:33:24,690 --> 00:33:26,690
Сейчас покажу.

167
00:33:32,870 --> 00:33:51,370
Допустим, что кривая потерь выглядит как-то так, и из случайного начального приближения нашёлся минимум здесь.

168
00:33:52,279 --> 00:34:05,836
В этой точке низкие потери, но она плохая — если модели дать немного другой набор данных, она выдаст плохие результаты.

169
00:34:06,936 --> 00:34:31,119
Наоборот, эта точка хорошая — потери в ней такие же, но она лучше обощает.

170
00:34:31,399 --> 00:34:53,649
Чтобы избежать застревания в плохой точке, мы будем циклически менять скорость обучения таким образом —

171
00:34:53,690 --> 00:34:59,200
сначала спускаемся по косинусоиде, потом резко поднимаемся, и так несколько раз.

172
00:34:59,530 --> 00:35:12,459
Это поможет выпрыгивать из плохих точек, а не застревать в них.

173
00:35:12,460 --> 00:35:33,580
Если мы попадём в хорошую область, то в ней и останемся.

174
00:35:40,570 --> 00:35:49,409
Вопрос из зала: Можно ли достичь такого эффекта, просто несколько раз выбрав случайные начальные приближения?

175
00:35:50,620 --> 00:36:05,069
Отличный вопрос. Именно это люди и делали до изобретения SGDR —

176
00:36:05,740 --> 00:36:18,630
десять раз обучали модель с нуля в надежде, что один из вариантов будет хорош.

177
00:36:19,450 --> 00:36:37,110
Преимущество SGDR в том, что модель обучается только один раз, находя лучшие решения в процессе обучения.

178
00:36:37,420 --> 00:36:51,780
Циклическое изменение скорости обучения даёт результаты лучше, чем просто случайные начальные приближения.

179
00:36:52,360 --> 00:37:02,099
Его изобрели недавно, он очень удобный, но про него мало кто знает.

180
00:37:02,800 --> 00:37:16,739
Мне кажется, что SGDR и алгоритм поиска скорости обучения — мои суперсилы, позволяющие обходить почти всех на соревнованиях Kaggle.

181
00:37:16,740 --> 00:37:26,789
Я включаюсь в соревнование в первые недели и сразу получаю прекрасные результаты.

182
00:37:27,460 --> 00:37:37,679
Именно поэтому на этом графике я выбрал область резкого спуска —

183
00:37:37,960 --> 00:37:54,299
значение 1е-2 при применении SGDR будет верхней точкой этой функции.

184
00:37:54,580 --> 00:38:03,509
Если вместо 1е-2 взять значение меньше, SGDR не сможет выбраться из ненужных локальных  минимумов.

185
00:38:05,950 --> 00:38:11,819
Вопрос из зала: Сколько раз меняется скорость обучения внутри эпохи?

186
00:38:12,610 --> 00:38:23,539
Скорость обучения меняется после каждого минибатча,

187
00:38:24,190 --> 00:38:31,559
а параметр длины цикла показывает, сколько эпох проходит от скачка до скачка — у нас одна.

188
00:38:32,110 --> 00:38:36,450
При длине цикла 2 скачок происходил бы каждые две эпохи.

189
00:38:36,520 --> 00:38:51,599
Главное в алгоритме — менять скорость обучения каждый минибатч, повторюсь, обычно так никто не делает.

190
00:38:53,470 --> 00:38:59,760
Вопрос из зала: Объясните ещё раз значение параметра precompute.

191
00:39:00,820 --> 00:39:13,259
Да, мы к этому вернёмся. Мы будем поверхностно узнавать вещи, а потом возвращаться к ним,

192
00:39:13,260 --> 00:39:18,239
каждый раз читая новый код и узнавая новую теорию.

193
00:39:18,240 --> 00:39:24,630
На протяжении недели вы можете задавать ваши вопросы на форуме.

194
00:39:27,040 --> 00:39:40,290
Вопрос из зала: Мы хотим уловить общие закономерности, не сваливаясь в частности. Для этого берётся среднее от всех минимумов?

195
00:39:41,260 --> 00:39:50,850
Как видите, здесь написано ансамбль снимков — пока мы не прописываем это в коде, но да,

196
00:39:51,730 --> 00:40:04,489
для улучшения обобщения берётся среднее значение в минимумах. Пока мы просто выбираем последний минимум.

197
00:40:09,420 --> 00:40:27,889
Если хотите поэкспериментировать, есть параметр cycle_save_name, который сохраняет значения минимумов для ручного усреднения.

198
00:40:31,830 --> 00:40:33,830
Хорошо.

199
00:40:34,200 --> 00:40:45,229
Итак, у нас есть модель с долей правильных ответов 99.3% и мы потратили несколько минут на её обучение.

200
00:40:45,780 --> 00:41:01,670
Периодически я сохраняю веса модели в файл методом .save(), их можно загрузить обратно методом .load().

201
00:41:02,670 --> 00:41:19,310
Когда вы обучаете модель, все промежуточные файлы —  предвычисленные активации, обрезанные изображения —

202
00:41:20,090 --> 00:41:48,020
хранятся в директории /data/dogscats/tmp.

203
00:41:48,540 --> 00:42:03,679
Если модель ведёт себя странно, причиной могут быть испорченные промежуточные файлы.

204
00:42:04,109 --> 00:42:08,659
Если удалить папку tmp, некоторые ошибки могут исчезнуть.

205
00:42:09,540 --> 00:42:13,749
В библиотеке fast.ai это аналог метода решения ошибок «выключить-включить».

206
00:42:14,200 --> 00:42:21,160
Веса модели сохраняются в папку /data/dogscats/models.

207
00:42:22,020 --> 00:42:26,089
Помню, когда только вышла статья про SGDR, кто-то написал в Twitter —

208
00:42:26,090 --> 00:42:30,650
«Чтобы ваша нейронная сеть работала, выключите и включите её».

209
00:42:33,180 --> 00:42:35,180
Вопрос?

210
00:42:36,360 --> 00:42:43,640
Вопрос из зала: Если я хочу заново обучить модель, мне нужно удалить все промежуточные файлы?

211
00:42:49,020 --> 00:43:07,730
Нет смысла удалять предвычисленные активации, это просто веса, скачанные из Интернета.

212
00:43:09,180 --> 00:43:21,049
Их стоит удалять, если файлы скачались неправильно или были повреждены.

213
00:43:21,360 --> 00:43:31,309
Для разных датасетов и архитектур автоматически создаются промежуточные файлы с разными названиями, об этом думать не нужно.

214
00:43:31,770 --> 00:43:46,669
Если вы начинаете всё с нуля, просто создайте новый объект learn вызовом ConvLearner.pretrained().

215
00:43:49,140 --> 00:43:58,220
До перерыва хочется успеть обсудить тонкую настройку и дифференциальные скорости обучения.

216
00:43:59,040 --> 00:44:12,750
До сих пор мы никак не меняли предвычисленные активации, то есть использовали модели,

217
00:44:13,750 --> 00:44:30,829
которые уже знали, как находить края, градиенты, углы, кривые, повторяющиеся узоры, куски текста и глаза.

218
00:44:33,059 --> 00:44:51,319
Мы не меняли эти фильтры, не меняли веса в матрицах свёртки, просто добавляли сверху новые слои.

219
00:44:52,559 --> 00:45:10,309
Может оказаться, что ваша модель должна различать различные виды глаз или лиц, или вы ищете айсберги на спутниковых снимках,

220
00:45:10,920 --> 00:45:19,579
и для этого нужны совершенно другие активации — поэтому придётся отбросить верхние слои и создавать их заново.

221
00:45:21,029 --> 00:45:32,190
Мы строим классификатор изображений кошек и собак, и сильные изменения не понадобятся, но кое-что поправим.

222
00:45:32,190 --> 00:45:47,539
Для изменения фильтров свёртки нужно вызвать метод разморозки .unfreeze(). Замороженный слой — это неизмененный слой.

223
00:45:47,539 --> 00:45:49,999
Метод .unfreeze() размораживает все слои.

224
00:45:50,880 --> 00:46:07,549
Очевидно, что первый слой сильно менять не нужно — за полтора миллиона изображений модель научилась видеть края и градиенты,

225
00:46:07,549 --> 00:46:17,629
это полезное умение. Углы и закругления тоже можно оставить.

226
00:46:17,690 --> 00:46:37,159
В целом, первые слои не нужно обновлять, в отличие от последних, которые стоит подстраивать под свою задачу.

227
00:46:38,909 --> 00:46:59,239
Поэтому мы создаём массив с различными скоростями обучения для различных слоёв — от внешних до внутренних.

228
00:46:59,339 --> 00:47:03,078
Эти скорости обучения соответствуют базовым геометрическим признакам,

229
00:47:03,779 --> 00:47:08,718
эти — более сложным свёрточным признакам,

230
00:47:09,179 --> 00:47:16,249
а эти — признакам, которые мы добавили в процессе обучения.

231
00:47:16,380 --> 00:47:29,390
Эти значения записаны в массив и передаются в метод .fit() для обучения модели.

232
00:47:29,640 --> 00:47:45,529
Мы назвали это дифференциальные скорости обучения, это не наше изобретение, но оно не очень известное.

233
00:47:46,019 --> 00:47:52,158
Я не знаю, описан ли этот метод в какой-нибудь статье.

234
00:47:52,859 --> 00:48:01,079
У Джейсона Йосински была статья, в которой он предлагал идею использовать разные скорости обучения,

235
00:48:01,079 --> 00:48:07,999
но вроде бы она нигде не воплощена, и я не знаю, называется ли это как-то иначе.

236
00:48:08,819 --> 00:48:19,338
Я обнаружил, что размораживание слоёв и использование дифференцированных скоростей обучения превращает хорошую модель в отличную.

237
00:48:24,959 --> 00:48:37,578
Вопрос из зала: У вас в массиве три гиперпараметра, и первый — это для последних добавленных слоёв?

238
00:48:40,049 --> 00:48:47,449
Нет, наоборот. Эти параметры относятся к группам слоёв, мы ещё будем говорить про архитектуру,

239
00:48:47,449 --> 00:48:51,000
эта нейронная сеть называется ResNet, остаточная нейронная сеть.

240
00:48:51,100 --> 00:48:55,770
Мы разделили её слои на три группы.

241
00:48:57,249 --> 00:49:09,269
Первая группа — внутренние слои, отвечающие за распознавание углов и краёв предметов.

242
00:49:09,940 --> 00:49:28,319
Вопрос из зала: Я думал, эти слои заморожены. Мы их разморозили и теперь обучаем вообще всё, что есть?

243
00:49:29,049 --> 00:49:33,538
Вопрос из зала: И для внутренних слоёв скорость обучения маленькая, потому что их не нужно сильно менять?

244
00:49:33,539 --> 00:49:43,169
Да, скорее всего, их вообще не нужно менять, но в принципе это возможно.

245
00:49:43,960 --> 00:49:45,960


246
00:49:48,759 --> 00:49:53,009
Вопрос из зала: Чем дифференциальные скорости обучения отличаются от подбора параметров по сетке?

247
00:49:55,119 --> 00:50:06,568
Всем. Подбор параметров по сетке — это поиск оптимального значения гиперпараметра.

248
00:50:07,719 --> 00:50:12,759
Можно думать об алгоритме поиска скорости обучения как о подборе параметров по сетке,

249
00:50:13,350 --> 00:50:16,490
но это никак не относится к дифференциальным скоростям обучения.

250
00:50:16,490 --> 00:50:24,680
На протяжении всего обучения модели для различных слоёв будут использоваться различные скорости обучения.

251
00:50:28,980 --> 00:50:49,758
Вопрос из зала: Что если у меня изображения большего размера, чем те, на которых сеть была обучена?

252
00:50:50,099 --> 00:50:59,508
Про размеры мы ещё пока поговорим, пока ответ такой — в библиотеке fast.ai на вход можно подавать изображения любого размера.

253
00:51:02,849 --> 00:51:07,159
Вопрос из зала: Можно ли разморозить только один уровень?

254
00:51:07,619 --> 00:51:14,629
Да, метод .unfreeze_to(n) разморозит все слои до n-го.

255
00:51:19,440 --> 00:51:38,960
Я считаю, что это бесполезная практика и дифференциальные скорости обучения работают лучше.

256
00:51:43,470 --> 00:51:47,779
Вопрос из зала: А если данных для обучения очень мало?

257
00:51:48,539 --> 00:52:00,259
Нет, не очень помогает. Помогает в обратном случае — когда не хватает мощности GPU для обработки большого количества данных,

258
00:52:00,630 --> 00:52:06,740
размораживание не всех уровней помогает снизить нагрузку на память и уменьшить время обучения.

259
00:52:06,779 --> 00:52:13,758
Вопрос из зала: Переспрошу ещё раз. Можно ли разморозить только один слой?

260
00:52:14,190 --> 00:52:19,069
Нет, только все слои, начиная с какого-то.

261
00:52:21,119 --> 00:52:25,639
Думаю, что можно переписать исходный код и включить эту возможность, но не вижу, зачем.

262
00:52:28,589 --> 00:52:37,070
Я очень рад, что показываю вам все эти штуки, мы работали над ними весь год и это действительно новейшие технологии.

263
00:52:38,970 --> 00:52:49,680
Мы получаем долю правильных ответов 99.5% — это удивительно.

264
00:52:51,780 --> 00:53:05,599
Я оговорился, когда раньше говорил про значение второго параметра. Второй параметр — это количество циклов, а не эпох.

265
00:53:06,000 --> 00:53:19,700
Если бы параметр cycle_len был равен двум, то выполнилось бы три цикла, каждый длиной в две эпохи, итого шесть.

266
00:53:20,339 --> 00:53:24,979
Здесь семь эпох, это из-за параметра cycle_mult=2.

267
00:53:25,380 --> 00:53:39,609
Параметр cycle_mult=2 удваивает длину цикла в эпохах после каждого цикла. Первый цикл длится 1 эпоху, второй — 2, третий — 4, итого 7 эпох.

268
00:53:40,430 --> 00:53:55,520
Автор статьи, описавший этот подход, считает его полезным, и я с ним согласен, вот почему.

269
00:53:57,810 --> 00:54:11,299
Если длина цикла слишком короткая, алгоритм будет постоянно выскакивать наверх и не найдёт хорошую точку.

270
00:54:11,339 --> 00:54:23,269
Это может быть полезно в начале для прощупывания поверхности, но потом стоит увеличить длину цикла.

271
00:54:24,329 --> 00:54:29,869
Значение cycle_mult=2 обычно подходит.

272
00:54:30,480 --> 00:54:35,179
У нас появляется много гиперпараметров, хотя сначала я говорил, что такого не будет.

273
00:54:35,400 --> 00:54:52,729
Всё нормально — скорость обучения всё ещё важнее всего, эти гиперпараметры просто позволяют немного улучшить модель.

274
00:54:53,759 --> 00:55:03,019
Конфигурация из трёх циклов с параметрами cycle_len=1 и cycle_mult=2 очень часто хорошо работает.

275
00:55:04,169 --> 00:55:11,509
Если работает плохо, я пробую три цикла с параметром cycle_len=2 и без параметра cycle_mult.

276
00:55:12,030 --> 00:55:17,190
Эти две конфигурации охватывают большинство случаев, не вижу смысла кропотливо подбирать новые.

277
00:55:17,190 --> 00:55:25,008
Вы можете просто использовать эту строку и получать хорошие результаты.

278
00:55:28,680 --> 00:55:37,069
Вопрос из зала: Почему более гладкие локальные минимумы соответствуют нейронным сетям, которые лучше обобщают?

279
00:55:39,660 --> 00:56:01,152
Возвращаемся к графику зависимости функции потерь от фиксированного параметра модели.

280
00:56:03,152 --> 00:56:24,809
Хорошо обобщающая модель невосприимчива к небольшим различиям в датасетах.

281
00:56:26,009 --> 00:56:33,259
Пусть синей и красной линиями показаны кривые потерь для двух различных датасетов.

282
00:56:34,359 --> 00:56:48,190
Модель в остром локальном минимуме плохо предскажет слегка отличающийся датасет, а в гладком минимуме хорошо предскажет оба.

283
00:56:49,730 --> 00:57:02,858
Избежать этого помогает cycle_mult=2. До перерыва мы успеем ещё раз улучшить модель.

284
00:57:03,380 --> 00:57:16,929
Для этого посмотрим ещё раз на неправильно распознанные изображения.

285
00:57:20,720 --> 00:57:41,709
Как я уже говорил раньше, все изображения обрезаются до квадратов перед тем, как модель их увидит.

286
00:57:42,740 --> 00:57:56,855
GPU быстрее работает, когда все изображения одинаковых размеров, возможно, в будущем это изменится.

287
00:57:56,955 --> 00:58:20,530
Изображение обрезается с сохранением центра — теперь видно, почему это изображение было распознано неправильно.

288
00:58:20,530 --> 00:58:35,709
Модель видела только тело животного, и по такому телу действительно сложно понять, кошка это или собака.

289
00:58:36,380 --> 00:58:42,160
Для решения этой проблемы мы применим тестовое дополнение данных (TTA).

290
00:58:42,560 --> 00:58:52,385
После обучения модели мы проведём дополнение данных на валидационной выборке

291
00:58:52,485 --> 00:59:02,310
и для каждого изображения выберем 4 новых случайных варианта.

292
00:59:02,720 --> 00:59:14,110
После обрезки получится 5 вариантов изображения, для каждого варианта получим предсказание и усредним.

293
00:59:14,750 --> 00:59:33,789
Для неудачных изображений один из вариантов после обрезки может содержать морду животного и оценка улучшится.

294
00:59:35,270 --> 00:59:40,510
Для применения тестового дополнения данных нужно вызвать метод .TTA().

295
00:59:40,700 --> 00:59:53,620
Оно называется тестовым, потому что применяется во время тестирования, сразу после обучения модели.

296
00:59:53,620 --> 01:00:00,910
Доля правильных ответов увеличилась до 99.65%.

297
01:00:01,460 --> 01:00:14,380
Вопрос из зала: Но во время обучения модели внутри одной эпохи модель видит только один вариант изображения?

298
01:00:14,930 --> 01:00:26,319
Нет, TTA здесь нет, я пробовал добавлять это в библиотеку, но тут этого нет.

299
01:00:26,320 --> 01:00:46,449
Здесь модель обучается с обычным дополнением данных, то есть после каждой эпохи все изображения немного менялись.

300
01:00:47,030 --> 01:00:56,229
После обучения модели мы вызываем TTA на валидационной выборке (по умолчанию).

301
01:00:56,230 --> 01:01:01,430
Для каждого изображения в валидационной выборке создаются 4 новых варианта,

302
01:01:04,210 --> 01:01:09,610
предсказания по ним усредняются с предсказаниями по оригинальному изображению, и получается новая доля правильных ответов.

303
01:01:10,200 --> 01:01:16,199
Вопрос из зала: То есть во время TTA модель видит изображения, которые не видела при обучении?

304
01:01:17,590 --> 01:01:25,559
Да, вообще все получающиеся в результате дополнения данных изображения уникальны.

305
01:01:25,660 --> 01:01:33,960
Изображение может быть повёрнуто всего на 0.34 градуса и увеличено всего в 1.056 раз, но это новое изображение.

306
01:01:36,849 --> 01:01:46,169
Вопрос из зала: Почему нельзя нарисовать белые границы, дополнив изображение до квадрата, а не обрезать его?

307
01:01:46,170 --> 01:01:55,160
Можно. Есть много алгоритмов дополнения данных, один из них — как раз добавление границ.

308
01:01:55,900 --> 01:02:06,240
По своему опыту могу сказать, что это не сильно помогает.

309
01:02:06,790 --> 01:02:12,209
Позже я покажу один из алгоритмов добавления границ — отражение,

310
01:02:12,210 --> 01:02:19,230
вместо белых границ вставляются отражённые части изображения, помогает со спутниковыми снимками.

311
01:02:19,869 --> 01:02:25,238
Обычно я приближаю изображение и обрезаю, а не добавляю границы.

312
01:02:28,390 --> 01:02:40,979
Вопрос из зала: Но в случае с длинной собакой при обрезке теряется морда, а при добавлении границ — нет.

313
01:02:41,560 --> 01:02:46,019
Да, в этом случае помогло бы добавление границ с отражением.

314
01:02:46,020 --> 01:02:50,939
В библиотеке fast.ai воплощено много алгоритмов дополнения данных.

315
01:02:51,440 --> 01:03:01,229
Конечно, всё зависит от размеров изображения,

316
01:03:01,870 --> 01:03:09,750
но, как правило, при использовании дополнения данных и TTA эффективнее найти максимально большое изображение

317
01:03:09,750 --> 01:03:22,049
и обрезать его до квадрата, чем вставлять границы и нагружать GPU.

318
01:03:22,050 --> 01:03:27,550
На практике добавление границ менее эффективно.

319
01:03:35,410 --> 01:03:44,190
Вопрос из зала: Как выглядит дополнение данных для датасетов не из изображений?

320
01:03:47,440 --> 01:03:50,399
Сложный вопрос.

321
01:03:52,630 --> 01:03:58,560
Я обсуждал это со своими друзьями из области обработки естественного языка (NLP), мы доберёмся до этого через пару лекций.

322
01:03:59,110 --> 01:04:18,480
Есть пара примеров статей, где слова заменялись на синонимы, но в целом область дополнения данных в NLP не развита.

323
01:04:23,500 --> 01:04:38,939
Вопрос из зала: Разве не проще было бы просто разрезать изображение, скажем, на три части вместо TTA?

324
01:04:40,349 --> 01:04:52,139
Для обучения модели — нет, гораздо эффективнее предоставить много слегка различающихся версий,

325
01:04:52,140 --> 01:04:58,890
чем просто три части изображения.

326
01:04:59,739 --> 01:05:07,960
Для TTA — да, возможно, это было бы лучше, но я ещё не написал соответствующий код в библиотеку.

327
01:05:07,960 --> 01:05:21,539
У меня где-то лежит старая версия кода. Я думаю, разрезание изображений хорошо бы сочеталось с дополнением данных.

328
01:05:23,619 --> 01:05:32,729
Я тестировал это и результаты почти незаменты, поэтому этого нет в библиотеке, да и код сильно усложнился бы.

329
01:05:34,490 --> 01:05:41,510
Вопрос из зала: Открыт ли исходный код библиотеки fast.ai?

330
01:05:43,440 --> 01:05:53,660
Да, открыт. Здесь надо упомянуть пару вещей.

331
01:05:54,089 --> 01:06:01,699
Библиотека fast.ai построена на основе PyTorch,

332
01:06:02,940 --> 01:06:15,199
PyTorch появился недавно и все уважаемые мной исследователи его используют.

333
01:06:15,960 --> 01:06:20,584
Во второй части прошлого запуска второго курса обнаружилось, что новейшие техники

334
01:06:20,684 --> 01:06:32,629
не получается преподавать с Keras и TensorFlow, как раньше, поэтому мы перешли на PyTorch на полпути.

335
01:06:33,630 --> 01:06:38,910
Проблема в том, что PyTorch довольно сложно использовать — всё надо писать с нуля.

336
01:06:39,510 --> 01:06:59,119
Вся библиотека fast.ai написана с нуля на основе PyTorch, чтобы вам не пришлось писать сотни строк кода для простых вещей.

337
01:06:59,910 --> 01:07:10,939
Мы хотим научить вас создавать модели мирового уровня. Для этого нужен PyTorch,

338
01:07:11,520 --> 01:07:27,740
но его сложно применять, поэтому мы написали библиотеку на его основе.

339
01:07:29,339 --> 01:07:36,859
Как я уже сказал, изначально мы использовали Keras, но потом поняли, что можно сильно всё упростить.

340
01:07:36,930 --> 01:07:50,298
В Jupyter ноутбуках прошлых запусков код в два-три раза длиннее и много возможностей ошибиться,

341
01:07:51,539 --> 01:08:01,969
поэтому мы написали библиотеку fast.ai, чтобы легко научить вас создавать современные модели.

342
01:08:02,729 --> 01:08:16,818
За последний год мы поняли, что эта библиотека помогает и нам. Мы начали разрабатывать больше новых методов,

343
01:08:16,819 --> 01:08:30,109
стали внедрять малоизвестные, но эффективные техники вроде поиска скорости обучения, которые ещё никто не автоматизировал.

344
01:08:31,109 --> 01:08:50,178
Библиотека fast.ai не только упрощает процесс, а ещё и предлагает массу уникальных возможностей.

345
01:08:51,299 --> 01:09:04,668
Сейчас библиотека сыровата, многие уже помогли нам в её написании, и я надеюсь, что к концу этого курса

346
01:09:06,270 --> 01:09:19,039
мы доведём её до ума, и все смогут её использовать. Открытый исходный код доступен на GitHub.

347
01:09:23,069 --> 01:09:32,689
Создаваемые в fast.ai модели PyTorch можно экспортировать во множество форматов.

348
01:09:33,689 --> 01:09:40,339
Если вы создаёте приложение для смартфона, скорее всего, вам придётся использовать TensorFlow.

349
01:09:41,040 --> 01:09:53,329
Позже мы обсудим, что из библиотеки fast.ai работает под Keras и TensorFlow, чтобы вы поняли, чем они различаются.

350
01:09:53,908 --> 01:10:06,679
Если вкратце — простые вещи быстрее делать с Keras и TensorFlow, а fast.ai и PyTorch лучше подходят для сложных моделей.

351
01:10:07,590 --> 01:10:14,659
Если вам нужно использовать именно TensorFlow, возможно, придётся что-то упростить.

352
01:10:18,060 --> 01:10:29,600
Конкретная библиотека не так важна — каждый год всё меняется.

353
01:10:29,600 --> 01:10:34,879
Главное, чтобы вы поняли основные идеи — как подбирать скорость обучения, зачем нужны дифференциальные скорости обучения,

354
01:10:34,880 --> 01:10:43,009
как менять скорость обучения в процессе обучения модели, что делает SGDR и так далее.

355
01:10:44,550 --> 01:10:53,540
Через год библиотеки могут сильно измениться.

356
01:11:03,510 --> 01:11:08,510
Вопрос из зала: Что вы думаете про Pyro?

357
01:11:09,010 --> 01:11:14,060
Мне очень интересно вероятностное программирование, но я пока не смотрел на Pyro. Очень круто, что Pyro использует PyTorch.

358
01:11:14,060 --> 01:11:19,859
Позже мы поговорим о том, что PyTorch — не просто библиотека для глубокого обучения.

359
01:11:20,360 --> 01:11:34,760
Например, PyTorch позволяет писать свои алгоритмы GPU-ускорения, мы этим ещё займёмся.

360
01:11:35,969 --> 01:11:41,719
Ладно, давайте сделаем перерыв на 8 минут и продолжим в 7:55.

361
01:11:46,590 --> 01:11:56,929
Итак, что значит доля правильных ответов 99.65%?

362
01:11:57,570 --> 01:12:06,409
В машинном обучении для оценивания качества модели часто используют матрицу ошибок.

363
01:12:06,719 --> 01:12:26,329
Сколько из 1000 кошек в валидационной выборке было распознано как кошки?

364
01:12:26,820 --> 01:12:33,259
Здесь 998 кошек из 1000 были распознаны как кошки, 2 — как собаки.

365
01:12:33,260 --> 01:12:39,980
Из 1000 собак 995 были распознаны как собаки и 5 — как кошки.

366
01:12:40,710 --> 01:12:50,599
Такие матрицы ошибок очень помогают, когда классов больше двух и непонятно, с чем больше всего проблем.

367
01:12:50,940 --> 01:12:59,480
Высокие значения выделены цветом, с такой матрицей удобно работать из предположения, что все цветные блоки должны быть на диагонали.

368
01:13:00,150 --> 01:13:10,130
После улучшения модели стоит ещё раз посмотреть на неправильно распознанные изображения.

369
01:13:10,680 --> 01:13:18,770
Неправильных кошек было две, но по умолчанию выводится четыре изображения.

370
01:13:18,770 --> 01:13:32,600
Есть два изображения, на которых точно не кошка, но с этим непонятно — изображение плохого качества и не видно зрачков.

371
01:13:33,120 --> 01:13:49,069
Неправильных собак было пять, вот четыре из них. Одна из них очевидно не собака, две выглядят как ошибки и ещё одна — как недостаток информации.

372
01:13:50,190 --> 01:14:01,640
Я участвовал во многих соревнованиях Kaggle и написал про них пару статей, с уверенностью говорю, что классификатор отличный.

373
01:14:01,640 --> 01:14:08,930
Он уже отличный, но потом мы ещё немного его улучшим.

374
01:14:08,930 --> 01:14:13,889
Вот что нужно делать для создания подобного классификатора:

375
01:14:14,270 --> 01:14:22,620
1. Применить на датасете один из алгоритмов дополнения данных

376
01:14:23,260 --> 01:14:26,660
и использовать предвычисленные активации с помощью precompute=true.

377
01:14:27,179 --> 01:14:35,059
2. Найти оптимальную скорость обучения и 3. создать новый слой нейронной сети, обучая его 1-2 эпохи.

378
01:14:35,460 --> 01:14:44,720
4. Выставить precompute=false для использования дополнения данных и создать новый слой, обучая его 2-3 эпохи с параметром cycle_len=1.

379
01:14:45,090 --> 01:14:56,059
5. Разморозить все уровни и 6. выставить различные скорости обучения для различных слоёв.

380
01:15:00,450 --> 01:15:07,110
В нашем случае разница между скоростями обучения для различных слоёв была в десять раз.

381
01:15:07,110 --> 01:15:21,410
Если вы работаете с обученной на изображениях ImageNet модели и классифицируете обычные фотографии,

382
01:15:22,110 --> 01:15:29,179
разумно делать скорость обучения каждый раз в 10 раз меньше, потому что внутренние слои уже достаточно хороши.

383
01:15:29,760 --> 01:15:37,739
Если вместо обычных фотографий у вас спутниковые или томографические снимки, внутренние слои придётся немного изменить,

384
01:15:38,140 --> 01:15:42,799
для этого можно выставить скорости обучения, различающиеся в 3 раза, а не в 10.

385
01:15:43,440 --> 01:15:48,109
Итак, скорости различаются в 3 или в 10 раз.

386
01:15:51,450 --> 01:15:59,540
7. После разморозки можно снова подобрать скорость обучения.

387
01:15:59,580 --> 01:16:08,270
Я не подбирал, но можно было, так как модель поменялась — мы разморозили слои и добавили дифференциальные скорости обучения.

388
01:16:09,030 --> 01:16:14,179
После подбора можно сверить, поменялась ли оптимальная скорость обучения.

389
01:16:14,850 --> 01:16:20,630
Если вы вызовете метод .lr_find() при наличии дифференциальных скоростей обучения, он выведет

390
01:16:21,000 --> 01:16:28,900
оптимальную скорость обучения для последнего слоя.

391
01:16:29,190 --> 01:16:35,450
8. Обучать всю нейронную сеть с параметром cycle_mult=2, пока не наступит переобучение или не кончится время.

392
01:16:35,610 --> 01:16:41,089
Давайте повторим эти шаги на новом датасете.

393
01:16:41,640 --> 01:16:53,070
Сегодня утром я заметил, что некоторые из вас приняли участие в соревновании Kaggle по различению пород собак.

394
01:16:53,680 --> 01:17:08,849
В этом соревновании нужно определить, к какой из 120 пород принадлежат собаки на фотографиях.

395
01:17:09,370 --> 01:17:29,789
Датасет может быть любой — томографические снимки, спутниковые снимки, любые размеченные изображения.

396
01:17:30,820 --> 01:17:40,499
Сейчас я покажу, что сделал сегодня утром за час.

397
01:17:41,650 --> 01:17:47,790
Я скачал данные соревнования по различеню пород собак с Kaggle, используя kaggle-cli —

398
01:17:48,130 --> 01:17:58,919
это интерфейс командной строки Kaggle, позволяющий скачать данные любого соревнования на ваш сервер Amazon, Crestle или любой другой.

399
01:17:59,440 --> 01:18:10,349
Я посмотрел на файлы — они организованы не так, как наш учебный датасет.

400
01:18:11,560 --> 01:18:16,905
Обучающая и тестовая выборки не размечены, их метки лежат в отдельном csv-файле.

401
01:18:17,005 --> 01:18:25,410
Я прочитал csv с помощью pandas, это библиотека Python для работы со структурированными файлами.

402
01:18:31,030 --> 01:18:39,120
Мы импортируем pandas как pd и вызываем метод pd.read_csv().

403
01:18:39,120 --> 01:18:46,260
Внутри csv файла — таблица соответствий имён файлов и пород собак, это второй способ разметки данных.

404
01:18:46,260 --> 01:19:02,489
Первый способ — раскладывать изображения по разным папкам, второй — держать разметку в отдельном файле.

405
01:19:04,359 --> 01:19:10,019
С помощью pandas я создал сводную таблицу, чтобы посмотреть на распределение пород.

406
01:19:10,119 --> 01:19:24,689
Видно, что на самые распространённые породы приходится где-то по 100 изображений, на менее распространённые — около 60.

407
01:19:25,269 --> 01:19:30,239
В сводной таблице 120 строк, потому что в датасете представлено 120 пород собак.

408
01:19:30,760 --> 01:19:35,179
Пойдём по описанному выше алгоритму.

409
01:19:35,760 --> 01:19:48,599
Для дополнения данных я опять выбрал transfoms_side_on и передал его в функцию tfms_from_model().

410
01:19:50,349 --> 01:20:00,148
Про параметр max_zoom мы ещё поговорим, он показывает максимально допустимое увеличение при дополнении данных.

411
01:20:00,789 --> 01:20:13,618
Все изменённые изображения будут увеличены максимум в 1.1 раза.

412
01:20:14,409 --> 01:20:30,929
Вместо метода .from_path() мы вызываем метод .from_csv() и передаём туда csv-файл с метками данных.

413
01:20:31,479 --> 01:20:41,069
Параметры метода — директория с данными, папка с обучающей выборкой, csv с метками,

414
01:20:42,699 --> 01:20:47,728
папка с тестовой выборкой — она нужна, если вы хотите отправить результат на Kaggle, мы это ещё обсудим.

415
01:20:49,149 --> 01:21:05,499
В предыдущем датасете у нас была валидационная выборка, а в этом её нет.

416
01:21:05,499 --> 01:21:13,089
Для оценивания качества модели перед отправкой на Kaggle мы случайным образом выделим валидационную выборку из обучающей.

417
01:21:13,670 --> 01:21:26,679
Здесь я сначала получил размер обучающей выборки n, преобразовав csv файл в список строк и взяв его длину.

418
01:21:27,050 --> 01:21:33,279
Размер выборки на единицу меньше количества строк, потому что первая строка — заголовок.

419
01:21:35,130 --> 01:21:47,679
Затем я вызвал метод получения индексов для кросс-валидации get_cv_idxs(). Про кросс-валидацию мы ещё поговорим.

420
01:21:48,590 --> 01:22:09,430
По умолчанию метод возвращает индексы случайных 20% выборки, это и будет наша валидационная выборка.

421
01:22:11,090 --> 01:22:34,279
Давайте посмотрим на неё. Индексы — это просто числа, n=10222, размер валидационной выборки — 2044.

422
01:22:35,310 --> 01:22:50,629
Массив индексов валидационной выборки тоже передаётся как параметр в метод .from_csv.

423
01:22:52,350 --> 01:23:18,709
Названия файлов в csv не содержат суффикса .jpg, поэтому мы передаём его туда же как suffix='.jpg'.

424
01:23:19,710 --> 01:23:25,219
Это все необходимые параметры.

425
01:23:25,890 --> 01:23:36,739
Многие из вас на этой неделе заметили, что обучающая выборка находится в объекте data.trn_ds и её можно изучать.

426
01:23:37,290 --> 01:23:55,699
Например, она содержит имена изображений, можно взять, например, самое первое и посмотреть на него.

427
01:23:56,040 --> 01:24:04,940
Мне было интересно, как выглядят данные, и я нашёл очаровательного щенка, очень мило.

428
01:24:04,940 --> 01:24:20,149
Дальше я смотрю, какого размера изображения в датасете. Если они слишком большие или слишком маленькие, это неудобно.

429
01:24:20,670 --> 01:24:29,779
Стандартные форматы моделей, обучающихся на изображениях ImageNet — 224x224 и 299x299.

430
01:24:30,090 --> 01:24:38,059
Если ваши изображения близки к таким размерам, как здесь — это отлично.

431
01:24:39,880 --> 01:24:51,509
Здесь я создаю словарь, используя генератор словарей. Генераторы словарей и списков в Python — очень удобные конструкции.

432
01:24:52,060 --> 01:25:02,040
Я прохожу по всем файлам и создаю словарь, где каждому имени файла соответствует размер файла.

433
01:25:04,389 --> 01:25:17,760
Ещё одна удобная конструкция, о которой я потом расскажу — распаковка аргументов, здесь мы выделяем высоты и ширины изображений.

434
01:25:18,639 --> 01:25:27,449
После этого массивы высот и ширин оборачиваются в массивы numpy, вот первые пять высот изображений.

435
01:25:27,969 --> 01:25:45,899
Здесь мы, как обычно, импортируем matplotlib.pyplot как plt, и строим гистограмму распределения высот методом plt.hist().

436
01:25:45,900 --> 01:25:52,589
Я делаю это для того, чтобы понять, с чем работаю.

437
01:25:53,139 --> 01:26:10,889
Большинсто изображений высотой меньше 1000 пикселей. Давайте возьмём только их и построим ещё одну гистограмму.

438
01:26:10,889 --> 01:26:25,520
Высота большинства изображений около 500, если точнее — 4581 изображение имеет высоту примерно 450.

439
01:26:27,940 --> 01:26:34,799
Вопрос из зала: Валидационная выборка всегда должна занимать 20% от данных?

440
01:26:39,179 --> 01:26:52,129
Обычно 20% хватает, если у вас не очень маленькие датасеты.

441
01:26:54,030 --> 01:27:00,949
Если вы обучаете модель несколько раз и предсказания на валидационной выборке каждый раз сильно отличаются,

442
01:27:01,549 --> 01:27:12,919
это сложно интерпретировать. Обычно так происходит, когда в валидационной выборке меньше 1000 изображений.

443
01:27:12,920 --> 01:27:17,599
Если вы боретесь за третий знак после запятой в доле правильных ответов,

444
01:27:18,630 --> 01:27:26,800
добавление даже одного изображения в маленькую валидационную выборку может изменить этот знак.

445
01:27:27,449 --> 01:27:53,119
Улучшение доли правильных ответов на 0.01 будет соответствовать правильной классификации ещё 10-20 изображений.

446
01:27:53,940 --> 01:28:09,739
В общем, почти всегда 20% достаточно, хотя это зависит от ваших целей.

447
01:28:11,639 --> 01:28:19,639
Этот вопрос относится не только к глубокому обучению, но и к машинному обучению в принципе —

448
01:28:19,639 --> 01:28:24,769
мы будем его обсужать в нашем курсе «Машинное обучение», он тоже будет онлайн.

449
01:28:27,389 --> 01:28:32,149
Сначала я смотрел на распределение высот изображений, а потом повторил то же самое для ширин,

450
01:28:32,280 --> 01:28:37,489
чтобы убедиться, что изображения не вытянуты вдоль какой-то оси. Результаты схожие, средняя ширина около 400.

451
01:28:38,130 --> 01:28:44,240
Видно, что датасет состоит из изображений хорошего размера.

452
01:28:44,929 --> 01:28:54,720
Изображения хорошего качества — здесь собака оптимального размера и находится в центре, обрезка не помешает классификации.

453
01:28:55,420 --> 01:29:04,710
Если бы собака была меньше и находилась в углу изображения, пришлось бы его увеличивать.

454
01:29:04,990 --> 01:29:13,090
На диагностических снимках опухоль обычно видна как маленькое пятнышко среди сложных структур, там всё гораздо сложнее.

455
01:29:13,090 --> 01:29:18,095
Наши изображения вполне стандартные.

456
01:29:18,195 --> 01:29:29,189
Я написал функцию get_data() для получения данных, здесь две строки кода, которые мы уже видели,

457
01:29:30,280 --> 01:29:34,319
и возможность передавать размер изображения sz и размер минибатча bs.

458
01:29:35,020 --> 01:29:40,080
Первые попытки обучения модели должны занимать мало времени, чтобы быстро понять, что происходит,

459
01:29:40,270 --> 01:29:47,670
поэтому сначала я уменьшил размер изображений до 64x64.

460
01:29:48,040 --> 01:29:58,560
Потом я поставил размер изображений побольше и усложнил архитектуру,

461
01:29:58,810 --> 01:30:03,780
и получил ошибку CUDA_ERROR_OUT_OF_MEMORY, нехватка памяти.

462
01:30:04,570 --> 01:30:19,940
GPU не справится с этой ошибкой сам, необходимо каждый раз перезапускать ноутбук.

463
01:30:21,190 --> 01:30:34,410
После перезапуска я уменьшил размер минибатча bs, он передаётся в метод ImageClassifierData.from_csv().

464
01:30:34,410 --> 01:30:43,020
Обычно я использую bs=64, после каждой ошибки о нехватки памяти уменьшаю это значение в два раза.

465
01:30:44,500 --> 01:30:49,740
Итак, функция get_data() позволяет мне увеличивать размер изображения для улучшения модели и

466
01:30:49,810 --> 01:30:53,075
менять размер минибатча, чтобы не утыкаться в нехватку памяти.

467
01:30:53,175 --> 01:31:03,579
Я поэкспериментировал с различными значениями и всё работало хорошо, поэтому я выставил размер изображения sz=224.

468
01:31:04,580 --> 01:31:12,939
Мы используем precompute=True, из-за этого первая попытка обучения модели заняла около минуты,

469
01:31:12,940 --> 01:31:18,190
и за 4 или 5 секунд мы обучили модель с долей правильных ответов 83%.

470
01:31:18,770 --> 01:31:25,479
Напомню, что доля правильных ответов показывает, сколько изображений было распознано абслютно верно.

471
01:31:25,670 --> 01:31:36,340
Достичь доли правильных ответов в 80% на 120 классах гораздо сложнее, чем в задаче двухклассовой классификации,

472
01:31:37,190 --> 01:31:52,030
поэтому я был приятно удивлён такому результату на модели без дополнения данных и разморозки слоёв.

473
01:31:53,120 --> 01:32:11,170
Следуя алгоритму, я выставил precompute=False, cycle_len=1 и увеличил количество циклов.

474
01:32:11,480 --> 01:32:16,719
Напомню, на протяжении одной эпохи модель один раз просматривает все изображения,

475
01:32:17,660 --> 01:32:27,159
а длина цикла показывает, сколько на его протяжении выполняется эпох, и на протяжении цикла скорость обучения только падает.

476
01:32:27,740 --> 01:32:37,220
Здесь cycle_len=1, то есть эпоха и цикл в данном случае — одно и то же.

477
01:32:37,220 --> 01:32:41,949
Я выполнил алгоритм поиска скорости обучения и остановился на значении 1e-2.

478
01:32:41,950 --> 01:32:49,780
Модель обучалась на протяжении пяти эпох, с каждой эпохой доля правильных ответов увеличивалась.

479
01:32:52,160 --> 01:32:58,720
После сохранения модели я сделал кое-что новое.

480
01:32:59,720 --> 01:33:07,449
Если вы обучили модель на изображениях маленького размера, вы можете вызвать метод .set_data()

481
01:33:08,120 --> 01:33:19,939
и передать модели те же изображения, но большего размера, при этом сохранив результаты обучения на маленьких размерах.

482
01:33:19,939 --> 01:33:31,629
Это ещё одна техника получения отличных результатов, о которой я пока нигде не слышал.

483
01:33:32,840 --> 01:33:45,398
Я обучил модель на изображениях размера 224x224, а сейчас прогоню ещё несколько эпох на 299x299.

484
01:33:45,399 --> 01:33:52,929
Для глубокого обучения у меня очень маленький датасет, всего 10 тысяч изображений, велика вероятность переобучения.

485
01:33:52,929 --> 01:34:09,649
Даже если я достиг переобучения на изображениях размера 224x224, ситуация улучшится при добавлении изображений 299x299.

486
01:34:10,789 --> 01:34:19,089
Изображения те же самые, но большего размера, поэтому модель воспринимает их как новые данные.

487
01:34:19,090 --> 01:34:32,349
Это удобный способ избежать переобучения — использовать датасет сначала с уменьшенными изображениями, а потом без изменений.

488
01:34:32,349 --> 01:34:39,479
Способ простой и очевидный, но я нигде про такое не читал.

489
01:34:43,610 --> 01:34:50,199
Вопрос из зала: Это можно сделать с использованием Keras и TensorFlow?

490
01:34:50,869 --> 01:35:10,629
Да, почти все современные архитектуры могут работать с произвольными размерами изображений, кроме, пожалуй, VGG-Net.

491
01:35:12,199 --> 01:35:15,339
Да, попробуйте, должно сработать.

492
01:35:17,209 --> 01:35:22,839
В метод .set_data() я передаю результат работы функции get_data(), которую уже показывал,

493
01:35:22,840 --> 01:35:25,929
она меняет размер всех изображений на 299x299.

494
01:35:26,599 --> 01:35:37,090
Все слои и так заморожены, но я на всякий случай делаю это ещё раз методом .freeze().

495
01:35:37,809 --> 01:35:50,850
Так как значение параметра precompute=False, модель обучается на дополненных данных.

496
01:35:50,850 --> 01:36:00,330
Я запустил три эпохи, видно, что потери на обучающей выборке больше потерь на валидационной.

497
01:36:00,429 --> 01:36:13,080
Это значит, что модель недообучается, длина цикла слишком коротка, модель не успевает за один цикл найти оптимальную область.

498
01:36:13,870 --> 01:36:20,519
Чтобы это исправить, мы ставим cycle_mult=2, теперь количество эпох в цикле удваивается каждый цикл.

499
01:36:20,770 --> 01:36:24,434
Первый цикл длится одну эпоху, второй — две, третий — четыре, итого семь.

500
01:36:24,934 --> 01:36:36,480
Теперь потери на обучающей и валидационной выборке одинаковые, мы движемся в правильном направлении.

501
01:36:37,060 --> 01:36:41,789
После этого я применяю тестовое дополнение данных, оно немного улучшает результаты.

502
01:36:42,699 --> 01:36:54,659
К этому моменту модель уже почти обучена, на всякий случай я обучаю её ещё пару эпох, это немного помогает.

503
01:36:55,179 --> 01:37:03,040
Результат неплохой, функция потерь на валидационной выборке принимает значение 0.199.

504
01:37:03,040 --> 01:37:21,749
Я не стал размораживать слои и менять их, потому что датасет очень похож на изображения ImageNet и это ничего не изменит.

505
01:37:22,690 --> 01:37:27,899
Когда я отправил результаты, выяснилось, что это действительно изображения ImageNet.

506
01:37:28,480 --> 01:37:41,190
Давайте посмотрим на таблицу результатов. Это учебное соревнование, но всё равно интересно.

507
01:37:41,949 --> 01:37:55,880
Наша модель почти попала в десятку   лучших. Я вижу студентов fast.ai на 8 и 9 местах,

508
01:37:57,030 --> 01:38:04,280
вижу людей в топе, которые схитрили, скачали валидационную выборку и обучили модель её предсказывать.

509
01:38:06,929 --> 01:38:14,959
Это учебное соревнование, оно для экспериментов, здесь так можно.

510
01:38:16,170 --> 01:38:25,670
У нас неплохие результаты — мы не делали ничего особенного и уже обошли две сотни команд.

511
01:38:25,670 --> 01:38:38,110
Мы использовали не все данные при обучении, можно убрать валидационную выборку и отправить результаты ещё раз.

512
01:38:46,350 --> 01:38:51,949
Вопрос из зала: Данные в датасете несбалансированы, как это учтено?

513
01:38:53,780 --> 01:39:06,020
Он не сбалансирован, но не настолько, чтобы это стало проблемой, от 60 до 100 изображений на класс это нормально.

514
01:39:06,540 --> 01:39:11,959
Вопрос из зала: А что можно делать с сильно несбалансированными данными?

515
01:39:12,600 --> 01:39:30,170
Мы это ещё обсудим, если вкратце — пару недель вышла статья, в которой авторы рекомендуют просто копировать редкие изображения.

516
01:39:33,510 --> 01:39:50,600
Вопрос из зала: В чём разница между precompute=True и .unfreeze()? Во время обучения с precompute=True не работает дополнение данных, так?

517
01:39:51,150 --> 01:39:57,080
Да, предварительные слои заморожены и дополнение данных не влияет на модель.

518
01:39:59,910 --> 01:40:06,709
Вопрос из зала: А что конкретно происходит при вызове метода .unfreeze()?

519
01:40:08,559 --> 01:40:13,319
Мы ещё поговорим про разморозку слоёв позже, пока скажу вкратце.

520
01:40:13,420 --> 01:40:24,449
Мы начали обучение с предвычисленными активациями, нейронная сеть уже умела выделять какие-то признаки.

521
01:40:25,989 --> 01:40:35,219
Мы добавили пару слоёв поверх уже существующих.

522
01:40:35,559 --> 01:40:46,840
Параметр precompute=True значит, что обучаются только добавленные нами слои,

523
01:40:46,840 --> 01:40:52,409
причём обучаются на основе известных нам активаций вроде «Это — глаз» и «Это — лицо».

524
01:40:52,989 --> 01:40:58,199
Дополнение данных не работает, потому что всё время используются предвычисленные активации, которые не меняются.

525
01:40:58,299 --> 01:41:08,729
Если поставить precompute=False, всё ещё будут меняться только последние два слоя,

526
01:41:08,729 --> 01:41:15,479
но дополнение данных будет работать, потому что активации будут пересоздаваться с нуля.

527
01:41:16,630 --> 01:41:24,024
Потом можно сделать .unfreeze(), тогда при обучении будут меняться все существующие слои.

528
01:41:24,524 --> 01:41:28,719
Вопрос из зала: Почему бы тогда сразу не ставить precompute=False?

529
01:41:29,499 --> 01:41:39,958
Единственное преимущество precompute=True в том, что это на порядок быстрее precompute=False.

530
01:41:40,539 --> 01:41:54,388
На больших датасетах это имеет значение, но никакого выигрыша в доле правильных ответов вы не получите, только во времени.

531
01:41:55,090 --> 01:41:59,699
Это полезно при создании тестовых моделей.

532
01:42:01,949 --> 01:42:20,538
Вопрос из зала: Как упростить ваш алгоритм, чтобы не анализировать результаты после каждого шага?

533
01:42:23,099 --> 01:42:44,538
Если вам нужна версия покороче, я могу выкинуть пару шагов. Главные шаги такие:

534
01:42:44,729 --> 01:42:50,239
Можно не ставить precompute=True, это просто экономия времени.

535
01:42:50,729 --> 01:42:53,689
1. Я всё равно советую подбирать скорость обучения.

536
01:42:55,530 --> 01:43:01,639
2. Изначально все слои заморожены, начните с обучения модели в течение 2-3 эпох с параметром cycle_len=1.

537
01:43:02,550 --> 01:43:07,019
3. Разморозьте слои и 4.-5. Обучите модель с дифференциальными скоростями обучения.

538
01:43:07,580 --> 01:43:15,739
Получается три этапа: найти скорость обучения, обучить замороженную модель с cycle_len=1,

539
01:43:16,289 --> 01:43:21,049
обучить размороженную модель с дифференциальными скоростями обучения и cycle_mult=2.

540
01:43:21,719 --> 01:43:30,059
У вас получится 5 или 6 строк кода.

541
01:43:30,059 --> 01:43:32,268
Вопрос?

542
01:43:33,719 --> 01:43:39,138
Вопрос из зала: Размер минибатча влияет только на время обучения?

543
01:43:39,139 --> 01:43:46,969
В общем да. Мы ещё обсудим это в деталях, станет понятнее, если вкратце —

544
01:43:46,969 --> 01:43:58,248
при маленьких размерах минибатча модель видит меньше изображений за раз и поэтому менее точно вычисляет градиент,

545
01:43:58,249 --> 01:44:09,769
то есть уменьшением размера минибатча вы увеличиваете изменчивость модели.

546
01:44:10,709 --> 01:44:28,199
Это влияет на оптимальную скорость обучения, но при уменьшении размера минибатча в 2-4 раза это влияние невелико.

547
01:44:28,659 --> 01:44:32,798
Вопрос из зала: Надо ли после изменения размера минибатча пересчитывать скорость обучения?

548
01:44:33,359 --> 01:44:45,149
Если изменение сильное, можно, но на практике скорость обучения не меняется с точностью до порядка.

549
01:44:48,090 --> 01:45:20,639
Вопрос из зала: Объясните ещё раз, что значат изображения из демонстрации работы различных слоёв.

550
01:45:22,090 --> 01:45:24,210
Мы это ещё будем обсуждать.

551
01:45:24,210 --> 01:45:30,179
Серые изображения — имитация того, как выглядят свёрточные фильтры. На первом слое они действительно так выглядят,

552
01:45:30,179 --> 01:45:40,019
потому что на вход этих фильтров подаются пиксели, вспомните матрицу свёртки с прошлой лекции.

553
01:45:40,210 --> 01:45:45,419
В примере матрица свёртки была 3х3, здесь 7х7.

554
01:45:45,820 --> 01:45:55,499
Для остальных слоёв входные данные — уже не пиксели, а комбинации фильтров, это нельзя просто нарисовать.

555
01:45:55,570 --> 01:46:05,720
Авторы статьи придумали алгоритм, который показывает, как примерно фильтры выглядели в среднем.

556
01:46:06,490 --> 01:46:22,859
Справа — примеры частей изображений, которые активируют эти фильтры, они иллюстрируют их работу.

557
01:46:25,320 --> 01:46:38,020
Вопрос из зала: Как рисовались серые изображения?

558
01:46:38,920 --> 01:46:51,299
Мы это ещё обсудим во второй части курса, это называется обратная свёртка.

559
01:46:51,940 --> 01:47:02,190
Можете почитать статью, ссылка на неё есть в Jupyter ноутбуке.

560
01:47:03,310 --> 01:47:08,160
Алгоритм очень изящный, но его сложно осознать.

561
01:47:17,130 --> 01:47:31,850
Вопрос из зала: Что бы вы делали, если собаки на изображениях находились бы не в центре?

562
01:47:33,510 --> 01:47:40,610
Это мы тоже обсудим во второй части курса. Есть алгоритм, позволяющий модели понять,

563
01:47:41,010 --> 01:47:50,779
где на изображении может быть что-то интересное, он помогает обрезать ненужные части.

564
01:47:50,780 --> 01:48:02,658
Я упоминал это на седьмой лекции прошлого запуска первой части курса, но расскажу детальнее в ближайшем запуске второй части.

565
01:48:05,969 --> 01:48:11,839
Может, в первой части найдётся время, я знаю, что Янет уже написала часть кода.

566
01:48:16,760 --> 01:48:28,420
Получив рабочую модель, можно моментально улучшить её ещё двумя способами.

567
01:48:29,840 --> 01:48:41,830
Первый — увеличить размер входных данных, на примере с породами собак я показал, что это можно делать и в процессе обучения.

568
01:48:42,170 --> 01:48:46,330
Второй — использовать лучшую архитектуру нейронной сети.

569
01:48:46,880 --> 01:48:52,390
В этой части курса мы ещё будем обсуждать архитектуры.

570
01:48:53,300 --> 01:49:11,030
В разных архитектурах могут быть разные размеры свёрточных фильтров, способы их комбинации, количество фильтров, слоёв и так далее.

571
01:49:14,750 --> 01:49:26,350
Мы использовали архитектуру ResNet34, с неё можно начать знакомство с нейронными сетями и на ней же и остановиться —

572
01:49:26,350 --> 01:49:30,309
в ней не очень много параметров, она хорошо работает на маленьких датасетах, удобная вещь.

573
01:49:31,610 --> 01:49:41,289
Есть архитектура ResNeXt, на прошлогоднем соревновании ImageNet её использовали обладатели второго места.

574
01:49:41,930 --> 01:49:49,299
Число после названия ResNet или ResNeXt означает количество слоёв нейронной сети.

575
01:49:49,670 --> 01:50:05,710
После ResNet34 я обычно использую ResNeXt50. ResNeXt50 обучается в 2 раза дольше и требует в 2-4 раза больше памяти, чем ResNet34.

576
01:50:06,590 --> 01:50:19,120
Итак, два способа — увеличить размер изображения до 299 и поменять архитектуру на ResNeXt50.

577
01:50:19,120 --> 01:50:24,219
Мне пришлось уменьшить размер минибатча до 28, чтобы хватило памяти.

578
01:50:24,219 --> 01:50:31,149
У меня 11 ГБ оперативной памяти, AWS или Crestle предоставят вам где-то 12.

579
01:50:31,429 --> 01:50:42,009
Итак, я скопировал ноутбук и перезапустил его с изменёнными параметрами.

580
01:50:42,770 --> 01:51:00,320
Я удалил ячейки с пояснениями, не подбирал заново скорость обучения.

581
01:51:00,320 --> 01:51:13,779
Шаги те же — дополнение данных, precompute=True, обучение, precompute=False, обучение, разморозка, дифференциальные скорости обучения, обучение.

582
01:51:13,780 --> 01:51:28,779
Я не стал ставить cycle_mult=2, потому что архитектура сложнее и легче переобучается.

583
01:51:28,780 --> 01:51:38,049
Я пробовал увеличивать длину цикла, но после этого потери на обучающей выборке становились меньше, чем на валидационной.

584
01:51:39,440 --> 01:51:47,144
Используя эти шаги и TTA, я получил долю правильных ответов в 99.75%.

585
01:51:47,244 --> 01:51:56,569
Это значит, что моя модель неправильно распознала одну собаку и четырёх кошек, давайте на них посмотрим.

586
01:51:58,280 --> 01:52:04,690
Из четырёх изображений с кошками на одном есть и собака, и кошка, два изображения плохие, одно ошибочное,

587
01:52:05,750 --> 01:52:11,179
а на изображении с собакой видно только зубы.

588
01:52:11,179 --> 01:52:22,914
Классификатор получился настолько хорошим, что ошибся, можно сказать, всего один раз.

589
01:52:23,514 --> 01:52:31,359
Вот что люди имеют в виду, говоря фразы вроде «сверхчеловеческий интеллект».

590
01:52:31,880 --> 01:52:37,719
Классификатор пород собак, который я сделал сегодня утром, различает породы лучше, чем я когда-нибудь научусь.

591
01:52:39,860 --> 01:52:52,390
Такие результаты можно получить с архитектурами типа ResNeXt. На обучение этой модели ушло около 20 минут.

592
01:53:01,100 --> 01:53:03,100


593
01:53:03,140 --> 01:53:05,140


594
01:53:05,450 --> 01:53:10,599


595
01:53:10,600 --> 01:53:14,140


596
01:53:16,190 --> 01:53:21,760


597
01:53:24,980 --> 01:53:26,980


598
01:53:27,440 --> 01:53:31,690


599
01:53:31,730 --> 01:53:36,160


600
01:53:36,500 --> 01:53:39,850


601
01:53:40,850 --> 01:53:45,399


602
01:53:46,010 --> 01:53:52,780


603
01:53:53,840 --> 01:53:59,559


604
01:53:59,690 --> 01:54:01,690


605
01:54:02,390 --> 01:54:04,629


606
01:54:04,630 --> 01:54:09,460


607
01:54:10,490 --> 01:54:12,999


608
01:54:13,760 --> 01:54:16,419


609
01:54:16,420 --> 01:54:23,710


610
01:54:23,710 --> 01:54:29,530


611
01:54:30,140 --> 01:54:31,700


612
01:54:32,720 --> 01:54:34,300


613
01:54:34,300 --> 01:54:37,300


614
01:54:37,340 --> 01:54:39,909


615
01:54:40,400 --> 01:54:41,960


616
01:54:41,960 --> 01:54:44,859


617
01:54:44,950 --> 01:54:49,090


618
01:54:50,660 --> 01:54:57,609


619
01:54:59,000 --> 01:55:01,000


620
01:55:01,670 --> 01:55:08,770


621
01:55:09,800 --> 01:55:17,350


622
01:55:18,020 --> 01:55:23,919


623
01:55:24,140 --> 01:55:29,409


624
01:55:30,020 --> 01:55:35,859


625
01:55:35,860 --> 01:55:42,100


626
01:55:42,800 --> 01:55:44,800


627
01:55:45,830 --> 01:55:47,300


628
01:55:47,300 --> 01:55:52,029


629
01:55:52,100 --> 01:55:59,379


630
01:55:59,380 --> 01:56:03,219


631
01:56:03,860 --> 01:56:09,250


632
01:56:09,250 --> 01:56:13,750


633
01:56:14,510 --> 01:56:17,199


634
01:56:25,460 --> 01:56:26,810


635
01:56:26,810 --> 01:56:33,370


636
01:56:34,159 --> 01:56:36,159


637
01:56:36,469 --> 01:56:43,719


638
01:56:43,719 --> 01:56:49,448


639
01:56:49,449 --> 01:56:56,979


640
01:56:56,980 --> 01:56:58,489


641
01:56:58,489 --> 01:57:00,489


642
01:57:00,679 --> 01:57:02,679


643
01:57:02,840 --> 01:57:08,620


644
01:57:08,989 --> 01:57:11,859


645
01:57:12,560 --> 01:57:14,560


646
01:57:14,720 --> 01:57:19,059


647
01:57:19,970 --> 01:57:22,659


648
01:57:23,450 --> 01:57:28,539


649
01:57:29,660 --> 01:57:31,839


650
01:57:32,870 --> 01:57:38,260


651
01:57:38,450 --> 01:57:42,789


652
01:57:44,870 --> 01:57:49,300


653
01:57:49,940 --> 01:57:51,940


654
01:57:52,100 --> 01:57:57,249


655
01:57:57,830 --> 01:58:03,010


656
01:58:03,740 --> 01:58:10,269


657
01:58:11,090 --> 01:58:13,090


658
01:58:13,550 --> 01:58:16,059


659
01:58:16,820 --> 01:58:18,820


660
01:58:19,160 --> 01:58:21,160


661
01:58:21,200 --> 01:58:27,729


662
01:58:29,450 --> 01:58:31,420


663
01:58:31,420 --> 01:58:36,220


664
01:58:36,290 --> 01:58:40,330


665
01:58:41,000 --> 01:58:43,000


666
01:58:43,340 --> 01:58:50,440


667
01:58:50,990 --> 01:58:53,109


668
01:58:53,180 --> 01:58:59,349


669
01:58:59,350 --> 01:59:02,289


670
01:59:02,290 --> 01:59:05,620


671
01:59:06,170 --> 01:59:08,530


672
01:59:09,140 --> 01:59:11,800


673
01:59:13,190 --> 01:59:16,000


674
01:59:16,640 --> 01:59:22,660


675
01:59:23,190 --> 01:59:25,460


676
01:59:26,010 --> 01:59:31,250


677
01:59:32,099 --> 01:59:38,119


678
01:59:38,429 --> 01:59:42,379


679
01:59:43,080 --> 01:59:48,679


680
01:59:48,840 --> 01:59:54,500


681
01:59:55,139 --> 02:00:00,919


682
02:00:01,440 --> 02:00:03,679


683
02:00:04,590 --> 02:00:11,630


684
02:00:12,690 --> 02:00:17,149


685
02:00:18,030 --> 02:00:22,580


686
02:00:23,520 --> 02:00:24,570


687
02:00:27,510 --> 02:00:33,260


688
02:00:33,530 --> 02:00:36,349


689
02:00:37,170 --> 02:00:39,170


690
02:00:40,199 --> 02:00:42,199


691
02:00:43,530 --> 02:00:50,239


692
02:00:50,310 --> 02:00:52,310


693
02:00:52,710 --> 02:00:57,409


694
02:00:59,040 --> 02:01:00,869


695
02:01:00,869 --> 02:01:02,869


696
02:01:03,780 --> 02:01:07,070


697
02:01:08,730 --> 02:01:10,730


698
02:01:11,010 --> 02:01:16,010


699
02:01:16,010 --> 02:01:18,010


700
02:01:18,540 --> 02:01:24,560


701
02:01:24,599 --> 02:01:29,839


702
02:01:30,610 --> 02:01:34,239


703
02:01:34,940 --> 02:01:36,940


704
02:01:37,010 --> 02:01:38,750


705
02:01:38,750 --> 02:01:43,659


706
02:01:45,500 --> 02:01:47,500


707
02:01:48,650 --> 02:01:56,409


708
02:01:57,800 --> 02:02:02,560


709
02:02:05,480 --> 02:02:07,689


710
02:02:08,960 --> 02:02:13,659


711
02:02:13,660 --> 02:02:19,180


712
02:02:19,340 --> 02:02:22,060


713
02:02:23,780 --> 02:02:27,639


714
02:02:31,010 --> 02:02:34,119


715
02:02:36,020 --> 02:02:37,430


716
02:02:37,430 --> 02:02:39,230


717
02:02:41,510 --> 02:02:44,739


718
02:02:45,410 --> 02:02:47,410


719
02:02:49,490 --> 02:02:53,920


720
02:02:54,890 --> 02:02:58,900


721
02:03:00,020 --> 02:03:01,610


722
02:03:05,180 --> 02:03:07,180


723
02:03:08,520 --> 02:03:10,520


724
02:03:10,990 --> 02:03:14,879


725
02:03:16,000 --> 02:03:18,299


726
02:03:18,970 --> 02:03:21,119


727
02:03:21,190 --> 02:03:26,609


728
02:03:26,710 --> 02:03:29,640


729
02:03:30,460 --> 02:03:32,460


730
02:03:33,190 --> 02:03:38,790


731
02:03:38,790 --> 02:03:45,990


732
02:03:46,180 --> 02:03:48,180


733
02:03:48,430 --> 02:03:52,439


734
02:03:52,750 --> 02:03:55,109


735
02:03:55,720 --> 02:04:02,970


736
02:04:02,970 --> 02:04:04,970


737
02:04:05,680 --> 02:04:10,019


738
02:04:11,410 --> 02:04:16,260


739
02:04:18,190 --> 02:04:20,879


740
02:04:22,510 --> 02:04:24,510


741
02:04:25,270 --> 02:04:28,950


742
02:04:33,840 --> 02:04:34,600


743
02:04:34,600 --> 02:04:39,419


744
02:04:39,820 --> 02:04:45,600


745
02:04:47,080 --> 02:04:50,039


746
02:04:50,040 --> 02:04:55,379


747
02:04:56,680 --> 02:04:58,680


748
02:04:58,990 --> 02:05:03,059


749
02:05:04,060 --> 02:05:05,610


750
02:05:11,440 --> 02:05:17,069


751
02:05:17,260 --> 02:05:22,990


752
02:05:25,970 --> 02:05:30,820


753
02:05:31,460 --> 02:05:37,390


754
02:05:37,540 --> 02:05:39,540


755
02:05:39,950 --> 02:05:45,249


756
02:05:45,440 --> 02:05:49,150


757
02:05:49,150 --> 02:05:54,400


758
02:05:55,100 --> 02:05:58,990


759
02:05:59,180 --> 02:06:01,930


760
02:06:02,570 --> 02:06:04,570


761
02:06:05,600 --> 02:06:07,600


762
02:06:11,330 --> 02:06:18,400


763
02:06:19,100 --> 02:06:25,059


764
02:06:25,870 --> 02:06:31,570


765
02:06:32,630 --> 02:06:38,199


766
02:06:38,900 --> 02:06:40,100


767
02:06:40,100 --> 02:06:42,100


768
02:06:42,530 --> 02:06:44,530


769
02:06:44,960 --> 02:06:46,460


770
02:06:46,460 --> 02:06:47,870


771
02:06:47,870 --> 02:06:49,870


772
02:06:51,110 --> 02:06:53,650


773
02:06:53,810 --> 02:06:59,110


774
02:07:00,560 --> 02:07:01,670


775
02:07:01,670 --> 02:07:08,170


776
02:07:08,170 --> 02:07:10,170


777
02:07:11,749 --> 02:07:14,858


778
02:07:16,159 --> 02:07:18,159


779
02:07:18,800 --> 02:07:22,869


780
02:07:23,629 --> 02:07:27,309


