1
00:00:00,030 --> 00:00:05,784
Добро пожаловать на пятую лекцию.

2
00:00:05,884 --> 00:00:27,834
Один из студентов магистратуры нашего университета написал пост про анализ структурированных данных по нашему курсу.

3
00:00:27,934 --> 00:00:37,824
Пост оказался очень популярным, как я и ожидал. Его опубликовали на сайте towardsdatascience.com,

4
00:00:37,924 --> 00:00:46,840
это неплохой ресурс для тех, кто интересуется новостями анализа данных.

5
00:00:46,940 --> 00:00:58,195
Автор поста — Kerem Turgutlu. Его пост рассказывает об основных идеях с последней лекции.

6
00:00:58,295 --> 00:01:05,452
Sebastian Ruder, которого я уже упоминал на прошлой неделе как одного из моих любимых исследователей,

7
00:01:05,552 --> 00:01:16,590
поделился ссылкой на этот пост, а кто-то из Stitch Fix ответил, что они давно таким занимаются.

8
00:01:16,590 --> 00:01:23,125
Я знаю, что в индустрии многие занимаются анализом структурированных данных, но про это никто не пишет.

9
00:01:23,225 --> 00:01:31,509
Тут Kerem публикует пост, и Stitch Fix сразу отвечает — «ну, ничего нового».

10
00:01:31,609 --> 00:01:46,310
Я был рад этому посту, и думаю, что на эту тему можно ещё много написать — например, про работу с различными датасетами,

11
00:01:46,410 --> 00:01:57,429
или анализ старых соревнований Kaggle, которые можно или нельзя было бы выиграть с современными инструментами.

12
00:01:57,529 --> 00:02:13,970
Было бы интересно почитать про различные характеристики дропаута, я не видел про это статей.

13
00:02:13,970 --> 00:02:21,950
Я думаю, тут большой потенциал для развития. Кто-то в Twitter ответил на пост фразой «Я столько лет искал эту информацию!».

14
00:02:25,310 --> 00:02:36,940
Nikhil B, чьи классификаторы игроков в бейсбол или крикет и изображения купюр я упоминал после первой лекции,

15
00:02:36,940 --> 00:02:54,545
скачал из Google пару сотен фотографий актёров в очках и без очков, разметил их вручную и обучил классификатор.

16
00:02:54,645 --> 00:03:06,724
Архитектура ResNet работала плохо, поэтому он экспериментировал с разморозкой слоёв

17
00:03:06,824 --> 00:03:11,440
и дифференциальными скоростями обучения, и достиг доли правильных ответов в 100%.

18
00:03:11,709 --> 00:03:22,590
Мне нравится, что он выбрал реальную задачу — изображения из Google, а не размеченный датасет с Kaggle.

19
00:03:22,690 --> 00:03:30,930
В его посте есть ссылка на удобный инструмент для скачивания изображений из Google.

20
00:03:31,030 --> 00:03:41,379
Сегодня я выступал в Университете Сингулярности перед топ-менеджерами одной из крупнейших телекоммуникационных компаний.

21
00:03:41,479 --> 00:03:56,220
Их поставщики убеждали их собирать миллионы изображений, покупать высокие вычислительные мощности и специальные программы.

22
00:03:56,320 --> 00:04:03,960
Я показал им этот пост и сказал — «Вот чего достиг человек после трёх недель обучения на машине за 60 центов в час».

23
00:04:04,060 --> 00:04:13,140
Они были очень рады, узнав, что такое доступно обычным людям.

24
00:04:13,240 --> 00:04:20,030
Я предполагаю, что Nikhil — обычный человек, прошу прощения, если ненароком его обидел.

25
00:04:20,029 --> 00:04:31,650
Я посмотрел на его классификатор игроков в крикет. Этот код совпадает с кодом с первой лекции за исключением количества эпох.

26
00:04:31,750 --> 00:04:42,852
Я надеялся, что так случится. Это доказывает, что эти четыре строки — полезный инструмент.

27
00:04:42,952 --> 00:04:50,894
Показывайте эти результаты топ-менеджерам своих компаний.

28
00:04:50,994 --> 00:05:04,820
Они будут сомневаться и говорить вам — «Если так можно, почему нам никто до сих пор этого не сказал?»,

29
00:05:04,820 --> 00:05:15,885
поэтому вам придётся продемонстрировать это на собственных примерах, например, данных вашей компании.

30
00:05:15,985 --> 00:05:28,700
Vitaly Bushaev написал введение в обучение нейронных сетей.

31
00:05:28,700 --> 00:05:40,340
У него хороший слог и умение объяснять сложные вещи простым языком, берите с него пример.

32
00:05:43,280 --> 00:05:52,220
Автор начинает с азов, но читатель понимает, что его не принимают за дурака —

33
00:05:52,220 --> 00:06:03,610
за каждым уравнением следует подробное объяснение того, что всё это значит.

34
00:06:03,710 --> 00:06:11,450
Автору удаётся сочетать уважение к читателям и отсутствие у них изначальных знаний в данной области.

35
00:06:11,450 --> 00:06:21,480
На этой неделе я запостил скриншот рейтинга соревнования Plant Seedlings Classification на Kaggle, где занимал первое место.

36
00:06:21,580 --> 00:06:31,025
Это было ошибкой, потому что к текущему моменту уже пятеро студентов нашего курса обогнали меня в этом рейтинге.

37
00:06:31,125 --> 00:06:41,870
Это текущий рейтинг соревнования, первые пять результатов — студенты курса fast.ai, шестой — преподаватель курса.

38
00:06:41,970 --> 00:07:06,212
Датасет состоит из нескольких тысяч изображений, размер большинства которых меньше 100x100.

39
00:07:06,312 --> 00:07:16,115
Для своего результата я просто последовательно выполнил ячейки Jupyter ноутбука, это заняло где-то час.

40
00:07:16,215 --> 00:07:23,170
Я думаю, эти студенты в рейтинге сделали немного больше, но не сильно.

41
00:07:23,170 --> 00:07:48,520
Как видно, стандартные средства библиотеки fastai дают хорошие результаты без особых усилий.

42
00:07:48,520 --> 00:07:55,510
Сегодня мы перейдём ко второй половине первой части курса.

43
00:07:55,510 --> 00:08:09,067
В первой половине мы разбирались пробежались по основным темам, поняли, как создавать соответствующие модели,

44
00:08:09,167 --> 00:08:13,590
и получили примерное представление о том, как они работают.

45
00:08:17,830 --> 00:08:27,245
Сейчас мы пройдёмся по этим темам снова, но уже углублённо, разбираясь во всех деталях

46
00:08:27,345 --> 00:08:35,590
и читая исходный код библиотеки fastai для того, чтобы повторить все шаги.

47
00:08:35,590 --> 00:08:45,370
К текущему моменту я показал вам лучшие из известных мне подходов, мы пока отойдём от этого.

48
00:08:45,370 --> 00:08:52,085
Я думаю, что перед тем, как изучать новые техники во второй части курса, важно понять,

49
00:08:52,185 --> 00:08:58,780
как работает код для всего, что мы уже умеем.

50
00:08:58,780 --> 00:09:12,625
Сегодня мы почти с нуля создадим весьма успешную модель коллаборативной фильтрации.

51
00:09:12,725 --> 00:09:19,330
Мы используем PyTorch для дифференцирования и библиотеку для работы с GPU, всё остальное напишем сами.

52
00:09:19,330 --> 00:09:24,977
Мы не будем использовать средства PyTorch для работы с нейронными сетями и постараемся не злоупотреблять средствами fastai.

53
00:09:25,077 --> 00:09:35,800
Мы не успели подробно разобрать коллаборативную фильтрацию на прошлой лекции, давайте к этому вернёмся.

54
00:09:35,800 --> 00:09:45,155
Мы будем работать с датасетом Movielens, это список оценок фильмов.

55
00:09:45,255 --> 00:09:58,900
Пользователи представлены индексом userId, фильмы — индексом movieId, оценки и даты их выставления записаны в столбцах rating и timestamp.

56
00:09:58,900 --> 00:10:12,650
Я никогда не использовал признак Timestamp, мы будем использовать признаки userId, movieId и rating.

57
00:10:12,750 --> 00:10:28,410
В терминах структурированных данных признаки userId и movieId — категориальные, а оценка — целевая переменная.

58
00:10:28,410 --> 00:10:35,330
У нас есть таблица названий фильмов, мы не будем использовать их для обучения модели, только для демонстрации её работы.

59
00:10:35,430 --> 00:10:46,089
Здесь также указаны жанры фильмов, я не использую их, кто-нибудь на этой неделе может проверить, прав ли я в этом.

60
00:10:46,089 --> 00:10:55,180
Для того, чтобы посмотреть на датасет, я выбрал пользователей, которые посмотрели больше всего фильмов,

61
00:10:57,880 --> 00:11:03,820
взял самые популярные фильмы и составил перекрёстную таблицу методом pandas.crosstab().

62
00:11:03,820 --> 00:11:12,680
Это подмножество датасета. Строки соответствуют пользователям, столбцы — фильмам, соответствующие оценки — в пересечениях.

63
00:11:12,780 --> 00:11:18,557
Некоторые пользователи не смотрели определённые фильмы, поэтому в таблице есть значения NaN.

64
00:11:18,657 --> 00:11:37,955
Я скопировал эту таблицу в Excel, демонстрация называется collab_filter.xlsx.

65
00:11:38,055 --> 00:12:09,790
Если вы чего-то не понимаете, задавайте вопросы здесь или на форуме. Янет следит за вопросами на форуме.

66
00:12:09,790 --> 00:12:19,803
Сейчас мы переходим к деталям работы, поэтому очень важно, чтобы все всё понимали.

67
00:12:19,903 --> 00:12:47,420
Мы не будем обучать нейронную сеть, а займёмся сначала факторизацией матриц, потому что это простейший способ решить нашу задачу.

68
00:12:47,520 --> 00:12:57,800
Эта матрица предсказаний, построенная по такому же принципу, как и скопированная из Jupyter ноутбука.

69
00:12:57,900 --> 00:13:18,645
Это истинные значения, это предсказания, это — среднеквадратичная ошибка (RMSE) между этими двумя таблицами.

70
00:13:18,745 --> 00:13:25,005
Таблица предсказаний состоит из случайных чисел, ошибка составляет 2.81.

71
00:13:25,105 --> 00:13:41,560
Сейчас я покажу, как мы предсказываем, что пользователь номер 14 оценит фильм номер 27 как 0.91. Пока оценка случайная.

72
00:13:41,560 --> 00:14:05,990
Оценка получается скалярным произведением выделенных векторов.

73
00:14:05,990 --> 00:14:22,509
Красный вектор — матрица размера 1x5, фиолетовый — матрица размера 5x1. Перемножая эти матрицы, получаем предсказание.

74
00:14:22,609 --> 00:14:33,050
Если для какой-то оценки нет истинного значения, она будет равна нулю, чтобы корректно считать функцию потерь.

75
00:14:34,220 --> 00:14:46,149
Наша модель — не нейронная сеть, а просто перемножение двух матриц.

76
00:14:46,249 --> 00:15:04,430
Таблица предсказаний 15x15 получена перемножением левой матрицы 15x5 на верхнюю матрицу 5x15.

77
00:15:04,430 --> 00:15:28,165
Сейчас числа в этих матрицах, то есть начальные веса модели, случайные, а модель — это перемножение этих матриц.

78
00:15:28,265 --> 00:15:43,135
Excel умеет выполнять градиентный спуск, его нужно включить в настройках, и станет доступен Решатель.

79
00:15:43,235 --> 00:16:07,525
В Решатель передаются ячейка с целевой функцией (RMSE) и ячейки с оптимизируемыми значениями (две матрицы).

80
00:16:07,625 --> 00:16:20,110
Решатель меняет числа в матрицах и с помощью градиентного спуска находит значения, минимизирующие целевую функцию.

81
00:16:20,520 --> 00:16:33,985
После запуска Решателя значение целевой функции начинает уменьшаться.

82
00:16:34,085 --> 00:16:43,840
Умножение матриц и градиентный спуск наводят на мысли о нейронных сетях,

83
00:16:43,940 --> 00:16:51,630
но здесь нет нелинейного слоя и второго слоя, поэтому это не глубокое обучение.

84
00:16:51,630 --> 00:17:00,150
Модели, использующие произведения матриц без нелинейных слоёв, называют моделями неглубокого обучения.

85
00:17:01,830 --> 00:17:17,189
Мне надоело ждать, поэтому я остановлю Решатель. Среднеквадратичная ошибка упала с 2.81 до 0.39.

86
00:17:17,189 --> 00:17:36,650
Модель предсказывает, что пользователь 72 поставил фильму 27 оценку 4.4. Истинное значение — 4, как видите, модель работает.

87
00:17:36,650 --> 00:18:11,190
Необходимо предсказать 225 значений, используя 150 параметров, поэтому это не простой подгон, а машинное обучение.

88
00:18:11,190 --> 00:18:23,725
В линейной алгебре такой процесс называется разложением матрицы, это можно было сделать аналитически,

89
00:18:23,825 --> 00:18:29,430
а мы делаем это с помощью градиентного спуска. Градиентный спуск — мощный инструмент.

90
00:18:29,430 --> 00:18:36,960
Я предпочитаю рассматривать это с интуитивной точки зрения, а не с точки зрения линейной алгебры.

91
00:18:36,960 --> 00:18:56,225
Предположим, что фильм номер 27 — это Властелин Колец: Братство Кольца, и мы хотим узнать, понравится ли он пользователю 72.

92
00:18:56,325 --> 00:19:11,250
Фильму соответствует пять чисел. Допустим, первое число говорит, насколько фильм фантастический,

93
00:19:11,250 --> 00:19:21,390
второе — настолько давно он вышел и какие там спецэффекты, пятое — сколько в фильме диалогов.

94
00:19:21,390 --> 00:19:27,820
Пять чисел соответствуют пяти признакам фильма.

95
00:19:27,920 --> 00:19:45,265
В таком случае для каждого пользователя можно сказать, насколько он любит фэнтези, спецэффекты и диалоги в фильмах.

96
00:19:45,365 --> 00:19:54,310
Сумма поэлементных произведений чисел пользователя на числа фильма отразит то, понравится ему этот фильм или нет.

97
00:19:54,410 --> 00:20:13,060
У нас нет этой информации о фильмах и пользователях, мы выбираем этот подход, и градиентный спуск подбирает эти числа.

98
00:20:13,160 --> 00:20:36,030
Эти числа называются скрытые факторы. Они скрытые, потому что мы не выделяли и не называли эти неявные признаки,

99
00:20:36,030 --> 00:20:46,740
а просто предположили, что факторы их отражают. Мы предположили, что оценка фильма может быть получена

100
00:20:46,740 --> 00:20:53,605
перемножением значений каких-то признаков фильма и соответствующих предпочтений пользователя,

101
00:20:53,705 --> 00:21:06,175
и использовали градиентный спуск, чтобы найти значения этих неизвестных признаков.

102
00:21:06,275 --> 00:21:14,889
В этом суть вероятностной факторизации матриц, так работает коллаборативная фильтрация с её применением.

103
00:21:14,989 --> 00:21:26,490
Всё, что мы сделали — инициализировали две случайные матрицы и перемножили их.

104
00:21:26,490 --> 00:21:38,250
Вопрос из зала: Может, надо было отнормировать значения к шкале от 0 до 5?

105
00:21:38,250 --> 00:21:46,380
Да, мы сделаем это и ещё много чего. Это — простейшая версия.

106
00:21:46,380 --> 00:21:50,850
Мы напишем этот алгоритм на Python и запустим на всём датасете.

107
00:21:54,750 --> 00:22:03,050
Вопрос из зала: Как определить размеры матриц?

108
00:22:03,150 --> 00:22:43,220
Эти матрицы — это матрицы эмбеддинга, 5 — её ширина. Для фильма 72 мы бы взяли строку номер 72 и получили эти пять чисел.

109
00:22:43,220 --> 00:22:53,780
Вопрос в том, как выбрать ширину матрицы эмбеддинга, и ответ — непонятно, надо пробовать.

110
00:22:53,780 --> 00:23:10,410
Число должно быть достаточно большим, чтобы учесть сложные закономерности, но не слишком большим,

111
00:23:10,510 --> 00:23:17,460
иначе параметров будет слишком много и модель будет очень долго обучаться и может переобучиться.

112
00:23:17,560 --> 00:23:26,865
Вопрос из зала: Что значат негативные факторы в матрицах эмбеддинга?

113
00:23:26,965 --> 00:23:34,610
В матрице для фильмов — например, то, что диалогов в фильме мало и они плохие.

114
00:23:34,610 --> 00:23:41,540
В матрице для пользователей — например, то, что пользователь терпеть не может спецэффекты в фильмах.

115
00:23:41,540 --> 00:23:49,645
Вопрос из зала: То есть факторы могут быть любые? Никаких ограничений?

116
00:23:49,745 --> 00:23:54,447
Да, любые, это просто матрицы эмбеддинга.

117
00:23:54,547 --> 00:24:19,340
Вопрос из зала: Почему мы доверяем этим матрицам эмбеддинга?

118
00:24:21,410 --> 00:24:33,380
Мы используем градиентный спуск для подбора факторов. Найдя хороший минимум, мы перестаём в них сомневаться,

119
00:24:33,380 --> 00:24:42,720
так как другие числа будут хуже. Конечно, нужно смотреть на результаты на валидационной выборке, мы будем это делать.

120
00:24:42,820 --> 00:24:50,240
Вопрос из зала: Нужно ли обучать модель заново при появлении нового пользователя или нового фильма?

121
00:24:50,240 --> 00:24:56,365
Очень хороший вопрос, на него нет короткого и быстрого ответа.

122
00:24:56,465 --> 00:25:11,000
Нужна будет немного другая модель, и со временем её придётся дообучать.

123
00:25:11,000 --> 00:25:28,110
Раньше Netflix после регистрации просил указать фильмы, которые вам понравились, и дообучал модель на этих данных.

124
00:25:28,210 --> 00:25:38,895
Вопрос из зала: Можно ли для этого просто найти максимально похожие фильмы?

125
00:25:38,995 --> 00:25:50,685
Да, но для этого нужно построить модель с признаками фильмов — жанр, год выпуска, актёры на главных ролях.

126
00:25:50,785 --> 00:26:05,235
У нас признаки не выделены, поэтому нужно использовать коллаборативную фильтрацию.

127
00:26:07,635 --> 00:26:17,010
Многие части кода вам уже знакомы. Мы начнём использовать PyTorch и fastai,

128
00:26:17,110 --> 00:26:26,610
а потом углубимся в детали их работы и несколько раз поменяем.

129
00:26:26,710 --> 00:26:39,860
Мы создаём валидационную выборку знакомой функцией get_ct_idxs().

130
00:26:39,860 --> 00:26:47,050
Параметр wd=2e-4 — это ограничение весов, ещё обсудим. Для тех, кто проходил курс «Машинное обучение» — это L2-регуляризация.

131
00:26:47,050 --> 00:26:53,742
Параметр n_factors — ширина таблицы эмбеддинга.

132
00:26:53,842 --> 00:27:06,375
Объект данных модели создаётся методом CollabFilterDataset.from_csv(), в него передаётся таблица с оценками.

133
00:27:06,475 --> 00:27:28,425
После этого нужно передать признак userId для строк, признак movieId для столбцов и целевую переменную ratings.

134
00:27:28,525 --> 00:27:33,390
Все рекомендательные системы на основе коллаборативной фильтрации построены так —

135
00:27:33,490 --> 00:27:40,660
есть набор пользователей и набор товаров, эти наборы связаны.

136
00:27:40,660 --> 00:27:53,530
В соревновании по предсказанию продаж вместо пользователей — магазины, а товары — то, что они продадут.

137
00:27:53,530 --> 00:28:09,045
Принцип один — по паре категориальных признаков высокой мощности через произведение матриц вычисляется оценка или вероятностью.

138
00:28:09,145 --> 00:28:26,800
Можно думать про это по-другому: когда мы предсказываем, понравится ли пользователю 72 фильм 27, мы смотрим,

139
00:28:26,900 --> 00:28:43,635
каким пользователям нравятся те же фильмы, что и пользователю 72, и какие фильмы нравятся пользователям, похожим на пользователя 72.

140
00:28:43,735 --> 00:28:56,475
Это две формулировки одного вопроса. Коллаборативная фильтрация рассматривает пары «пользователь — фильм»

141
00:28:56,575 --> 00:29:11,670
и ищет фильмы, которые смотрели похожие люди, и людей, которые смотрели похожие фильмы.

142
00:29:11,770 --> 00:29:21,240
Если ваш датасет построен таким образом, при работе с ним можно использовать коллаборативную фильтрацию.

143
00:29:21,340 --> 00:29:28,460
Итак, есть два признака и целевая переменная.

144
00:29:28,460 --> 00:29:34,310
Как обычно, мы получаем алгоритм обучения из объекта данных модели методом .get_learner().

145
00:29:34,310 --> 00:29:48,285
Метод принимает ширину матрицы эмбеддинга n_factors, валидационную выборку val_idxs, размер минибатча 64 и алгоритм оптимизации opt_fn.

146
00:29:48,385 --> 00:29:52,842
Мы ещё обсудим алгоритмы оптимизации, здесь используется Adam.

147
00:29:52,942 --> 00:30:03,210
После создания алгоритма обучения мы обучаем модель, всё как обычно.

148
00:30:03,310 --> 00:30:10,905
Такие модели обучаются быстро, здесь всего три эпохи.

149
00:30:11,005 --> 00:30:15,480
Можно использовать алгоритм поиска скорости обучения и всё остальное, к чему вы уже привыкли.

150
00:30:15,580 --> 00:30:24,590
Обучение модели заняло пару секунд, не было никаких предобученных моделей, всё с нуля.

151
00:30:24,690 --> 00:30:34,335
Для получения среднеквадратичной ошибки (RMSE) нужно взять корень из функции потерь в последнем столбце.

152
00:30:34,435 --> 00:30:58,880
Корень из 0.776 равен примерно 0.88, лучший бенчмарк на этом датасете — 0.91, мы побили его за две секунды.

153
00:30:58,880 --> 00:31:11,800
Так можно написать модель коллаборативной фильтрации с использованием fastai, не задумываясь о деталях.

154
00:31:11,900 --> 00:31:23,470
Сейчас мы построим эту модель с нуля и достигнем значения метрики 0.77-0.78.

155
00:31:23,570 --> 00:31:32,935
Если вы хотите повторить этот результат без углубления в детали, этих трёх строк кода достаточно.

156
00:31:33,035 --> 00:31:38,095
Предсказания получаются методом .predict(), можно визуализировать их с помощью библиотеки seaborn.

157
00:31:38,195 --> 00:31:48,960
Библиотека seaborn построена на основе библиотеки matplotlib, поэтому знание matplotlib пригодится при её освоении.

158
00:31:48,960 --> 00:31:54,230
В seaborn есть несколько удобных видов графиков. Например, метод seaborn.jointplot()

159
00:31:54,230 --> 00:32:00,120
строит распределение предсказаний (горизонтальная ось) и истинных значений (вертикальная ось).

160
00:32:02,340 --> 00:32:07,192
Видно, что модель отражает общую картину данных — высокие оценки предсказываются высокими числами.

161
00:32:07,292 --> 00:32:18,420
Сверху — гистограмма распределения предсказаний, справа — истинных значений, наглядная иллюстрация.

162
00:32:18,420 --> 00:32:23,615
Вопрос из зала: Что значит параметр n_factors и почему он равен 50?

163
00:32:23,915 --> 00:32:29,352
Он равен 50, потому что это значение здесь работает лучше всего, это ширина матрицы эмбеддинга.

164
00:32:29,452 --> 00:32:39,860
В демонстрации Excel этот параметр равен 5, а у нас 50.

165
00:32:41,750 --> 00:32:54,715
Янет: Что меняется, если оценка — не действительное число, а либо 0, либо 1?

166
00:32:54,815 --> 00:33:02,575
Тогда нужно строить классификатор, а не регрессию.

167
00:33:02,675 --> 00:33:11,650
Янет: Что для этого нужно изменить?

168
00:33:11,750 --> 00:33:15,385
Не уверен, что мы доберёмся до этого в этом курсе.

169
00:33:15,485 --> 00:33:21,600
Задача классификации с использованием коллаборативной фильтрации ещё не воплощена в fastai,

170
00:33:21,600 --> 00:33:26,315
может, кто-то из студентов захочет это добавить, это несложно.

171
00:33:26,415 --> 00:33:44,850
Нужно поменять функцию активации на сигмоиду и поменять функцию потерь с RMSE на перекрёстную энтропию.

172
00:33:44,850 --> 00:33:50,940
Больше ничего менять не надо, надеюсь, кто-нибудь это напишет, и к следующей неделе у нас уже будут средства.

173
00:33:50,940 --> 00:34:04,800
Произведение векторов — это то же самое, что и произведение матриц.

174
00:34:04,800 --> 00:34:13,209
Два вектора умножаются поэлементно, и результаты складываются.

175
00:34:13,309 --> 00:34:22,110
Давайте напишем это на Python. PyTorch-тензор создаётся конструктором T().

176
00:34:22,110 --> 00:34:34,434
Это функция fastai, в PyTorch тензор создаётся методом torch.from_numpy(). Мы создали два тензора из матриц

177
00:34:34,534 --> 00:34:46,090
a = [[1, 2], [3, 4]] и b = [[2, 2], [10, 10]].

178
00:34:46,190 --> 00:34:52,150
Я не добавил .cuda() при создании переменных, поэтому они лежат в CPU, а не в GPU.

179
00:34:52,250 --> 00:35:19,590
Оператор обычного умножения a*b в PyTorch перемножит два тензора одинакового размера поэлементно.

180
00:35:19,590 --> 00:36:10,285
(a*b).sum(1) просуммирует элементы в каждой строке матрицы a*b, то есть перемножит строки матриц a и b.

181
00:36:10,385 --> 00:36:25,220
Этот результат можно было бы получить с использованием матричного умножения, но мы будем делать так.

182
00:36:28,080 --> 00:36:44,455
Нужно помнить, что данные представлены в виде обычной таблицы, а не перекрёстной, как в демонстрации в Excel.

183
00:36:44,555 --> 00:36:50,962
Для каждого пользователя мы находим строку длиной 50 в матрице эмбеддинга пользователей и умножаем её на

184
00:36:51,062 --> 00:37:02,680
строку для фильма длиной 50 в матрице эмбеддинга фильмов.

185
00:37:02,780 --> 00:37:21,120
Для этого мы создадим свой слой нейронной сети в виде модуля PyTorch.

186
00:37:21,120 --> 00:37:32,710
Модуль PyTorch — специальный объект, который можно использовать в качестве слоя нейронной сети.

187
00:37:32,810 --> 00:37:41,470
Модуль предполагает наличие реализованного скалярного произведения.

188
00:37:41,570 --> 00:37:55,405
Модуль создаётся конструктором model=DotProduct() и после этого используется как функция.

189
00:37:55,505 --> 00:38:08,369
Модуль — не просто функция, можно брать его производную и создавать нейронные сети из многих модулей.

190
00:38:08,369 --> 00:38:14,730
По сути, это удобно определённая функция.

191
00:38:14,730 --> 00:38:23,260
Скалярное произведение DotProduct() задаётся классом Python.

192
00:38:23,360 --> 00:38:31,410
Если вы не писали на Python в объектно-ориентированном стиле, придётся начать, потому что все модули PyTorch устроены таким образом.

193
00:38:33,690 --> 00:38:46,000
Мне нравится в PyTorch то, что там используется стиль написания кода Python, а не изобретается всё заново, как в TensorFlow.

194
00:38:46,100 --> 00:38:55,770
Для реализации нового поведения в Python используются классы.

195
00:38:55,770 --> 00:39:07,020
Янет: Можно ли использовать fastai для решения задачи коллаборативной фильтрации на очень больших данных?

196
00:39:07,020 --> 00:39:33,560
Да, конечно. Данные хранятся в датафрейме, датафрейм хранится в оперативной памяти.

197
00:39:33,560 --> 00:39:40,920
На Amazon легко арендовать машину с 512 ГБ памяти.

198
00:39:40,920 --> 00:39:46,200
Если ваш csv-файл больше 512 ГБ, что впечатляет,

199
00:39:48,510 --> 00:39:52,769


200
00:39:54,210 --> 00:40:00,359


201
00:40:00,359 --> 00:40:03,519


202
00:40:03,619 --> 00:40:15,549
Я ни разу не встречал матриц коллаборативной фильтрации тяжелее 512 ГБ, но даже с таким можно работать.

203
00:40:15,649 --> 00:40:32,640
В PyTorch при создании класса необходимо реализовать метод forward().

204
00:40:32,640 --> 00:40:37,109


205
00:40:37,109 --> 00:40:43,019


206
00:40:43,019 --> 00:40:48,180


207
00:40:48,180 --> 00:40:51,989


208
00:40:51,989 --> 00:40:54,369


209
00:40:54,469 --> 00:41:01,529
Итак, мы создаём класс и реализуем метод forward, выполняющий скалярное произведение.

210
00:41:01,529 --> 00:41:13,979
После реализации класса создаётся модуль, который потом используется для вычисления скалярного произведения.

211
00:41:16,529 --> 00:41:29,811
Так создаётся слой в PyTorch, это проще, чем в других библиотеках, потому что используются встроенные средства Python.

212
00:41:29,911 --> 00:41:34,499
Давайте создадим более сложный модуль с помощью класса EmbeddingDot().

213
00:41:38,039 --> 00:41:49,670
Снова понадобится метод forward. Появятся новые поля u (users) и m (movies) — матрицы эмбеддинга пользователей и фильмов.

214
00:41:49,670 --> 00:42:00,254
Метод forward() использует эти поля, а на вход принимает индексы категориальных и количественных признаков в минибатче cats и cons.

215
00:42:00,354 --> 00:42:07,054
Индексы пользователей и фильмов могут отличаться от натурального ряда —

216
00:42:07,154 --> 00:42:16,864
например, лежать в диапазоне от 1,000,000 до 1,001,000.

217
00:42:16,964 --> 00:42:25,952
В таком случае длина матрицы эмбеддинга была бы 1,001,000, это неразумное использование места.

218
00:42:26,052 --> 00:42:38,210
Поэтому первым делом мы получаем список уникальных индексов пользователей, а потом нумеруем их заново.

219
00:42:38,310 --> 00:43:03,640
Эта строка создания словаря новой нумерации индексов очень полезная, запомните её.

220
00:43:06,729 --> 00:43:18,439
После создания новых индексов мы заменяем ими старые.

221
00:43:18,539 --> 00:43:31,639
Метод .apply() в pandas позволяет применить к датафрейму любую функцию, здесь используется лямбда-функция.

222
00:43:31,739 --> 00:43:36,039
Для фильмов делается то же самое.

223
00:43:36,039 --> 00:43:41,319
После такого преобразования оценки фильмов не изменились, но индексы были заменены на числа натурального ряда,

224
00:43:43,690 --> 00:43:49,239
чтобы эффективно использовать матрицы эмбеддинга.

225
00:43:49,239 --> 00:43:54,819
Переменные n_users и n_movies содержат количество уникальных пользователей и фильмов.

226
00:43:54,819 --> 00:44:00,609
Давайте напишем демонстрацию в Excel на Python.

227
00:44:00,609 --> 00:44:21,760
В самом простом варианте модуля PyTorch не нужно реализовывать конструктор класса, так как нет никаких параметров.

228
00:44:21,760 --> 00:44:37,850
У нас есть параметры — количество пользователей n_users и количество фильмов n_movies, поэтому нужен конструктор.

229
00:44:37,850 --> 00:44:50,550
Конструктор в Python реализуется функцией __init__().

230
00:44:50,650 --> 00:45:01,930
Если вы не писали классы раньше, попрактикуйтесь. Конструктор — это функция, вызывающаяся при создании объекта.

231
00:45:02,030 --> 00:45:16,920
Для наследования от класса nn.Module необходимо указать его в параметрах и вызвать конструктор родительского класса.

232
00:45:17,020 --> 00:45:27,685
Класс EmbeddingDot() наследует класс torch.nn.Module(), поэтому он — полноценный модуль PyTorch.

233
00:45:27,785 --> 00:45:41,870
Для реализации класса мы создаём поля self.u и self.m. Поле self.u — объект класса nn.Embedding(), матрица эмбеддинга.

234
00:45:41,870 --> 00:45:55,280
Матрица эмбеддинга пользователей self.u содержит n_users строк и n_factors столбцов, в демонстрации в Excel n_users=15 и n_factors=5.

235
00:45:55,280 --> 00:46:01,880
То же самое для фильмов.

236
00:46:01,880 --> 00:46:09,910
После создания матрицы эмбеддинга заполняются случайными числами.

237
00:46:12,920 --> 00:46:33,665
Случайные числа должны лежать в разумном диапазоне, чтобы градиентный спуск нормально работал.

238
00:46:33,765 --> 00:46:51,020
Я прикинул, какими должны быть числа, чтобы оценки лежали в диапазоне от 0 до 5, получился диапазон от 0 до 0.05.

239
00:46:51,020 --> 00:47:13,960
Kaiming He разработал алгоритм для определения этого диапазона.

240
00:47:14,060 --> 00:47:34,765
Идея в том, чтобы случайные числа в матрице составляли нормальное распределение со стандартным отклонением,

241
00:47:34,865 --> 00:47:48,950
обратно пропорциональным ширине матрицы эмбеддинга.

242
00:47:48,950 --> 00:48:04,940
У нас ширина матрицы эмбеддинга равна 50, примерно так и выходит.

243
00:48:04,940 --> 00:48:28,430
В PyTorch есть функция для автоматического определения этого числа, но мы всё делаем с нуля, поэтому задаём руками.

244
00:48:28,430 --> 00:48:53,774
Поле weight поля self.u класса EmbeddingDot() содержит матрицу эмбеддинга. Матрица эмбеддинга — объект класса Variable,

245
00:48:53,874 --> 00:49:12,284
это то же самое, что и тензор, но с функцией автоматического дифференцирования. Тензор содержится в поле data.

246
00:49:12,384 --> 00:49:22,484
Итак, тензор матрицы эмбеддинга содержится в поле self.u.weight.data.

247
00:49:22,584 --> 00:49:33,419
Во всех функциях на тензорах в PyTorch можно поставить нижнее подчёркивание «_» после названия,

248
00:49:33,519 --> 00:49:48,344
и функция выполнится на вызываемом объекте. Эта функция заполняет тензор числами, распределёнными равномерно.

249
00:49:48,444 --> 00:50:12,869
Без этой функции строка была бы чуть длиннее.

250
00:50:12,969 --> 00:50:21,449
Итак, у нас есть матрицы эмбеддинга.

251
00:50:21,549 --> 00:50:31,069
В метод forward я передам данные, полученные методом ColumnarModelData.from_data_frame().

252
00:50:31,069 --> 00:50:38,579
Несмотря на то, что у нас нет количественных признаков, формально они передаются.

253
00:50:38,679 --> 00:50:48,329
Столбец пользователей содержится в первом столбце датафрейма с данными, столбец фильмов — во втором.

254
00:50:48,429 --> 00:50:58,264
Мне не хочется создавать новый класс, поэтому я использую эту конструкцию.

255
00:50:58,364 --> 00:51:21,220
Метод forward принимает индексы данных для одного минибатча и достаёт из матриц эмбеддинга соответствующие векторы.

256
00:51:21,320 --> 00:51:31,359
Принцип работы я уже показывал, тут это делается сразу для минибатча, а не для одной пары «пользователь — фильм».

257
00:51:31,459 --> 00:51:43,449
Нам не нужно писать никаких циклов, потому что PyTorch почти все операции выполняет сразу над минибатчами.

258
00:51:43,549 --> 00:51:52,509
Если вы напишете цикл для того, чтобы просматривать минибатч по изображению за раз, это не ускорит работу.

259
00:51:52,609 --> 00:51:59,339
Поэтому из соображений быстроты стоит пользоваться встроенными средствами PyTorch.

260
00:51:59,339 --> 00:52:05,604
Повторюсь, почти всё в PyTorch так и работает, вам не нужно об этом думать.

261
00:52:05,704 --> 00:52:13,239
Итак, мы определили скалярное произведение векторов пользователей и фильмов.

262
00:52:13,339 --> 00:52:27,684
Я задаю признаки — это всё в датасете, кроме оценки фильма и времени, и целевую переменную — то есть оценку фильма.

263
00:52:27,784 --> 00:52:39,546
Из этих данных методом ColumnarModelData.from_data_frame() создаётся объект модели данных data.

264
00:52:39,646 --> 00:52:47,519
Алгоритм обучения model создаётся конструктором EmbeddingDot().

265
00:52:49,549 --> 00:52:55,469
После этого нужно создать алгоритм оптимизации opt.

266
00:52:55,469 --> 00:53:02,640
Единственная строка из fastai — создание объекта data, остальные строки используют только PyTorch.

267
00:53:02,640 --> 00:53:15,630
Во второй части курса я покажу и создание объекта данных с нуля, но это очень скучно, мы не будем делать это сейчас.

268
00:53:17,220 --> 00:53:33,610
Вы можете обсудить это на форуме, но сейчас я буду использовать этот удобный метод.

269
00:53:33,710 --> 00:53:39,130
Создание объекта данных модели — единственное место, где мы будем использовать fastai, в остальных — только PyTorch.

270
00:53:39,230 --> 00:53:51,579
Алгоритм оптимизации — это то, что меняет веса модели в процессе обучения, он создаётся методом optim.SGD().

271
00:53:51,679 --> 00:53:57,939
В качестве параметров передаются параметры модели model.parameters().

272
00:53:58,039 --> 00:54:07,859
Наша модель — объект класса, наследуемого от torch.nn.Module, она поддерживает весь функционал модулей PyTorch,

273
00:54:10,230 --> 00:54:29,319
в том числе и метод .parameters(), возвращающий все обучаемые веса модели.

274
00:54:29,419 --> 00:54:38,721
Другие параметры — скорость обучения 1e-1, ограничение весов weight_decay=wd и импульс momentum=0.9, их мы обсудим позже.

275
00:54:38,821 --> 00:54:43,950
Нужно будет написать цикл обучения, мы это сделаем потом.

276
00:54:45,809 --> 00:54:58,230
В цикле обучения на каждом минибатче из весов модели вычитается произведение градиента на скорость обучения.

277
00:54:58,230 --> 00:55:02,935
Цикл обучения в fastai выполняется функцией fit(), вот её код.

278
00:55:03,035 --> 00:55:25,099
Первая строка — цикл по эпохам. t — загрузчик данных, для каждого минибатча из t вычисляется функция потерь,

279
00:55:25,490 --> 00:55:39,960
отображается в прогресс-баре, вызываются callback-функции, считается метрика на валидационной выборке.

280
00:55:39,960 --> 00:55:55,120
То есть в каждой эпохе на каждой итерации вызывается метод step(), описанный в оптимизаторе, скоро мы напишем это с нуля.

281
00:55:55,220 --> 00:56:06,745
Мы не создавали алгоритм обучения в объекте learner. Функция fit() — из библиотеки fastai,

282
00:56:06,845 --> 00:56:14,700
но она более низкоуровневая, чем learner.fit(), потому что принимает в качестве модели модуль PyTorch.

283
00:56:14,700 --> 00:56:33,355
Эта функция полезна, если у вас есть готовый модуль PyTorch и вы не хотите писать собственный цикл обучения.

284
00:56:33,455 --> 00:56:41,250
Удобство fastai — в доступности различных уровней абстракции.

285
00:56:41,250 --> 00:56:51,640
На данном уровне недоступны градиентный спуск с перезапуском, дифференциальные скорости обучения

286
00:56:51,740 --> 00:57:02,100
и другие реализованные в алгоритме обучения возможности. Их придётся писать с нуля, это недостаток.

287
00:57:02,100 --> 00:57:13,375
Но есть и преимущество — функция fit() очень простая, у неё понятный код и она работает с модулями PyTorch.

288
00:57:13,475 --> 00:57:24,230
Функция выводит потери на валидационной и обучающей выборках.

289
00:57:24,330 --> 00:57:33,190
Мы хотели достичь значения функции потерь в 0.76, пока не получилось,

290
00:57:33,290 --> 00:57:41,369
модель коллаборативной фильтрации в fastai с параметрами по умолчанию работает лучше.

291
00:57:41,369 --> 00:57:57,960
Функция fit() не выполняет имитацию отжига, поэтому мы меняем скорость обучения функцией set_lrs(opt, 0.01).

292
00:57:57,960 --> 00:58:05,275
Функция принимает алгоритм оптимизации PyTorch и новое значение скорости обучения, после этого опять вызывается fit().

293
00:58:05,375 --> 00:58:17,185
Так имитация отжига выполняется вручную. Значение функции потерь уменьшилось с 1.21 до 1.13.

294
00:58:17,285 --> 00:58:33,669
Давайте сделаем перерыв на семь минут, а после него ещё улучшим модель.
==============================

295
00:58:36,869 --> 00:58:54,960
Меня попросили показать функцию fit() подробнее, она реализована в модуле model библиотеки fastai, это файл model.py.

296
00:58:54,960 --> 00:59:12,204
В каждой эпохе для каждого минибатча вызывается метод .step(), вот его реализация.

297
00:59:12,304 --> 00:59:39,569
В методе переменная output инициализируется через поле self.m, это поле унаследовано от класса nn.Module.

298
00:59:42,059 --> 00:59:51,772
Остальные строки в методе мы ещё обсудим, они вычисляют функцию потерь и выполняют обратный проход.

299
00:59:51,872 --> 01:00:00,130
Примерно так устроен код.

300
01:00:00,230 --> 01:00:09,780
Библиотека fastai сочетает в себе возможность достигать результатов мирового уровня и читаемость кода,

301
01:00:09,780 --> 01:00:22,840
поэтому читайте код, обсуждайте его на форумах и пишите, если придумали, как можно его упростить,

302
01:00:22,940 --> 01:00:29,995
потому что кода будет много.

303
01:00:30,095 --> 01:00:36,790
Давайте вернёмся к демонстрации в Excel и попробуем её улучшить.

304
01:00:36,890 --> 01:00:47,830
Наши рассуждения основывались на идее того, что пользователь 72 любит фэнтези и спецэффекты,

305
01:00:47,930 --> 01:00:57,150
а фильм 27 подходит под это определение, поэтому данный пользователь поставил ему высокую оценку.

306
01:00:57,150 --> 01:01:17,040
Мы не учли тот факт, что пользователь 72 в принципе высоко оценивает фильмы, а фильм 27 не особо выдающийся.

307
01:01:17,040 --> 01:01:29,640
Для компенсации этого вводится новый параметр - смещение. Для пользователей и для фильмов нужно своё значение смещения.

308
01:01:32,280 --> 01:01:48,050
В демонстрации Excel есть вкладка bias, в ней те же данные, но к матрицам эмбеддинга добавлены строка и столбец смещений.

309
01:01:48,150 --> 01:02:01,929
При вычислении скалярного произведения векторов к результату добавляются два смещения.

310
01:02:02,029 --> 01:02:27,630
Функция потерь такая же. Если теперь запустить Решатель и подобрать ещё и смещения, результат получится лучше, чем раньше.

311
01:02:27,630 --> 01:02:37,019
Это наше первое улучшение, код не сильно меняется.

312
01:02:37,119 --> 01:02:48,635
Я ввёл функцию get_emb() для создания матриц эмбеддинга, ni и nf - количество входных данных и количество факторов.

313
01:02:48,735 --> 01:02:55,685
Функция создаёт матрицу по указанным размерам и равномерно заполняет её случайными числами.

314
01:02:55,785 --> 01:03:00,575
В прошлый раз я заполнял матрицы числами от 0 до 0.05, а сейчас - от -0.01 до 0.01,

315
01:03:00,675 --> 01:03:05,765
точные диапазоны не так важны, главное - примерно попасть в необходимый диапазон.

316
01:03:05,865 --> 01:03:20,866
С помощью этой функции мы создаём и матрицы эмбеддинга, и столбцы смещений, столбец смещений - матрица с nf=1.

317
01:03:20,966 --> 01:03:27,634
Эта конструкция - генератор списков, четыре раза вызывающий функцию get_emb()

318
01:03:27,734 --> 01:03:34,630
и присваивающий результаты её работы поочередно переменным self.u, self.m, self.ub, self.mb.

319
01:03:34,630 --> 01:04:10,655
Метод forward() точно так же перемножает матрицы пользователей и фильмов, но добавляет к результату два смещения.

320
01:04:10,755 --> 01:04:15,962
С помощью метода .squeze() PyTorch добавляет дополнительную размерность массивам.

321
01:04:16,062 --> 01:04:29,840
Это называется расширение аргумента (broadcasting), мы обсудим это в курсе по машинному обучению.

322
01:04:29,940 --> 01:04:40,700
Расширение аргумента нужно для того, чтобы складывать матрицы и векторы, приводя их к одному размеру.

323
01:04:40,800 --> 01:05:00,600
Для этого вектор дублируется несколько раз в одном направлении до достижения необходимого размера.

324
01:05:00,700 --> 01:05:05,280
Расширение аргумента в PyTorch работает так же, как и в numpy.

325
01:05:05,380 --> 01:05:11,920
Изначально PyTorch не поддерживал расширение аргумента. Я первый добавил его в PyTorch с помощью костыля,

326
01:05:11,920 --> 01:05:17,110
а потом авторы добавили его поддержку в саму библиотеку.

327
01:05:17,110 --> 01:05:22,180
Итак, расширение аргумента в PyTorch работает так же, как и в numpy.

328
01:05:24,640 --> 01:05:37,390
Очень важно понять, как это работает, потому что это позволяет очень сильно ускорить вычисления, избежав циклов.

329
01:05:37,390 --> 01:05:46,870
Без этого мне пришлось бы в цикле прибавлять вектор смещения к каждому столбцу матрицы, это долго и неудобно.

330
01:05:50,590 --> 01:05:59,770
Расширение аргументов появилось в 60-х годах в языке программирования APL, его автор - Кен Айверсон.

331
01:05:59,770 --> 01:06:10,330
Концепция APL описана в его статье "Notation as a Tool of Thought" - это новая система математических обозначений.

332
01:06:10,330 --> 01:06:15,220
Идея статьи в том, что высокоуровневые системы обозначений позволяют думать и выражать очень сложные мысли.

333
01:06:15,220 --> 01:06:22,820
Расширение аргумента - часть этой идеи, мы ещё будем его использовать,

334
01:06:22,920 --> 01:06:34,832
поэтому изучите этот вопрос в курсе "Машинное обучение" или в Google по запросу "numpy broadcasting".

335
01:06:34,932 --> 01:06:45,195
Итак, расширение аргумента позволяет складывать матрицы и векторы.

336
01:06:45,295 --> 01:07:04,445
После этого мы откалибруем значения оценок к диапазону от 1 до 5, как предлагала Янет.

337
01:07:04,545 --> 01:07:19,455
Для этого от полученного значения оценки сначала берётся сигмоида, она выглядит вот так, значения от 0 до 1.

338
01:07:19,555 --> 01:07:24,900
Например, значение 4.96 превратилось бы в близкое к единице.

339
01:07:24,900 --> 01:07:51,610
Полученное значение умножается на 4 и к нему прибавляется 1, что даёт нам диапазон от 1 до 5.

340
01:07:51,610 --> 01:08:08,710
В коде это выглядит так: сначала оценка res пропускается через сигмоиду.

341
01:08:08,710 --> 01:08:33,645
Все функции над тензорами в PyTorch лежат в модуле nn.functional, его обычно импортируют как F.

342
01:08:33,745 --> 01:08:39,849
F.sigmoid() - функция сигмоиды из этого модуля.

343
01:08:39,949 --> 01:08:48,388
После применения сигмоиды оценка находится в диапазоне от 0 до 1.

344
01:08:48,389 --> 01:09:00,084
После этого оценка умножается на разброс оценок, здесь он равен 5-1=4, и прибавляется минимальная оценка min_rating=1.

345
01:09:00,184 --> 01:09:24,569
Не обязательно приводить оценки к диапазону от 1 до 5, но мы сделали это для интерпретируемости предсказаний.

346
01:09:24,569 --> 01:09:37,959
Это не нейронная сеть, но принцип общий - создавайте необходимый вам формат вывода самым простым способом.

347
01:09:38,059 --> 01:09:44,304
Для этого мы и калибруем оценки.

348
01:09:44,404 --> 01:09:50,589
Итак, теперь класс нашей модели называется EmbeddingDotBias(), модель инициализируется как раньше.

349
01:09:50,689 --> 01:10:01,350
Я добавил .cuda() в конце, чтобы модель хранилась в GPU, fastai делает это автоматически.

350
01:10:01,350 --> 01:10:05,580
Алгоритм оптимизации и функция fit() такие же, как и раньше.

351
01:10:05,580 --> 01:10:23,770
Значения метрики улучшились. Мы меняем скорость обучение, как и раньше, и метрика достигает значения 0.8.

352
01:10:23,870 --> 01:10:34,885
В общем, так и строятся модели коллаборативной фильтрации.

353
01:10:34,985 --> 01:10:47,664
Янет напомнила мне о том, что не совсем корректно называть то, что мы делаем, факторизацией матриц.

354
01:10:47,764 --> 01:10:56,170
Факторизация матриц предполагает, что перемножение матриц пользователей и фильмов даёт матрицу оценок.

355
01:10:56,270 --> 01:11:14,860
У нас в матрице стоит оценка 0, если для данной пары "пользователь - фильм" нет истинного значения,

356
01:11:14,960 --> 01:11:22,290
а простое произведение матриц не может это учесть.

357
01:11:22,290 --> 01:11:29,650
Это было очень неудобно, когда люди решали эту задачу с применением линейной алгебры,

358
01:11:29,750 --> 01:11:36,780
потому что обычно матрицы оценок очень разреженные, в них очень много пустых значений.

359
01:11:36,780 --> 01:11:43,650
В нашей демонстрации их мало, потому что я выбрал самых заядлых зрителей и самые популярные фильмы.

360
01:11:43,650 --> 01:11:49,495
Традиционно в пустых значениях использовались нули, то есть модели нужно было предсказывать нулевую оценку -

361
01:11:49,595 --> 01:11:55,213
как будто то, что пользователь не смотрел фильм, значит, что он ему не понравился.

362
01:11:55,313 --> 01:12:11,220
Это давало ужасные результаты, а вероятностная факторизация матриц позволяет этого избежать,

363
01:12:11,220 --> 01:12:16,110
вычисляя функцию потерь только для непустых значений.

364
01:12:18,240 --> 01:12:25,030
Например, если пользователь 1 поставил фильму 1029 оценку 3.0, а мы предсказали 3.5, потери будут равны 0.5.

365
01:12:25,130 --> 01:12:35,440
Представление данных в таком виде не допускает возможности вычисления функции потерь для несуществующей пары.

366
01:12:35,540 --> 01:12:42,325
Минибатчи содержат только данные из этой таблицы.

367
01:12:43,825 --> 01:12:53,500
Вероятностная факторизация матриц сильно развилась во время соревнования Netflix Prize, окончившегося в 2009.

368
01:12:53,600 --> 01:13:02,540
Тогда она уже существовала, но нигде не использовалась. В первый год соревнования Netflix Prize

369
01:13:02,640 --> 01:13:10,625
кто-то написал пост про то, как эта простая методика даёт отличные результаты,

370
01:13:10,725 --> 01:13:15,860
и внезапно все результаты в рейтинге соревнования подскочили.

371
01:13:15,960 --> 01:13:21,500
Это было несколько лет назад, а сейчас все модели коллаборативной фильтрации так работают.

372
01:13:21,600 --> 01:13:40,975
Не все модели используют сигмоиду, хотя это очень простая вещь, ничего сверхестественного, а помогает.

373
01:13:41,075 --> 01:14:20,050
Давайте посмотри на реализацию класса CollabFilterDataset в файле column_data.py, чтобы сравнить его с нашей моделью.

374
01:14:20,050 --> 01:14:29,985
Метод get_learner создаёт объект класса CollabFilterLearner(), передавая в конструктор результат работы метода get_model(),

375
01:14:30,085 --> 01:14:48,785
который, в свою очередь, создаёт объект класса EmbeddingDotBias(). Класс EmbeddingDotBias() выглядит в точности как наш.

376
01:14:48,885 --> 01:15:00,340
Написанный нами код - тот же код, что и внутри библиотеки fastai.

377
01:15:00,340 --> 01:15:11,410
Этот код чуть проще, так как в нём используется класс CollabFilterDataset(), который позволяет

378
01:15:11,410 --> 01:15:16,104
не доставать данные с использованием списков признаков cats и cons, но остальное совпадает.

379
01:15:16,204 --> 01:15:32,604
Надеюсь, вы почувствовали, что fastai - не зашифрованные письмена, а функции, которые легко написать с нуля.

380
01:15:32,704 --> 01:15:51,690
У модели fastai значение метрики было 0.76, а не 0.8, потому что она использовала SGDR и алгоритм оптимизации Adam.

381
01:15:51,690 --> 01:16:08,219
Янет: Я думаю, можно было бы улучшить модель, используя признак даты в датасете.

382
01:16:08,219 --> 01:16:18,179
Да, можно было бы. Даже если вы не реализовали класс EmbeddingDotBias() в своём Jupyter ноутбуке,

383
01:16:18,179 --> 01:16:29,850
а использовали свою модель, вы могли бы посмотреть в код fastai, скопировать его

384
01:16:29,850 --> 01:16:46,830
и написать на его основе улучшенный класс EmbeddingDotBiasBetter(), чтобы учесть временной признак.

385
01:16:46,830 --> 01:17:01,889
Да, можно многое улучшить - например, предположить, что предпочтения пользователей меняются со временем,

386
01:17:01,989 --> 01:17:06,690
как предложила Янет, или учесть жанры фильмов.

387
01:17:08,940 --> 01:17:27,110
Это сложно сделать на этой модели, она жёсткая, поэтому сейчас мы заменим её на нейронную сеть.

388
01:17:27,110 --> 01:17:49,435
Мы возьмём те же входные данные и те же матрицы эмбеддинга.

389
01:17:49,535 --> 01:17:58,880
Матрица эмбеддинга для фильмов транспонирована, чтобы обе матрицы были одинаково ориентированы.

390
01:17:58,880 --> 01:18:09,370
Датасет представлен в виде обычной таблицы, а не перекрёстной таблицы.

391
01:18:09,470 --> 01:18:45,170
Первым делом мы заменяем нумерацию пользователей на натуральные ряды функцией MATCH().

392
01:18:45,170 --> 01:18:58,640
После этого для каждого пользователя достаётся соответствующий вектор матрицы эмбеддинга функцией OFFSET().

393
01:18:58,640 --> 01:19:22,580
Функция OFFSET() копирует соответствующие значения из матрицы эмбеддинга.

394
01:19:22,580 --> 01:19:51,800
Доставание строки матрицы эмбеддинга - это умножение вектора, представленного прямым кодированием, на эту матрицу.

395
01:19:51,800 --> 01:19:59,190
Полезно это помнить - матрица эмбеддинга подразумевает матричное произведение.

396
01:19:59,290 --> 01:20:12,840
Под капотом не происходит умножения вектора, представленного прямым кодированием, на матрицу эмбеддинга,

397
01:20:12,940 --> 01:20:19,280
потому что есть удобная оптимизация - доставание по индексу.

398
01:20:19,280 --> 01:20:28,830
Матрицы эмбеддинга позволяют ускорить вычисления, избежав умножения матриц.

399
01:20:28,930 --> 01:20:47,900
Нумерация фильмов так же заменена на натуральный ряд и фильмам так же сопоставлены векторы эмбеддинга.

400
01:20:49,460 --> 01:21:06,370
Вместо скалярного произведения этих двух векторов длиной 5 для получения оценки, как мы делали раньше,

401
01:21:06,370 --> 01:21:17,562
мы объединим их в один вектор длиной 10 и передадим этот вектор в нейронную сеть.

402
01:21:17,662 --> 01:21:33,840
Из таких векторов будет состоять тензор активаций после слоя эмбеддинга,

403
01:21:33,940 --> 01:21:39,525
и уже на их основании будет делаться предсказание.

404
01:21:39,625 --> 01:21:47,344
Как мы знаем, нейронные сети могут научиться делать что угодно, в том числе и коллаборативную фильтрацию.

405
01:21:47,444 --> 01:21:52,699
Наша нейронная сеть реализуется классом EmbeddingNet().

406
01:21:52,799 --> 01:22:10,050
Я не вводил смещение, потому что в линейном слое PyTorch nn.Linear оно есть по умолчанию.

407
01:22:10,050 --> 01:22:39,210
Пусть размер матрицы эмбеддинга пользователей - nu x nf, фильмов - nm x nf.

408
01:22:39,210 --> 01:22:50,099
Для каждой пары "пользователь - фильм" мы берём по вектору длиной nf из обеих матриц

409
01:22:50,099 --> 01:22:57,239
и объединяем их в вектор длиной 2 x nf.

410
01:23:00,480 --> 01:23:27,610
Проделав такое для всех пар, получаем матрицу размера (nu + nm) x 10.

411
01:23:27,710 --> 01:23:49,329
Полученная матрица пропускается через выпрямитель, а потом умножается на матрицу 10x1 для получения оценки.

412
01:23:49,429 --> 01:23:57,879
Это классическая нейронная сеть с одним скрытым слоем.

413
01:23:57,979 --> 01:24:05,190
Я считаю, что здесь один скрытый слой. Слой эмбеддинга тоже скрытый,

414
01:24:05,190 --> 01:24:21,270
но оба этих слоя линейны и идут сразу друг за другом, поэтому это один большой линейный слой.

415
01:24:21,270 --> 01:24:27,690
Линейный слой в PyTorch создаётся конструктором nn.Linear().

416
01:24:31,290 --> 01:24:46,020
В курсе "Машинное обучение" мы создавали линейный слой с нуля, можете посмотреть и повторить, но там нет ничего нового.

417
01:24:46,020 --> 01:24:57,750
Итак, мы создаём матрицы эмбеддинга, а потом два линейных слоя.

418
01:24:57,750 --> 01:25:06,415
Можно увеличить функционал класса и добавить параметр количества активаций в скрытом слое nh=10,

419
01:25:06,515 --> 01:25:32,820
это добавит возможностей для эксперимента. Параметр nh - это ширина матрицы весов полносвязного слоя.

420
01:25:32,820 --> 01:25:38,550


421
01:25:38,550 --> 01:25:41,670


422
01:25:41,670 --> 01:25:47,100


423
01:25:47,100 --> 01:25:52,320


424
01:25:56,300 --> 01:26:01,580


425
01:26:01,580 --> 01:26:07,980


426
01:26:07,980 --> 01:26:14,160


427
01:26:14,160 --> 01:26:16,199


428
01:26:16,199 --> 01:26:20,550


429
01:26:20,550 --> 01:26:26,070


430
01:26:28,220 --> 01:26:34,950


431
01:26:34,950 --> 01:26:42,630


432
01:26:42,630 --> 01:26:45,690


433
01:26:48,030 --> 01:26:52,890


434
01:26:52,890 --> 01:26:57,660


435
01:27:00,810 --> 01:27:05,280


436
01:27:08,130 --> 01:27:14,610


437
01:27:14,610 --> 01:27:20,340


438
01:27:20,340 --> 01:27:25,860


439
01:27:27,840 --> 01:27:31,800


440
01:27:31,800 --> 01:27:38,100


441
01:27:38,100 --> 01:27:48,600


442
01:27:48,600 --> 01:27:54,810


443
01:27:54,810 --> 01:27:59,820


444
01:28:02,490 --> 01:28:07,830


445
01:28:07,830 --> 01:28:12,270


446
01:28:12,270 --> 01:28:18,570


447
01:28:24,420 --> 01:28:30,750


448
01:28:30,750 --> 01:28:34,619


449
01:28:34,619 --> 01:28:40,789


450
01:28:40,789 --> 01:28:46,590


451
01:28:46,590 --> 01:28:51,269


452
01:28:51,269 --> 01:28:59,309


453
01:28:59,309 --> 01:29:03,030


454
01:29:03,030 --> 01:29:10,230


455
01:29:10,230 --> 01:29:15,599


456
01:29:15,599 --> 01:29:23,519


457
01:29:23,519 --> 01:29:26,429


458
01:29:26,429 --> 01:29:30,960


459
01:29:30,960 --> 01:29:35,699


460
01:29:35,699 --> 01:29:50,789


461
01:29:50,789 --> 01:29:55,110


462
01:29:55,110 --> 01:29:57,389


463
01:29:57,389 --> 01:30:01,499


464
01:30:01,499 --> 01:30:06,269


465
01:30:06,269 --> 01:30:10,920


466
01:30:10,920 --> 01:30:15,420


467
01:30:15,420 --> 01:30:22,019


468
01:30:22,019 --> 01:30:24,960


469
01:30:24,960 --> 01:30:30,869


470
01:30:30,869 --> 01:30:36,150


471
01:30:36,150 --> 01:30:43,349


472
01:30:43,349 --> 01:30:51,000


473
01:30:51,000 --> 01:30:57,620


474
01:31:00,770 --> 01:31:08,489


475
01:31:12,570 --> 01:31:18,510


476
01:31:18,510 --> 01:31:22,830


477
01:31:22,830 --> 01:31:28,320


478
01:31:28,320 --> 01:31:31,710


479
01:31:31,710 --> 01:31:39,210


480
01:31:39,210 --> 01:31:48,630


481
01:31:48,630 --> 01:31:53,520


482
01:31:53,520 --> 01:32:08,790


483
01:32:18,630 --> 01:32:24,719


484
01:32:24,719 --> 01:32:31,469


485
01:32:31,469 --> 01:32:37,590


486
01:32:37,590 --> 01:32:42,780


487
01:32:42,780 --> 01:32:47,010


488
01:32:47,010 --> 01:32:52,230


489
01:32:53,790 --> 01:32:57,989


490
01:32:57,989 --> 01:33:02,500


491
01:33:02,500 --> 01:33:08,710


492
01:33:08,710 --> 01:33:12,040


493
01:33:12,040 --> 01:33:15,880


494
01:33:15,880 --> 01:33:27,000


495
01:33:27,000 --> 01:33:34,870


496
01:33:34,870 --> 01:33:42,220


497
01:33:42,220 --> 01:33:49,330


498
01:33:49,330 --> 01:33:54,160


499
01:33:54,160 --> 01:34:03,220


500
01:34:03,220 --> 01:34:08,110


501
01:34:11,200 --> 01:34:16,030


502
01:34:16,030 --> 01:34:20,560


503
01:34:20,560 --> 01:34:23,770


504
01:34:23,770 --> 01:34:30,040


505
01:34:30,430 --> 01:34:37,270


506
01:34:37,270 --> 01:34:45,330


507
01:34:48,400 --> 01:34:54,460


508
01:34:54,460 --> 01:35:09,160


509
01:35:09,160 --> 01:35:18,290


510
01:35:18,290 --> 01:35:23,630


511
01:35:23,630 --> 01:35:27,410


512
01:35:27,410 --> 01:35:32,180


513
01:35:32,180 --> 01:35:38,300


514
01:35:38,300 --> 01:35:45,650


515
01:35:47,450 --> 01:35:53,060


516
01:35:53,060 --> 01:36:03,740


517
01:36:06,500 --> 01:36:13,820


518
01:36:13,820 --> 01:36:18,440


519
01:36:18,440 --> 01:36:24,670


520
01:36:24,670 --> 01:36:27,850


521
01:36:27,880 --> 01:36:34,430


522
01:36:34,430 --> 01:36:37,940


523
01:36:41,390 --> 01:36:47,240


524
01:36:51,710 --> 01:36:54,860


525
01:36:54,860 --> 01:37:02,950


526
01:37:02,950 --> 01:37:10,460


527
01:37:10,460 --> 01:37:15,050


528
01:37:15,050 --> 01:37:20,330


529
01:37:20,330 --> 01:37:24,410


530
01:37:24,410 --> 01:37:33,019


531
01:37:33,019 --> 01:37:40,129


532
01:37:40,129 --> 01:37:45,769


533
01:37:45,769 --> 01:37:49,760


534
01:37:49,760 --> 01:37:57,049


535
01:37:57,049 --> 01:38:05,599


536
01:38:05,599 --> 01:38:09,969


537
01:38:09,969 --> 01:38:18,129


538
01:38:18,129 --> 01:38:23,059


539
01:38:23,059 --> 01:38:26,419


540
01:38:26,419 --> 01:38:30,769


541
01:38:30,769 --> 01:38:40,969


542
01:38:40,969 --> 01:38:46,219


543
01:38:46,219 --> 01:38:51,229


544
01:38:51,229 --> 01:38:59,089


545
01:38:59,089 --> 01:39:03,349


546
01:39:03,349 --> 01:39:07,399


547
01:39:07,399 --> 01:39:11,749


548
01:39:13,999 --> 01:39:18,469


549
01:39:18,469 --> 01:39:24,049


550
01:39:24,049 --> 01:39:30,530


551
01:39:30,530 --> 01:39:34,609


552
01:39:34,609 --> 01:39:39,570


553
01:39:43,530 --> 01:39:47,760


554
01:39:47,760 --> 01:39:51,540


555
01:39:51,540 --> 01:39:56,430


556
01:39:56,430 --> 01:40:00,540


557
01:40:00,540 --> 01:40:03,240


558
01:40:03,240 --> 01:40:08,910


559
01:40:08,910 --> 01:40:14,220


560
01:40:14,220 --> 01:40:18,390


561
01:40:18,390 --> 01:40:23,460


562
01:40:23,460 --> 01:40:29,490


563
01:40:29,490 --> 01:40:33,660


564
01:40:33,660 --> 01:40:36,780


565
01:40:36,780 --> 01:40:41,970


566
01:40:41,970 --> 01:40:47,640


567
01:40:47,640 --> 01:40:51,810


568
01:40:51,810 --> 01:40:58,080


569
01:41:01,710 --> 01:41:07,680


570
01:41:07,680 --> 01:41:13,620


571
01:41:13,620 --> 01:41:20,010


572
01:41:20,010 --> 01:41:29,010


573
01:41:29,010 --> 01:41:36,240


574
01:41:36,240 --> 01:41:42,020


575
01:41:42,890 --> 01:41:49,950


576
01:41:52,040 --> 01:41:56,050


577
01:41:56,050 --> 01:42:02,770


578
01:42:02,770 --> 01:42:06,969


579
01:42:06,969 --> 01:42:13,630


580
01:42:13,630 --> 01:42:22,090


581
01:42:22,090 --> 01:42:26,890


582
01:42:26,890 --> 01:42:33,580


583
01:42:33,580 --> 01:42:38,380


584
01:42:38,380 --> 01:42:45,850


585
01:42:45,850 --> 01:42:52,719


586
01:42:52,719 --> 01:43:03,100


587
01:43:03,100 --> 01:43:07,989


588
01:43:09,790 --> 01:43:14,739


589
01:43:14,739 --> 01:43:21,400


590
01:43:21,400 --> 01:43:24,250


591
01:43:24,250 --> 01:43:28,480


592
01:43:28,480 --> 01:43:37,870


593
01:43:37,870 --> 01:43:42,880


594
01:43:42,880 --> 01:43:47,199


595
01:43:49,060 --> 01:43:54,310


596
01:43:54,310 --> 01:43:59,260


597
01:43:59,260 --> 01:44:07,000


598
01:44:07,000 --> 01:44:14,200


599
01:44:14,200 --> 01:44:24,640


600
01:44:24,640 --> 01:44:29,020


601
01:44:29,020 --> 01:44:35,860


602
01:44:39,760 --> 01:44:43,060


603
01:44:43,060 --> 01:44:47,830


604
01:44:51,960 --> 01:44:56,380


605
01:44:56,380 --> 01:45:00,640


606
01:45:00,640 --> 01:45:04,240


607
01:45:06,430 --> 01:45:10,840


608
01:45:10,840 --> 01:45:15,580


609
01:45:15,580 --> 01:45:19,720


610
01:45:19,720 --> 01:45:23,530


611
01:45:28,270 --> 01:45:34,270


612
01:45:34,270 --> 01:45:40,150


613
01:45:41,500 --> 01:45:46,600


614
01:45:46,600 --> 01:45:53,050


615
01:45:53,050 --> 01:46:02,920


616
01:46:02,920 --> 01:46:10,720


617
01:46:10,720 --> 01:46:17,550


618
01:46:17,550 --> 01:46:22,450


619
01:46:22,450 --> 01:46:26,380


620
01:46:26,380 --> 01:46:33,670


621
01:46:33,670 --> 01:46:42,160


622
01:46:42,160 --> 01:46:45,100


623
01:46:45,100 --> 01:47:00,940


624
01:47:02,170 --> 01:47:06,940


625
01:47:10,960 --> 01:47:13,330


626
01:47:13,330 --> 01:47:17,860


627
01:47:17,860 --> 01:47:23,020


628
01:47:23,020 --> 01:47:25,690


629
01:47:28,150 --> 01:47:36,310


630
01:47:36,310 --> 01:47:43,810


631
01:47:43,810 --> 01:47:47,020


632
01:47:47,020 --> 01:47:56,440


633
01:47:59,170 --> 01:48:03,910


634
01:48:03,910 --> 01:48:10,240


635
01:48:10,240 --> 01:48:16,270


636
01:48:16,270 --> 01:48:23,050


637
01:48:23,050 --> 01:48:27,790


638
01:48:27,790 --> 01:48:31,750


639
01:48:31,750 --> 01:48:34,929


640
01:48:34,929 --> 01:48:39,429


641
01:48:39,429 --> 01:48:43,540


642
01:48:43,540 --> 01:48:48,010


643
01:48:48,010 --> 01:48:54,400


644
01:48:57,520 --> 01:49:03,159


645
01:49:05,079 --> 01:49:09,610


646
01:49:09,610 --> 01:49:14,020


647
01:49:14,020 --> 01:49:19,510


648
01:49:19,510 --> 01:49:23,860


649
01:49:25,480 --> 01:49:28,599


650
01:49:28,599 --> 01:49:33,880


651
01:49:33,880 --> 01:49:38,790


652
01:49:38,790 --> 01:49:45,130


653
01:49:45,130 --> 01:49:48,550


654
01:49:48,550 --> 01:49:52,090


655
01:49:52,090 --> 01:49:55,420


656
01:49:55,420 --> 01:49:59,710


657
01:49:59,710 --> 01:50:05,469


658
01:50:05,469 --> 01:50:10,719


659
01:50:10,719 --> 01:50:17,139


660
01:50:17,139 --> 01:50:22,239


661
01:50:24,670 --> 01:50:28,060


662
01:50:28,060 --> 01:50:37,300


663
01:50:37,300 --> 01:50:45,219


664
01:50:45,219 --> 01:50:52,239


665
01:50:56,349 --> 01:51:02,530


666
01:51:02,530 --> 01:51:09,099


667
01:51:09,099 --> 01:51:11,800


668
01:51:11,800 --> 01:51:17,590


669
01:51:17,590 --> 01:51:26,170


670
01:51:26,170 --> 01:51:32,559


671
01:51:32,559 --> 01:51:41,139


672
01:51:41,139 --> 01:51:48,849


673
01:51:48,849 --> 01:51:56,440


674
01:51:59,050 --> 01:52:06,070


675
01:52:10,420 --> 01:52:13,809


676
01:52:13,809 --> 01:52:19,570


677
01:52:22,989 --> 01:52:32,070


678
01:52:32,070 --> 01:52:40,989


679
01:52:40,989 --> 01:52:45,550


680
01:52:45,550 --> 01:52:49,690


681
01:52:53,769 --> 01:52:58,990


682
01:52:58,990 --> 01:53:05,170


683
01:53:05,170 --> 01:53:12,220


684
01:53:12,220 --> 01:53:19,750


685
01:53:19,750 --> 01:53:30,610


686
01:53:30,610 --> 01:53:35,410


687
01:53:35,410 --> 01:53:40,180


688
01:53:40,180 --> 01:53:51,850


689
01:53:51,850 --> 01:53:56,830


690
01:53:56,830 --> 01:54:01,260


691
01:54:01,260 --> 01:54:11,350


692
01:54:11,350 --> 01:54:16,510


693
01:54:16,510 --> 01:54:21,430


694
01:54:21,430 --> 01:54:28,810


695
01:54:28,810 --> 01:54:39,340


696
01:54:39,340 --> 01:54:49,660


697
01:54:49,660 --> 01:54:59,110


698
01:54:59,110 --> 01:55:03,850


699
01:55:03,850 --> 01:55:13,020


700
01:55:13,020 --> 01:55:26,800


701
01:55:26,800 --> 01:55:32,650


702
01:55:35,830 --> 01:55:41,740


703
01:55:41,740 --> 01:55:48,940


704
01:55:48,940 --> 01:55:55,600


705
01:55:55,600 --> 01:56:03,280


706
01:56:08,080 --> 01:56:14,200


707
01:56:14,200 --> 01:56:18,790


708
01:56:18,790 --> 01:56:24,100


709
01:56:24,100 --> 01:56:28,300


710
01:56:28,300 --> 01:56:32,140


711
01:56:32,140 --> 01:56:35,680


712
01:56:35,680 --> 01:56:40,240


713
01:56:41,950 --> 01:56:46,810


714
01:56:46,810 --> 01:56:51,700


715
01:56:57,340 --> 01:57:04,300


716
01:57:04,300 --> 01:57:11,950


717
01:57:11,950 --> 01:57:22,620


718
01:57:26,160 --> 01:57:31,660


719
01:57:31,660 --> 01:57:38,710


720
01:57:38,710 --> 01:57:41,680


721
01:57:41,680 --> 01:57:45,910


722
01:57:45,910 --> 01:57:50,800


723
01:57:50,800 --> 01:57:55,300


724
01:57:55,300 --> 01:57:59,170


725
01:57:59,170 --> 01:58:03,330


726
01:58:03,330 --> 01:58:08,140


727
01:58:08,140 --> 01:58:12,160


728
01:58:13,750 --> 01:58:21,670


729
01:58:21,670 --> 01:58:26,230


730
01:58:37,930 --> 01:58:44,740


731
01:58:46,960 --> 01:58:58,000


732
01:58:58,000 --> 01:59:03,240


733
01:59:03,720 --> 01:59:18,220


734
01:59:18,220 --> 01:59:22,720


735
01:59:22,720 --> 01:59:25,690


736
01:59:29,020 --> 01:59:36,690


737
01:59:38,489 --> 01:59:41,700


738
01:59:41,700 --> 01:59:46,440


739
01:59:46,440 --> 01:59:50,670


740
01:59:50,670 --> 01:59:56,880


741
01:59:56,880 --> 02:00:00,330


742
02:00:00,330 --> 02:00:08,640


743
02:00:08,640 --> 02:00:14,730


744
02:00:17,310 --> 02:00:22,200


745
02:00:24,750 --> 02:00:31,170


746
02:00:31,170 --> 02:00:36,390


747
02:00:36,390 --> 02:00:43,710


748
02:00:43,710 --> 02:00:49,560


749
02:00:49,560 --> 02:00:53,660


750
02:00:58,830 --> 02:01:04,560


751
02:01:04,560 --> 02:01:09,690


752
02:01:13,920 --> 02:01:19,020


753
02:01:19,020 --> 02:01:25,230


754
02:01:28,290 --> 02:01:34,110


755
02:01:34,110 --> 02:01:42,960


756
02:01:42,960 --> 02:01:49,989


757
02:01:56,739 --> 02:02:00,400


758
02:02:00,400 --> 02:02:05,650


759
02:02:05,650 --> 02:02:12,730


760
02:02:12,730 --> 02:02:19,300


761
02:02:19,300 --> 02:02:25,690


762
02:02:28,750 --> 02:02:36,550


763
02:02:36,550 --> 02:02:41,680


764
02:02:41,680 --> 02:02:48,610


765
02:02:52,920 --> 02:03:00,610


766
02:03:00,610 --> 02:03:07,210


767
02:03:07,210 --> 02:03:13,210


768
02:03:13,210 --> 02:03:22,420


769
02:03:22,420 --> 02:03:28,780


770
02:03:28,780 --> 02:03:34,090


771
02:03:34,090 --> 02:03:37,630


772
02:03:37,630 --> 02:03:42,130


773
02:03:42,130 --> 02:03:47,830


774
02:03:47,830 --> 02:03:53,370


775
02:04:00,180 --> 02:04:10,380


776
02:04:10,380 --> 02:04:14,980


777
02:04:16,210 --> 02:04:22,360


778
02:04:22,360 --> 02:04:31,900


779
02:04:31,900 --> 02:04:36,489


780
02:04:36,489 --> 02:04:40,930


781
02:04:40,930 --> 02:04:47,290


782
02:04:47,290 --> 02:04:52,390


783
02:04:52,390 --> 02:04:58,120


784
02:04:58,120 --> 02:05:02,770


785
02:05:02,770 --> 02:05:09,190


786
02:05:11,949 --> 02:05:15,280


787
02:05:15,280 --> 02:05:22,840


788
02:05:22,840 --> 02:05:28,180


789
02:05:28,180 --> 02:05:33,730


790
02:05:35,890 --> 02:05:39,670


791
02:05:39,670 --> 02:05:44,080


792
02:05:44,080 --> 02:05:50,620


793
02:05:50,620 --> 02:05:55,090


794
02:05:55,090 --> 02:05:59,440


795
02:06:00,820 --> 02:06:06,850


796
02:06:06,850 --> 02:06:11,020


797
02:06:11,020 --> 02:06:15,580


798
02:06:17,260 --> 02:06:21,730


799
02:06:24,400 --> 02:06:30,340


800
02:06:30,340 --> 02:06:37,540


801
02:06:37,540 --> 02:06:42,370


802
02:06:42,370 --> 02:06:49,320


803
02:06:49,320 --> 02:06:55,300


804
02:06:55,300 --> 02:06:58,750


805
02:06:58,750 --> 02:07:04,060


806
02:07:04,060 --> 02:07:09,550


807
02:07:09,550 --> 02:07:14,980


808
02:07:16,840 --> 02:07:22,630


809
02:07:22,630 --> 02:07:26,980


810
02:07:28,510 --> 02:07:34,870


811
02:07:34,870 --> 02:07:41,320


812
02:07:41,320 --> 02:07:46,210


813
02:07:46,210 --> 02:07:53,260


814
02:07:53,260 --> 02:07:56,650


815
02:07:59,290 --> 02:08:03,480


816
02:08:03,480 --> 02:08:09,760


817
02:08:09,760 --> 02:08:13,120


818
02:08:13,120 --> 02:08:18,100


819
02:08:18,100 --> 02:08:22,240


820
02:08:24,700 --> 02:08:29,650


821
02:08:29,650 --> 02:08:33,010


822
02:08:33,010 --> 02:08:37,720


823
02:08:37,720 --> 02:08:43,060


824
02:08:43,060 --> 02:08:48,550


825
02:08:48,550 --> 02:08:55,030


826
02:08:55,030 --> 02:08:58,840


827
02:08:58,840 --> 02:09:04,660


828
02:09:04,660 --> 02:09:09,940


829
02:09:09,940 --> 02:09:13,540


830
02:09:13,540 --> 02:09:18,660


831
02:09:19,830 --> 02:09:25,000


832
02:09:25,000 --> 02:09:31,480


833
02:09:31,480 --> 02:09:35,140


834
02:09:35,140 --> 02:09:42,100


835
02:09:42,100 --> 02:09:48,370


836
02:09:50,500 --> 02:09:56,500


837
02:09:56,500 --> 02:10:00,670


838
02:10:00,670 --> 02:10:03,790


839
02:10:03,790 --> 02:10:15,430


840
02:10:15,430 --> 02:10:21,310


841
02:10:21,310 --> 02:10:26,770


842
02:10:26,770 --> 02:10:29,590


843
02:10:29,590 --> 02:10:35,500


844
02:10:35,500 --> 02:10:38,610


845
02:10:38,610 --> 02:10:45,930


846
02:10:45,930 --> 02:10:50,880


847
02:10:50,880 --> 02:10:57,720


848
02:10:57,720 --> 02:11:02,850


849
02:11:02,850 --> 02:11:12,750


850
02:11:12,750 --> 02:11:19,860


851
02:11:19,860 --> 02:11:27,480


852
02:11:27,480 --> 02:11:34,739


853
02:11:34,739 --> 02:11:39,510


854
02:11:39,510 --> 02:11:46,440


855
02:11:48,570 --> 02:11:54,330


856
02:11:54,330 --> 02:11:57,989


857
02:11:57,989 --> 02:12:03,360


858
02:12:03,360 --> 02:12:08,910


859
02:12:08,910 --> 02:12:14,100


860
02:12:14,100 --> 02:12:19,140


861
02:12:19,140 --> 02:12:23,400


862
02:12:26,130 --> 02:12:32,880


863
02:12:32,880 --> 02:12:39,270


864
02:12:39,270 --> 02:12:49,619


865
02:12:55,960 --> 02:13:04,840


866
02:13:04,840 --> 02:13:10,750


867
02:13:10,750 --> 02:13:15,909


868
02:13:15,909 --> 02:13:19,630


869
02:13:19,630 --> 02:13:24,219


870
02:13:24,219 --> 02:13:31,719


871
02:13:31,719 --> 02:13:39,159


872
02:13:39,159 --> 02:13:47,679


873
02:13:47,679 --> 02:13:52,150


874
02:13:52,150 --> 02:13:57,550


875
02:13:57,550 --> 02:14:02,770


876
02:14:02,770 --> 02:14:07,210


877
02:14:07,210 --> 02:14:14,469


878
02:14:14,469 --> 02:14:21,780


879
02:14:21,780 --> 02:14:28,809


880
02:14:28,809 --> 02:14:35,829


881
02:14:38,139 --> 02:14:42,940


882
02:14:46,929 --> 02:14:53,559


883
02:14:53,559 --> 02:14:56,920


884
02:14:56,920 --> 02:15:02,739


885
02:15:03,070 --> 02:15:09,580


886
02:15:09,580 --> 02:15:15,460


887
02:15:15,460 --> 02:15:22,000


888
02:15:22,000 --> 02:15:28,480


889
02:15:28,480 --> 02:15:32,110


890
02:15:32,110 --> 02:15:36,400


891
02:15:36,400 --> 02:15:40,300


892
02:15:40,300 --> 02:15:47,410


893
02:15:47,410 --> 02:15:51,970


894
02:15:51,970 --> 02:15:57,340


895
02:15:57,340 --> 02:16:01,960


896
02:16:01,960 --> 02:16:11,440


897
02:16:11,440 --> 02:16:17,410


898
02:16:17,410 --> 02:16:26,950


899
02:16:26,950 --> 02:16:34,510


900
02:16:34,510 --> 02:16:40,150


901
02:16:40,150 --> 02:16:46,540


902
02:16:46,540 --> 02:16:53,200


903
02:16:53,200 --> 02:16:57,460


904
02:16:59,170 --> 02:17:03,130


905
02:17:03,129 --> 02:17:05,550


906
02:17:06,620 --> 02:17:11,460


907
02:17:12,660 --> 02:17:21,420


908
02:17:21,420 --> 02:17:27,030


909
02:17:27,030 --> 02:17:32,640


910
02:17:35,280 --> 02:17:40,350


911
02:17:40,350 --> 02:17:46,080


912
02:17:46,080 --> 02:17:50,340


913
02:17:50,340 --> 02:17:57,120


914
02:17:57,120 --> 02:18:00,480


915
02:18:02,459 --> 02:18:06,149


916
02:18:06,150 --> 02:18:10,680


917
02:18:10,680 --> 02:18:17,280


918
02:18:17,280 --> 02:18:21,060


919
02:18:23,309 --> 02:18:26,969


920
02:18:26,969 --> 02:18:32,219


921
02:18:32,219 --> 02:18:39,439


