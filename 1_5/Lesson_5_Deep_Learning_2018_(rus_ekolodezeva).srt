1
00:00:00,030 --> 00:00:05,784
Добро пожаловать на пятую лекцию.

2
00:00:05,884 --> 00:00:27,834
Один из студентов магистратуры нашего университета написал пост про анализ структурированных данных по нашему курсу.

3
00:00:27,934 --> 00:00:37,824
Пост оказался очень популярным, как я и ожидал. Его опубликовали на сайте towardsdatascience.com,

4
00:00:37,924 --> 00:00:46,840
это неплохой ресурс для тех, кто интересуется новостями анализа данных.

5
00:00:46,940 --> 00:00:58,195
Автор поста — Kerem Turgutlu. Его пост рассказывает об основных идеях с последней лекции.

6
00:00:58,295 --> 00:01:05,452
Sebastian Ruder, которого я уже упоминал на прошлой неделе как одного из моих любимых исследователей,

7
00:01:05,552 --> 00:01:16,590
поделился ссылкой на этот пост, а кто-то из Stitch Fix ответил, что они давно таким занимаются.

8
00:01:16,590 --> 00:01:23,125
Я знаю, что в индустрии многие занимаются анализом структурированных данных, но про это никто не пишет.

9
00:01:23,225 --> 00:01:31,509
Тут Kerem публикует пост, и Stitch Fix сразу отвечает — «ну, ничего нового».

10
00:01:31,609 --> 00:01:46,310
Я был рад этому посту, и думаю, что на эту тему можно ещё много написать — например, про работу с различными датасетами,

11
00:01:46,410 --> 00:01:57,429
или анализ старых соревнований Kaggle, которые можно или нельзя было бы выиграть с современными инструментами.

12
00:01:57,529 --> 00:02:13,970
Было бы интересно почитать про различные характеристики дропаута, я не видел про это статей.

13
00:02:13,970 --> 00:02:21,950
Я думаю, тут большой потенциал для развития. Кто-то в Twitter ответил на пост фразой «Я столько лет искал эту информацию!».

14
00:02:25,310 --> 00:02:36,940
Nikhil B, чьи классификаторы игроков в бейсбол или крикет и изображения купюр я упоминал после первой лекции,

15
00:02:36,940 --> 00:02:54,545
скачал из Google пару сотен фотографий актёров в очках и без очков, разметил их вручную и обучил классификатор.

16
00:02:54,645 --> 00:03:06,724
Архитектура ResNet работала плохо, поэтому он экспериментировал с разморозкой слоёв

17
00:03:06,824 --> 00:03:11,440
и дифференциальными скоростями обучения, и достиг доли правильных ответов в 100%.

18
00:03:11,709 --> 00:03:22,590
Мне нравится, что он выбрал реальную задачу — изображения из Google, а не размеченный датасет с Kaggle.

19
00:03:22,690 --> 00:03:30,930
В его посте есть ссылка на удобный инструмент для скачивания изображений из Google.

20
00:03:31,030 --> 00:03:41,379
Сегодня я выступал в Университете Сингулярности перед топ-менеджерами одной из крупнейших телекоммуникационных компаний.

21
00:03:41,479 --> 00:03:56,220
Их поставщики убеждали их собирать миллионы изображений, покупать высокие вычислительные мощности и специальные программы.

22
00:03:56,320 --> 00:04:03,960
Я показал им этот пост и сказал — «Вот чего достиг человек после трёх недель обучения на машине за 60 центов в час».

23
00:04:04,060 --> 00:04:13,140
Они были очень рады, узнав, что такое доступно обычным людям.

24
00:04:13,240 --> 00:04:20,030
Я предполагаю, что Nikhil — обычный человек, прошу прощения, если ненароком его обидел.

25
00:04:20,029 --> 00:04:31,650
Я посмотрел на его классификатор игроков в крикет. Этот код совпадает с кодом с первой лекции за исключением количества эпох.

26
00:04:31,750 --> 00:04:42,852
Я надеялся, что так случится. Это доказывает, что эти четыре строки — полезный инструмент.

27
00:04:42,952 --> 00:04:50,894
Показывайте эти результаты топ-менеджерам своих компаний.

28
00:04:50,994 --> 00:05:04,820
Они будут сомневаться и говорить вам — «Если так можно, почему нам никто до сих пор этого не сказал?»,

29
00:05:04,820 --> 00:05:15,885
поэтому вам придётся продемонстрировать это на собственных примерах, например, данных вашей компании.

30
00:05:15,985 --> 00:05:28,700
Vitaly Bushaev написал введение в обучение нейронных сетей.

31
00:05:28,700 --> 00:05:40,340
У него хороший слог и умение объяснять сложные вещи простым языком, берите с него пример.

32
00:05:43,280 --> 00:05:52,220
Автор начинает с азов, но читатель понимает, что его не принимают за дурака —

33
00:05:52,220 --> 00:06:03,610
за каждым уравнением следует подробное объяснение того, что всё это значит.

34
00:06:03,710 --> 00:06:11,450
Автору удаётся сочетать уважение к читателям и отсутствие у них изначальных знаний в данной области.

35
00:06:11,450 --> 00:06:21,480
На этой неделе я запостил скриншот рейтинга соревнования Plant Seedlings Classification на Kaggle, где занимал первое место.

36
00:06:21,580 --> 00:06:31,025
Это было ошибкой, потому что к текущему моменту уже пятеро студентов нашего курса обогнали меня в этом рейтинге.

37
00:06:31,125 --> 00:06:41,870
Это текущий рейтинг соревнования, первые пять результатов — студенты курса fast.ai, шестой — преподаватель курса.

38
00:06:41,970 --> 00:07:06,212
Датасет состоит из нескольких тысяч изображений, размер большинства которых меньше 100x100.

39
00:07:06,312 --> 00:07:16,115
Для своего результата я просто последовательно выполнил ячейки Jupyter ноутбука, это заняло где-то час.

40
00:07:16,215 --> 00:07:23,170
Я думаю, эти студенты в рейтинге сделали немного больше, но не сильно.

41
00:07:23,170 --> 00:07:48,520
Как видно, стандартные средства библиотеки fastai дают хорошие результаты без особых усилий.

42
00:07:48,520 --> 00:07:55,510
Сегодня мы перейдём ко второй половине первой части курса.

43
00:07:55,510 --> 00:08:09,067
В первой половине мы разбирались пробежались по основным темам, поняли, как создавать соответствующие модели,

44
00:08:09,167 --> 00:08:13,590
и получили примерное представление о том, как они работают.

45
00:08:17,830 --> 00:08:27,245
Сейчас мы пройдёмся по этим темам снова, но уже углублённо, разбираясь во всех деталях

46
00:08:27,345 --> 00:08:35,590
и читая исходный код библиотеки fastai для того, чтобы повторить все шаги.

47
00:08:35,590 --> 00:08:45,370
К текущему моменту я показал вам лучшие из известных мне подходов, мы пока отойдём от этого.

48
00:08:45,370 --> 00:08:52,085
Я думаю, что перед тем, как изучать новые техники во второй части курса, важно понять,

49
00:08:52,185 --> 00:08:58,780
как работает код для всего, что мы уже умеем.

50
00:08:58,780 --> 00:09:12,625
Сегодня мы почти с нуля создадим весьма успешную модель коллаборативной фильтрации.

51
00:09:12,725 --> 00:09:19,330
Мы используем PyTorch для дифференцирования и библиотеку для работы с GPU, всё остальное напишем сами.

52
00:09:19,330 --> 00:09:24,977
Мы не будем использовать средства PyTorch для работы с нейронными сетями и постараемся не злоупотреблять средствами fastai.

53
00:09:25,077 --> 00:09:35,800
Мы не успели подробно разобрать коллаборативную фильтрацию на прошлой лекции, давайте к этому вернёмся.

54
00:09:35,800 --> 00:09:45,155
Мы будем работать с датасетом Movielens, это список оценок фильмов.

55
00:09:45,255 --> 00:09:58,900
Пользователи представлены индексом userId, фильмы — индексом movieId, оценки и даты их выставления записаны в столбцах rating и timestamp.

56
00:09:58,900 --> 00:10:12,650
Я никогда не использовал признак Timestamp, мы будем использовать признаки userId, movieId и rating.

57
00:10:12,750 --> 00:10:28,410
В терминах структурированных данных признаки userId и movieId — категориальные, а оценка — целевая переменная.

58
00:10:28,410 --> 00:10:35,330
У нас есть таблица названий фильмов, мы не будем использовать их для обучения модели, только для демонстрации её работы.

59
00:10:35,430 --> 00:10:46,089
Здесь также указаны жанры фильмов, я не использую их, кто-нибудь на этой неделе может проверить, прав ли я в этом.

60
00:10:46,089 --> 00:10:55,180
Для того, чтобы посмотреть на датасет, я выбрал пользователей, которые посмотрели больше всего фильмов,

61
00:10:57,880 --> 00:11:03,820
взял самые популярные фильмы и составил перекрёстную таблицу методом pandas.crosstab().

62
00:11:03,820 --> 00:11:12,680
Это подмножество датасета. Строки соответствуют пользователям, столбцы — фильмам, соответствующие оценки — в пересечениях.

63
00:11:12,780 --> 00:11:18,557
Некоторые пользователи не смотрели определённые фильмы, поэтому в таблице есть значения NaN.

64
00:11:18,657 --> 00:11:37,955
Я скопировал эту таблицу в Excel, демонстрация называется collab_filter.xlsx.

65
00:11:38,055 --> 00:12:09,790
Если вы чего-то не понимаете, задавайте вопросы здесь или на форуме. Янет следит за вопросами на форуме.

66
00:12:09,790 --> 00:12:19,803
Сейчас мы переходим к деталям работы, поэтому очень важно, чтобы все всё понимали.

67
00:12:19,903 --> 00:12:47,420
Мы не будем обучать нейронную сеть, а займёмся сначала факторизацией матриц, потому что это простейший способ решить нашу задачу.

68
00:12:47,520 --> 00:12:57,800
Эта матрица предсказаний, построенная по такому же принципу, как и скопированная из Jupyter ноутбука.

69
00:12:57,900 --> 00:13:18,645
Это истинные значения, это предсказания, это — среднеквадратичная ошибка (RMSE) между этими двумя таблицами.

70
00:13:18,745 --> 00:13:25,005
Таблица предсказаний состоит из случайных чисел, ошибка составляет 2.81.

71
00:13:25,105 --> 00:13:41,560
Сейчас я покажу, как мы предсказываем, что пользователь номер 14 оценит фильм номер 27 как 0.91. Пока оценка случайная.

72
00:13:41,560 --> 00:14:05,990
Оценка получается скалярным произведением выделенных векторов.

73
00:14:05,990 --> 00:14:22,509
Красный вектор — матрица размера 1x5, фиолетовый — матрица размера 5x1. Перемножая эти матрицы, получаем предсказание.

74
00:14:22,609 --> 00:14:33,050
Если для какой-то оценки нет истинного значения, она будет равна нулю, чтобы корректно считать функцию потерь.

75
00:14:34,220 --> 00:14:46,149
Наша модель — не нейронная сеть, а просто перемножение двух матриц.

76
00:14:46,249 --> 00:15:04,430
Таблица предсказаний 15x15 получена перемножением левой матрицы 15x5 на верхнюю матрицу 5x15.

77
00:15:04,430 --> 00:15:28,165
Сейчас числа в этих матрицах, то есть начальные веса модели, случайные, а модель — это перемножение этих матриц.

78
00:15:28,265 --> 00:15:43,135
Excel умеет выполнять градиентный спуск, его нужно включить в настройках, и станет доступен Решатель.

79
00:15:43,235 --> 00:16:07,525
В Решатель передаются ячейка с целевой функцией (RMSE) и ячейки с оптимизируемыми значениями (две матрицы).

80
00:16:07,625 --> 00:16:20,110
Решатель меняет числа в матрицах и с помощью градиентного спуска находит значения, минимизирующие целевую функцию.

81
00:16:20,520 --> 00:16:33,985
После запуска Решателя значение целевой функции начинает уменьшаться.

82
00:16:34,085 --> 00:16:43,840
Умножение матриц и градиентный спуск наводят на мысли о нейронных сетях,

83
00:16:43,940 --> 00:16:51,630
но здесь нет нелинейного слоя и второго слоя, поэтому это не глубокое обучение.

84
00:16:51,630 --> 00:17:00,150
Модели, использующие произведения матриц без нелинейных слоёв, называют моделями неглубокого обучения.

85
00:17:01,830 --> 00:17:17,189
Мне надоело ждать, поэтому я остановлю Решатель. Среднеквадратичная ошибка упала с 2.81 до 0.39.

86
00:17:17,189 --> 00:17:36,650
Модель предсказывает, что пользователь 72 поставил фильму 27 оценку 4.4. Истинное значение — 4, как видите, модель работает.

87
00:17:36,650 --> 00:18:11,190
Необходимо предсказать 225 значений, используя 150 параметров, поэтому это не простой подгон, а машинное обучение.

88
00:18:11,190 --> 00:18:23,725
В линейной алгебре такой процесс называется разложением матрицы, это можно было сделать аналитически,

89
00:18:23,825 --> 00:18:29,430
а мы делаем это с помощью градиентного спуска. Градиентный спуск — мощный инструмент.

90
00:18:29,430 --> 00:18:36,960
Я предпочитаю рассматривать это с интуитивной точки зрения, а не с точки зрения линейной алгебры.

91
00:18:36,960 --> 00:18:56,225
Предположим, что фильм номер 27 — это Властелин Колец: Братство Кольца, и мы хотим узнать, понравится ли он пользователю 72.

92
00:18:56,325 --> 00:19:11,250
Фильму соответствует пять чисел. Допустим, первое число говорит, насколько фильм фантастический,

93
00:19:11,250 --> 00:19:21,390
второе — настолько давно он вышел и какие там спецэффекты, пятое — сколько в фильме диалогов.

94
00:19:21,390 --> 00:19:27,820
Пять чисел соответствуют пяти признакам фильма.

95
00:19:27,920 --> 00:19:45,265
В таком случае для каждого пользователя можно сказать, насколько он любит фэнтези, спецэффекты и диалоги в фильмах.

96
00:19:45,365 --> 00:19:54,310
Сумма поэлементных произведений чисел пользователя на числа фильма отразит то, понравится ему этот фильм или нет.

97
00:19:54,410 --> 00:20:13,060
У нас нет этой информации о фильмах и пользователях, мы выбираем этот подход, и градиентный спуск подбирает эти числа.

98
00:20:13,160 --> 00:20:36,030
Эти числа называются скрытые факторы. Они скрытые, потому что мы не выделяли и не называли эти неявные признаки,

99
00:20:36,030 --> 00:20:46,740
а просто предположили, что факторы их отражают. Мы предположили, что оценка фильма может быть получена

100
00:20:46,740 --> 00:20:53,605
перемножением значений каких-то признаков фильма и соответствующих предпочтений пользователя,

101
00:20:53,705 --> 00:21:06,175
и использовали градиентный спуск, чтобы найти значения этих неизвестных признаков.

102
00:21:06,275 --> 00:21:14,889
В этом суть вероятностной факторизации матриц, так работает коллаборативная фильтрация с её применением.

103
00:21:14,989 --> 00:21:26,490
Всё, что мы сделали — инициализировали две случайные матрицы и перемножили их.

104
00:21:26,490 --> 00:21:38,250
Вопрос из зала: Может, надо было отнормировать значения к шкале от 0 до 5?

105
00:21:38,250 --> 00:21:46,380
Да, мы сделаем это и ещё много чего. Это — простейшая версия.

106
00:21:46,380 --> 00:21:50,850
Мы напишем этот алгоритм на Python и запустим на всём датасете.

107
00:21:54,750 --> 00:22:03,050
Вопрос из зала: Как определить размеры матриц?

108
00:22:03,150 --> 00:22:43,220
Эти матрицы — это матрицы эмбеддинга, 5 — её ширина. Для фильма 72 мы бы взяли строку номер 72 и получили эти пять чисел.

109
00:22:43,220 --> 00:22:53,780
Вопрос в том, как выбрать ширину матрицы эмбеддинга, и ответ — непонятно, надо пробовать.

110
00:22:53,780 --> 00:23:10,410
Число должно быть достаточно большим, чтобы учесть сложные закономерности, но не слишком большим,

111
00:23:10,510 --> 00:23:17,460
иначе параметров будет слишком много и модель будет очень долго обучаться и может переобучиться.

112
00:23:17,560 --> 00:23:26,865
Вопрос из зала: Что значат негативные факторы в матрицах эмбеддинга?

113
00:23:26,965 --> 00:23:34,610
В матрице для фильмов — например, то, что диалогов в фильме мало и они плохие.

114
00:23:34,610 --> 00:23:41,540
В матрице для пользователей — например, то, что пользователь терпеть не может спецэффекты в фильмах.

115
00:23:41,540 --> 00:23:49,645
Вопрос из зала: То есть факторы могут быть любые? Никаких ограничений?

116
00:23:49,745 --> 00:23:54,447
Да, любые, это просто матрицы эмбеддинга.

117
00:23:54,547 --> 00:24:19,340
Вопрос из зала: Почему мы доверяем этим матрицам эмбеддинга?

118
00:24:21,410 --> 00:24:33,380
Мы используем градиентный спуск для подбора факторов. Найдя хороший минимум, мы перестаём в них сомневаться,

119
00:24:33,380 --> 00:24:42,720
так как другие числа будут хуже. Конечно, нужно смотреть на результаты на валидационной выборке, мы будем это делать.

120
00:24:42,820 --> 00:24:50,240
Вопрос из зала: Нужно ли обучать модель заново при появлении нового пользователя или нового фильма?

121
00:24:50,240 --> 00:24:56,365
Очень хороший вопрос, на него нет короткого и быстрого ответа.

122
00:24:56,465 --> 00:25:11,000
Нужна будет немного другая модель, и со временем её придётся дообучать.

123
00:25:11,000 --> 00:25:28,110
Раньше Netflix после регистрации просил указать фильмы, которые вам понравились, и дообучал модель на этих данных.

124
00:25:28,210 --> 00:25:38,895
Вопрос из зала: Можно ли для этого просто найти максимально похожие фильмы?

125
00:25:38,995 --> 00:25:50,685
Да, но для этого нужно построить модель с признаками фильмов — жанр, год выпуска, актёры на главных ролях.

126
00:25:50,785 --> 00:26:05,235
У нас признаки не выделены, поэтому нужно использовать коллаборативную фильтрацию.

127
00:26:07,635 --> 00:26:17,010
Многие части кода вам уже знакомы. Мы начнём использовать PyTorch и fastai,

128
00:26:17,110 --> 00:26:26,610
а потом углубимся в детали их работы и несколько раз поменяем.

129
00:26:26,710 --> 00:26:39,860
Мы создаём валидационную выборку знакомой функцией get_ct_idxs().

130
00:26:39,860 --> 00:26:47,050
Параметр wd=2e-4 — это ограничение весов, ещё обсудим. Для тех, кто проходил курс «Машинное обучение» — это L2-регуляризация.

131
00:26:47,050 --> 00:26:53,742
Параметр n_factors — ширина таблицы эмбеддинга.

132
00:26:53,842 --> 00:27:06,375
Объект данных модели создаётся методом CollabFilterDataset.from_csv(), в него передаётся таблица с оценками.

133
00:27:06,475 --> 00:27:28,425
После этого нужно передать признак userId для строк, признак movieId для столбцов и целевую переменную ratings.

134
00:27:28,525 --> 00:27:33,390
Все рекомендательные системы на основе коллаборативной фильтрации построены так —

135
00:27:33,490 --> 00:27:40,660
есть набор пользователей и набор товаров, эти наборы связаны.

136
00:27:40,660 --> 00:27:53,530
В соревновании по предсказанию продаж вместо пользователей — магазины, а товары — то, что они продадут.

137
00:27:53,530 --> 00:28:09,045
Принцип один — по паре категориальных признаков высокой мощности через произведение матриц вычисляется оценка или вероятностью.

138
00:28:09,145 --> 00:28:26,800
Можно думать про это по-другому: когда мы предсказываем, понравится ли пользователю 72 фильм 27, мы смотрим,

139
00:28:26,900 --> 00:28:43,635
каким пользователям нравятся те же фильмы, что и пользователю 72, и какие фильмы нравятся пользователям, похожим на пользователя 72.

140
00:28:43,735 --> 00:28:56,475
Это две формулировки одного вопроса. Коллаборативная фильтрация рассматривает пары «пользователь — фильм»

141
00:28:56,575 --> 00:29:11,670
и ищет фильмы, которые смотрели похожие люди, и людей, которые смотрели похожие фильмы.

142
00:29:11,770 --> 00:29:21,240
Если ваш датасет построен таким образом, при работе с ним можно использовать коллаборативную фильтрацию.

143
00:29:21,340 --> 00:29:28,460
Итак, есть два признака и целевая переменная.

144
00:29:28,460 --> 00:29:34,310
Как обычно, мы получаем алгоритм обучения из объекта данных модели методом .get_learner().

145
00:29:34,310 --> 00:29:48,285
Метод принимает ширину матрицы эмбеддинга n_factors, валидационную выборку val_idxs, размер минибатча 64 и алгоритм оптимизации opt_fn.

146
00:29:48,385 --> 00:29:52,842
Мы ещё обсудим алгоритмы оптимизации, здесь используется Adam.

147
00:29:52,942 --> 00:30:03,210
После создания алгоритма обучения мы обучаем модель, всё как обычно.

148
00:30:03,310 --> 00:30:10,905
Такие модели обучаются быстро, здесь всего три эпохи.

149
00:30:11,005 --> 00:30:15,480
Можно использовать алгоритм поиска скорости обучения и всё остальное, к чему вы уже привыкли.

150
00:30:15,580 --> 00:30:24,590
Обучение модели заняло пару секунд, не было никаких предобученных моделей, всё с нуля.

151
00:30:24,690 --> 00:30:34,335
Для получения среднеквадратичной ошибки (RMSE) нужно взять корень из метрики в последнем столбце.

152
00:30:34,435 --> 00:30:58,880
Корень из 0.776 равен примерно 0.88, лучший бенчмарк на этом датасете — 0.91, мы побили его за две секунды.

153
00:30:58,880 --> 00:31:11,800
Так можно написать модель коллаборативной фильтрации с использованием fastai, не задумываясь о деталях.

154
00:31:11,900 --> 00:31:23,470
Сейчас мы построим эту модель с нуля и достигнем значения метрики 0.77-0.78.

155
00:31:23,570 --> 00:31:32,935
Если вы хотите повторить этот результат без углубления в детали, этих трёх строк кода достаточно.

156
00:31:33,035 --> 00:31:38,095
Предсказания получаются методом .predict(), можно визуализировать их с помощью библиотеки seaborn.

157
00:31:38,195 --> 00:31:48,960
Библиотека seaborn построена на основе библиотеки matplotlib, поэтому знание matplotlib пригодится при её освоении.

158
00:31:48,960 --> 00:31:54,230
В seaborn есть несколько удобных видов графиков. Например, метод seaborn.jointplot()

159
00:31:54,230 --> 00:32:00,120
строит распределение предсказаний (горизонтальная ось) и истинных значений (вертикальная ось).

160
00:32:02,340 --> 00:32:07,192
Видно, что модель отражает общую картину данных — высокие оценки предсказываются высокими числами.

161
00:32:07,292 --> 00:32:18,420
Сверху — гистограмма распределения предсказаний, справа — истинных значений, наглядная иллюстрация.

162
00:32:18,420 --> 00:32:23,615
Вопрос из зала: Что значит параметр n_factors и почему он равен 50?

163
00:32:23,915 --> 00:32:29,352
Он равен 50, потому что это значение здесь работает лучше всего, это ширина матрицы эмбеддинга.

164
00:32:29,452 --> 00:32:39,860
В демонстрации Excel этот параметр равен 5, а у нас 50.

165
00:32:41,750 --> 00:32:54,715
Янет: Что меняется, если оценка — не действительное число, а либо 0, либо 1?

166
00:32:54,815 --> 00:33:02,575
Тогда нужно строить классификатор, а не регрессию.

167
00:33:02,675 --> 00:33:11,650
Янет: Что для этого нужно изменить?

168
00:33:11,750 --> 00:33:15,385
Не уверен, что мы доберёмся до этого в этом курсе.

169
00:33:15,485 --> 00:33:21,600
Задача классификации с использованием коллаборативной фильтрации ещё не воплощена в fastai,

170
00:33:21,600 --> 00:33:26,315
может, кто-то из студентов захочет это добавить, это несложно.

171
00:33:26,415 --> 00:33:44,850
Нужно поменять функцию активации на сигмоиду и поменять функцию потерь с RMSE на перекрёстную энтропию.

172
00:33:44,850 --> 00:33:50,940
Больше ничего менять не надо, надеюсь, кто-нибудь это напишет, и к следующей неделе у нас уже будут средства.

173
00:33:50,940 --> 00:34:04,800
Произведение векторов — это то же самое, что и произведение матриц.

174
00:34:04,800 --> 00:34:13,209
Два вектора умножаются поэлементно, и результаты складываются.

175
00:34:13,309 --> 00:34:22,110
Давайте напишем это на Python. PyTorch-тензор создаётся конструктором T().

176
00:34:22,110 --> 00:34:34,434
Это функция fastai, в PyTorch тензор создаётся методом torch.from_numpy(). Мы создали два тензора из матриц

177
00:34:34,534 --> 00:34:46,090
a = [[1, 2], [3, 4]] и b = [[2, 2], [10, 10]].

178
00:34:46,190 --> 00:34:52,150
Я не добавил .cuda() при создании переменных, поэтому они лежат в CPU, а не в GPU.

179
00:34:52,250 --> 00:35:19,590
Оператор обычного умножения a*b в PyTorch перемножит два тензора одинакового размера поэлементно.

180
00:35:19,590 --> 00:36:10,285
(a*b).sum(1) просуммирует элементы в каждой строке матрицы a*b, то есть перемножит строки матриц a и b.

181
00:36:10,385 --> 00:36:25,220
Этот результат можно было бы получить с использованием матричного умножения, но мы будем делать так.

182
00:36:28,080 --> 00:36:44,455
Нужно помнить, что данные представлены в виде обычной таблицы, а не перекрёстной, как в демонстрации в Excel.

183
00:36:44,555 --> 00:36:50,962
Для каждого пользователя мы находим строку длиной 50 в матрице эмбеддинга пользователей и умножаем её на

184
00:36:51,062 --> 00:37:02,680
строку для фильма длиной 50 в матрице эмбеддинга фильмов.

185
00:37:02,780 --> 00:37:21,120
Для этого мы создадим свой слой нейронной сети в виде модуля PyTorch.

186
00:37:21,120 --> 00:37:32,710
Модуль PyTorch — специальный объект, который можно использовать в качестве слоя нейронной сети.

187
00:37:32,810 --> 00:37:41,470
Модуль предполагает наличие реализованного скалярного произведения.

188
00:37:41,570 --> 00:37:55,405
Модуль создаётся конструктором model=DotProduct() и после этого используется как функция.

189
00:37:55,505 --> 00:38:08,369
Модуль — не просто функция, можно брать его производную и создавать нейронные сети из многих модулей.

190
00:38:08,369 --> 00:38:14,730
По сути, это удобно определённая функция.

191
00:38:14,730 --> 00:38:23,260
Скалярное произведение DotProduct() задаётся классом Python.

192
00:38:23,360 --> 00:38:31,410
Если вы не писали на Python в объектно-ориентированном стиле, придётся начать, потому что все модули PyTorch устроены таким образом.

193
00:38:33,690 --> 00:38:46,000
Мне нравится в PyTorch то, что там используется стиль написания кода Python, а не изобретается всё заново, как в TensorFlow.

194
00:38:46,100 --> 00:38:55,770
Для реализации нового поведения в Python используются классы.

195
00:38:55,770 --> 00:39:07,020
Янет: Можно ли использовать fastai для решения задачи коллаборативной фильтрации на очень больших данных?

196
00:39:07,020 --> 00:39:33,560
Да, конечно. Данные хранятся в датафрейме, датафрейм хранится в оперативной памяти.

197
00:39:33,560 --> 00:39:40,920
На Amazon легко арендовать машину с 512 ГБ памяти.

198
00:39:40,920 --> 00:39:46,200
Если ваш csv-файл больше 512 ГБ, что впечатляет,

199
00:39:48,510 --> 00:39:52,769


200
00:39:54,210 --> 00:40:00,359


201
00:40:00,359 --> 00:40:03,519


202
00:40:03,619 --> 00:40:15,549
Я ни разу не встречал матриц коллаборативной фильтрации тяжелее 512 ГБ, но даже с таким можно работать.

203
00:40:15,649 --> 00:40:32,640
В PyTorch при создании класса необходимо реализовать метод forward().

204
00:40:32,640 --> 00:40:37,109


205
00:40:37,109 --> 00:40:43,019


206
00:40:43,019 --> 00:40:48,180


207
00:40:48,180 --> 00:40:51,989


208
00:40:51,989 --> 00:40:54,369


209
00:40:54,469 --> 00:41:01,529
Итак, мы создаём класс и реализуем метод forward, выполняющий скалярное произведение.

210
00:41:01,529 --> 00:41:13,979
После реализации класса создаётся модуль, который потом используется для вычисления скалярного произведения.

211
00:41:16,529 --> 00:41:29,811
Так создаётся слой в PyTorch, это проще, чем в других библиотеках, потому что используются встроенные средства Python.

212
00:41:29,911 --> 00:41:34,499
Давайте создадим более сложный модуль с помощью класса EmbeddingDot().

213
00:41:38,039 --> 00:41:49,670
Снова понадобится метод forward. Появятся новые поля u (users) и m (movies) — матрицы эмбеддинга пользователей и фильмов.

214
00:41:49,670 --> 00:42:00,254
Метод forward() использует эти поля, а на вход принимает индексы категориальных и количественных признаков в минибатче cats и cons.

215
00:42:00,354 --> 00:42:07,054
Индексы пользователей и фильмов могут отличаться от натурального ряда —

216
00:42:07,154 --> 00:42:16,864
например, лежать в диапазоне от 1,000,000 до 1,001,000.

217
00:42:16,964 --> 00:42:25,952
В таком случае длина матрицы эмбеддинга была бы 1,001,000, это неразумное использование места.

218
00:42:26,052 --> 00:42:38,210
Поэтому первым делом мы получаем список уникальных индексов пользователей, а потом нумеруем их заново.

219
00:42:38,310 --> 00:43:03,640
Эта строка создания словаря новой нумерации индексов очень полезная, запомните её.

220
00:43:06,729 --> 00:43:18,439
После создания новых индексов мы заменяем ими старые.

221
00:43:18,539 --> 00:43:31,639
Метод .apply() в pandas позволяет применить к датафрейму любую функцию, здесь используется лямбда-функция.

222
00:43:31,739 --> 00:43:36,039
Для фильмов делается то же самое.

223
00:43:36,039 --> 00:43:41,319
После такого преобразования оценки фильмов не изменились, но индексы были заменены на числа натурального ряда,

224
00:43:43,690 --> 00:43:49,239
чтобы эффективно использовать матрицы эмбеддинга.

225
00:43:49,239 --> 00:43:54,819
Переменные n_users и n_movies содержат количество уникальных пользователей и фильмов.

226
00:43:54,819 --> 00:44:00,609
Давайте напишем демонстрацию в Excel на Python.

227
00:44:00,609 --> 00:44:21,760
В самом простом варианте модуля PyTorch не нужно реализовывать конструктор класса, так как нет никаких параметров.

228
00:44:21,760 --> 00:44:37,850
У нас есть параметры — количество пользователей n_users и количество фильмов n_movies, поэтому нужен конструктор.

229
00:44:37,850 --> 00:44:50,550
Конструктор в Python реализуется функцией __init__().

230
00:44:50,650 --> 00:45:01,930
Если вы не писали классы раньше, попрактикуйтесь. Конструктор — это функция, вызывающаяся при создании объекта.

231
00:45:02,030 --> 00:45:16,920
Для наследования от класса nn.Module необходимо указать его в параметрах и вызвать конструктор родительского класса.

232
00:45:17,020 --> 00:45:27,685
Класс EmbeddingDot() наследует класс torch.nn.Module(), поэтому он — полноценный модуль PyTorch.

233
00:45:27,785 --> 00:45:41,870
Для реализации класса мы создаём поля self.u и self.m. Поле self.u — объект класса nn.Embedding(), матрица эмбеддинга.

234
00:45:41,870 --> 00:45:55,280
Матрица эмбеддинга пользователей self.u содержит n_users строк и n_factors столбцов, в демонстрации в Excel n_users=15 и n_factors=5.

235
00:45:55,280 --> 00:46:01,880
То же самое для фильмов.

236
00:46:01,880 --> 00:46:09,910
После создания матрицы эмбеддинга заполняются случайными числами.

237
00:46:12,920 --> 00:46:33,665
Случайные числа должны лежать в разумном диапазоне, чтобы градиентный спуск нормально работал.

238
00:46:33,765 --> 00:46:51,020
Я прикинул, какими должны быть числа, чтобы оценки лежали в диапазоне от 0 до 5, получился диапазон от 0 до 0.05.

239
00:46:51,020 --> 00:47:13,960
Kaiming He разработал алгоритм для определения этого диапазона.

240
00:47:14,060 --> 00:47:34,765
Идея в том, чтобы случайные числа в матрице составляли нормальное распределение со стандартным отклонением,

241
00:47:34,865 --> 00:47:48,950
обратно пропорциональным ширине матрицы эмбеддинга.

242
00:47:48,950 --> 00:48:04,940
У нас ширина матрицы эмбеддинга равна 50, примерно так и выходит.

243
00:48:04,940 --> 00:48:28,430
В PyTorch есть функция для автоматического определения этого числа, но мы всё делаем с нуля, поэтому задаём руками.

244
00:48:28,430 --> 00:48:53,774
Поле weight поля self.u класса EmbeddingDot() содержит матрицу эмбеддинга. Матрица эмбеддинга — объект класса Variable,

245
00:48:53,874 --> 00:49:12,284
это то же самое, что и тензор, но с функцией автоматического дифференцирования. Тензор содержится в поле data.

246
00:49:12,384 --> 00:49:22,484
Итак, тензор матрицы эмбеддинга содержится в поле self.u.weight.data.

247
00:49:22,584 --> 00:49:33,419
Во всех функциях на тензорах в PyTorch можно поставить нижнее подчёркивание «_» после названия,

248
00:49:33,519 --> 00:49:48,344
и функция выполнится на вызываемом объекте. Эта функция заполняет тензор числами, распределёнными равномерно.

249
00:49:48,444 --> 00:50:12,869
Без этой функции строка была бы чуть длиннее.

250
00:50:12,969 --> 00:50:21,449
Итак, у нас есть матрицы эмбеддинга.

251
00:50:21,549 --> 00:50:31,069
В метод forward я передам данные, полученные методом ColumnarModelData.from_data_frame().

252
00:50:31,069 --> 00:50:38,579
Несмотря на то, что у нас нет количественных признаков, формально они передаются.

253
00:50:38,679 --> 00:50:48,329
Столбец пользователей содержится в первом столбце датафрейма с данными, столбец фильмов — во втором.

254
00:50:48,429 --> 00:50:58,264
Мне не хочется создавать новый класс, поэтому я использую эту конструкцию.

255
00:50:58,364 --> 00:51:21,220
Метод forward принимает индексы данных для одного минибатча и достаёт из матриц эмбеддинга соответствующие векторы.

256
00:51:21,320 --> 00:51:31,359
Принцип работы я уже показывал, тут это делается сразу для минибатча, а не для одной пары «пользователь — фильм».

257
00:51:31,459 --> 00:51:43,449
Нам не нужно писать никаких циклов, потому что PyTorch почти все операции выполняет сразу над минибатчами.

258
00:51:43,549 --> 00:51:52,509
Если вы напишете цикл для того, чтобы просматривать минибатч по изображению за раз, это не ускорит работу.

259
00:51:52,609 --> 00:51:59,339
Поэтому из соображений быстроты стоит пользоваться встроенными средствами PyTorch.

260
00:51:59,339 --> 00:52:05,604
Повторюсь, почти всё в PyTorch так и работает, вам не нужно об этом думать.

261
00:52:05,704 --> 00:52:13,239
Итак, мы определили скалярное произведение векторов пользователей и фильмов.

262
00:52:13,339 --> 00:52:27,684
Я задаю признаки — это всё в датасете, кроме оценки фильма и времени, и целевую переменную — то есть оценку фильма.

263
00:52:27,784 --> 00:52:39,546
Из этих данных методом ColumnarModelData.from_data_frame() создаётся объект модели данных data.

264
00:52:39,646 --> 00:52:42,204


265
00:52:42,304 --> 00:52:47,519


266
00:52:49,549 --> 00:52:55,469


267
00:52:55,469 --> 00:53:02,640


268
00:53:02,640 --> 00:53:07,499


269
00:53:07,499 --> 00:53:11,400


270
00:53:11,400 --> 00:53:14,430


271
00:53:17,220 --> 00:53:21,960


272
00:53:21,960 --> 00:53:26,670


273
00:53:26,670 --> 00:53:29,700


274
00:53:31,380 --> 00:53:35,940


275
00:53:35,940 --> 00:53:42,420


276
00:53:42,420 --> 00:53:48,359


277
00:53:48,359 --> 00:53:54,900


278
00:53:54,900 --> 00:54:01,079


279
00:54:01,079 --> 00:54:07,859


280
00:54:10,230 --> 00:54:16,890


281
00:54:16,890 --> 00:54:21,230


282
00:54:21,230 --> 00:54:27,359


283
00:54:27,359 --> 00:54:31,380


284
00:54:31,380 --> 00:54:37,079


285
00:54:37,079 --> 00:54:43,950


286
00:54:45,809 --> 00:54:51,170


287
00:54:51,170 --> 00:54:58,230


288
00:54:58,230 --> 00:55:07,740


289
00:55:12,510 --> 00:55:18,359


290
00:55:21,770 --> 00:55:25,099


291
00:55:25,490 --> 00:55:32,070


292
00:55:32,070 --> 00:55:39,960


293
00:55:39,960 --> 00:55:46,110


294
00:55:46,110 --> 00:55:52,050


295
00:55:52,050 --> 00:55:58,290


296
00:55:58,290 --> 00:56:04,590


297
00:56:04,590 --> 00:56:09,000


298
00:56:09,000 --> 00:56:14,700


299
00:56:14,700 --> 00:56:21,510


300
00:56:21,510 --> 00:56:24,990


301
00:56:27,300 --> 00:56:30,960


302
00:56:30,960 --> 00:56:35,850


303
00:56:35,850 --> 00:56:41,250


304
00:56:41,250 --> 00:56:46,040


305
00:56:46,040 --> 00:56:49,980


306
00:56:49,980 --> 00:56:53,400


307
00:56:53,400 --> 00:56:57,540


308
00:56:57,540 --> 00:57:02,100


309
00:57:02,100 --> 00:57:06,540


310
00:57:06,540 --> 00:57:11,130


311
00:57:11,130 --> 00:57:15,720


312
00:57:19,100 --> 00:57:29,460


313
00:57:29,460 --> 00:57:37,020


314
00:57:37,020 --> 00:57:41,369


315
00:57:41,369 --> 00:57:46,920


316
00:57:46,920 --> 00:57:50,940


317
00:57:50,940 --> 00:57:54,089


318
00:57:54,089 --> 00:57:57,960


319
00:57:57,960 --> 00:58:02,160


320
00:58:02,160 --> 00:58:08,490


321
00:58:08,490 --> 00:58:13,740


322
00:58:13,740 --> 00:58:20,730


323
00:58:20,730 --> 00:58:27,630


324
00:58:27,630 --> 00:58:39,809


325
00:58:39,809 --> 00:58:45,779


326
00:58:45,779 --> 00:58:54,960


327
00:58:54,960 --> 00:59:01,049


328
00:59:01,049 --> 00:59:07,470


329
00:59:07,470 --> 00:59:17,039


330
00:59:17,039 --> 00:59:20,940


331
00:59:20,940 --> 00:59:28,500


332
00:59:28,500 --> 00:59:35,059


333
00:59:35,059 --> 00:59:39,569


334
00:59:42,059 --> 00:59:45,960


335
00:59:45,960 --> 00:59:50,550


336
00:59:50,550 --> 00:59:55,740


337
00:59:57,480 --> 01:00:02,880


338
01:00:02,880 --> 01:00:09,780


339
01:00:09,780 --> 01:00:15,210


340
01:00:15,210 --> 01:00:19,230


341
01:00:19,230 --> 01:00:26,550


342
01:00:26,550 --> 01:00:33,540


343
01:00:33,540 --> 01:00:40,140


344
01:00:40,140 --> 01:00:44,790


345
01:00:44,790 --> 01:00:50,970


346
01:00:50,970 --> 01:00:57,150


347
01:00:57,150 --> 01:01:05,400


348
01:01:05,400 --> 01:01:10,710


349
01:01:10,710 --> 01:01:17,040


350
01:01:17,040 --> 01:01:24,300


351
01:01:24,300 --> 01:01:29,640


352
01:01:32,280 --> 01:01:37,380


353
01:01:37,380 --> 01:01:44,420


354
01:01:44,420 --> 01:01:51,780


355
01:01:51,780 --> 01:01:58,400


356
01:01:58,400 --> 01:02:05,559


357
01:02:05,559 --> 01:02:11,200


358
01:02:14,650 --> 01:02:20,980


359
01:02:20,980 --> 01:02:27,630


360
01:02:27,630 --> 01:02:32,579


361
01:02:32,579 --> 01:02:41,559


362
01:02:41,559 --> 01:02:46,900


363
01:02:46,900 --> 01:02:50,470


364
01:02:52,450 --> 01:02:59,020


365
01:02:59,020 --> 01:03:02,230


366
01:03:02,230 --> 01:03:09,400


367
01:03:09,400 --> 01:03:14,710


368
01:03:14,710 --> 01:03:20,440


369
01:03:20,440 --> 01:03:25,900


370
01:03:25,900 --> 01:03:29,890


371
01:03:29,890 --> 01:03:34,630


372
01:03:34,630 --> 01:03:44,260


373
01:03:44,260 --> 01:03:50,289


374
01:03:50,289 --> 01:03:58,380


375
01:03:58,440 --> 01:04:02,770


376
01:04:02,770 --> 01:04:07,150


377
01:04:07,150 --> 01:04:14,260


378
01:04:14,260 --> 01:04:21,370


379
01:04:23,340 --> 01:04:27,640


380
01:04:28,030 --> 01:04:31,750


381
01:04:31,750 --> 01:04:36,760


382
01:04:36,760 --> 01:04:44,740


383
01:04:46,900 --> 01:04:53,800


384
01:04:53,800 --> 01:04:58,000


385
01:04:58,000 --> 01:05:03,300


386
01:05:03,300 --> 01:05:07,360


387
01:05:07,360 --> 01:05:11,920


388
01:05:11,920 --> 01:05:17,110


389
01:05:17,110 --> 01:05:22,180


390
01:05:24,640 --> 01:05:29,470


391
01:05:29,470 --> 01:05:34,180


392
01:05:34,180 --> 01:05:37,390


393
01:05:37,390 --> 01:05:40,510


394
01:05:40,510 --> 01:05:46,870


395
01:05:50,590 --> 01:05:54,610


396
01:05:54,610 --> 01:05:59,770


397
01:05:59,770 --> 01:06:05,110


398
01:06:05,110 --> 01:06:10,330


399
01:06:10,330 --> 01:06:15,220


400
01:06:15,220 --> 01:06:20,110


401
01:06:20,110 --> 01:06:25,630


402
01:06:25,630 --> 01:06:33,880


403
01:06:33,880 --> 01:06:37,990


404
01:06:40,860 --> 01:06:49,630


405
01:06:49,630 --> 01:06:56,220


406
01:06:59,890 --> 01:07:09,100


407
01:07:09,100 --> 01:07:14,110


408
01:07:14,110 --> 01:07:24,900


409
01:07:24,900 --> 01:07:29,500


410
01:07:29,500 --> 01:07:33,520


411
01:07:33,520 --> 01:07:37,450


412
01:07:37,450 --> 01:07:44,800


413
01:07:44,800 --> 01:07:47,020


414
01:07:47,020 --> 01:07:51,610


415
01:07:51,610 --> 01:08:00,100


416
01:08:00,100 --> 01:08:03,940


417
01:08:03,940 --> 01:08:08,710


418
01:08:08,710 --> 01:08:16,450


419
01:08:16,450 --> 01:08:21,430


420
01:08:21,430 --> 01:08:26,470


421
01:08:26,470 --> 01:08:30,580


422
01:08:30,580 --> 01:08:36,810


423
01:08:36,810 --> 01:08:42,989


424
01:08:44,729 --> 01:08:48,388


425
01:08:48,389 --> 01:08:54,989


426
01:08:57,149 --> 01:09:03,119


427
01:09:03,120 --> 01:09:08,429


428
01:09:08,429 --> 01:09:13,290


429
01:09:13,290 --> 01:09:16,710


430
01:09:16,710 --> 01:09:20,100


431
01:09:20,100 --> 01:09:24,569


432
01:09:24,569 --> 01:09:28,440


433
01:09:30,689 --> 01:09:35,399


434
01:09:35,399 --> 01:09:40,619


435
01:09:40,620 --> 01:09:48,089


436
01:09:48,089 --> 01:09:53,190


437
01:09:53,189 --> 01:09:56,790


438
01:09:56,790 --> 01:10:01,350


439
01:10:01,350 --> 01:10:05,580


440
01:10:05,580 --> 01:10:11,520


441
01:10:11,520 --> 01:10:16,050


442
01:10:16,050 --> 01:10:31,590


443
01:10:31,590 --> 01:10:38,280


444
01:10:38,280 --> 01:10:46,139


445
01:10:46,139 --> 01:10:49,290


446
01:10:49,290 --> 01:11:03,150


447
01:11:03,150 --> 01:11:11,730


448
01:11:11,730 --> 01:11:18,090


449
01:11:18,090 --> 01:11:22,290


450
01:11:22,290 --> 01:11:27,450


451
01:11:27,450 --> 01:11:31,950


452
01:11:31,950 --> 01:11:36,780


453
01:11:36,780 --> 01:11:40,500


454
01:11:40,500 --> 01:11:43,650


455
01:11:43,650 --> 01:11:49,980


456
01:11:49,980 --> 01:11:54,120


457
01:11:54,120 --> 01:11:58,950


458
01:11:58,950 --> 01:12:05,580


459
01:12:05,580 --> 01:12:11,220


460
01:12:11,220 --> 01:12:16,110


461
01:12:18,240 --> 01:12:22,860


462
01:12:22,860 --> 01:12:27,300


463
01:12:27,300 --> 01:12:32,850


464
01:12:32,850 --> 01:12:38,130


465
01:12:38,130 --> 01:12:46,620


466
01:12:46,620 --> 01:12:50,760


467
01:12:50,760 --> 01:12:56,340


468
01:12:56,340 --> 01:13:00,640


469
01:13:00,640 --> 01:13:04,540


470
01:13:04,540 --> 01:13:08,710


471
01:13:08,710 --> 01:13:12,640


472
01:13:12,640 --> 01:13:19,180


473
01:13:19,180 --> 01:13:23,920


474
01:13:23,920 --> 01:13:27,640


475
01:13:27,640 --> 01:13:32,800


476
01:13:32,800 --> 01:13:35,770


477
01:13:35,770 --> 01:13:39,640


478
01:13:39,640 --> 01:13:45,280


479
01:13:47,800 --> 01:13:56,590


480
01:13:56,590 --> 01:14:03,640


481
01:14:03,640 --> 01:14:09,550


482
01:14:09,550 --> 01:14:20,050


483
01:14:20,050 --> 01:14:27,330


484
01:14:27,330 --> 01:14:32,740


485
01:14:32,740 --> 01:14:40,300


486
01:14:40,300 --> 01:14:44,920


487
01:14:44,920 --> 01:14:52,750


488
01:14:52,750 --> 01:15:00,340


489
01:15:00,340 --> 01:15:04,960


490
01:15:04,960 --> 01:15:11,410


491
01:15:11,410 --> 01:15:13,889


492
01:15:13,889 --> 01:15:18,420


493
01:15:18,420 --> 01:15:22,710


494
01:15:22,710 --> 01:15:26,880


495
01:15:26,880 --> 01:15:38,429


496
01:15:38,429 --> 01:15:41,940


497
01:15:44,460 --> 01:15:51,690


498
01:15:51,690 --> 01:15:58,159


499
01:15:58,159 --> 01:16:02,820


500
01:16:02,820 --> 01:16:08,219


501
01:16:08,219 --> 01:16:13,260


502
01:16:13,260 --> 01:16:18,179


503
01:16:18,179 --> 01:16:21,600


504
01:16:21,600 --> 01:16:25,889


505
01:16:25,889 --> 01:16:29,850


506
01:16:29,850 --> 01:16:36,449


507
01:16:38,969 --> 01:16:46,830


508
01:16:46,830 --> 01:16:50,850


509
01:16:50,850 --> 01:16:55,560


510
01:16:55,560 --> 01:17:00,389


511
01:17:00,389 --> 01:17:06,690


512
01:17:08,940 --> 01:17:13,800


513
01:17:13,800 --> 01:17:19,650


514
01:17:21,900 --> 01:17:27,110


515
01:17:27,110 --> 01:17:36,770


516
01:17:36,770 --> 01:17:43,450


517
01:17:46,130 --> 01:17:52,840


518
01:17:52,840 --> 01:17:58,880


519
01:17:58,880 --> 01:18:05,300


520
01:18:05,300 --> 01:18:13,540


521
01:18:13,540 --> 01:18:22,180


522
01:18:22,180 --> 01:18:27,710


523
01:18:27,710 --> 01:18:34,040


524
01:18:34,040 --> 01:18:39,980


525
01:18:39,980 --> 01:18:45,170


526
01:18:45,170 --> 01:18:52,180


527
01:18:52,180 --> 01:18:58,640


528
01:18:58,640 --> 01:19:01,700


529
01:19:05,120 --> 01:19:10,130


530
01:19:10,130 --> 01:19:14,810


531
01:19:14,810 --> 01:19:18,590


532
01:19:18,590 --> 01:19:22,580


533
01:19:22,580 --> 01:19:29,240


534
01:19:29,240 --> 01:19:37,820


535
01:19:37,820 --> 01:19:44,150


536
01:19:44,150 --> 01:19:51,800


537
01:19:51,800 --> 01:19:56,210


538
01:19:56,210 --> 01:20:02,270


539
01:20:02,270 --> 01:20:07,280


540
01:20:10,460 --> 01:20:15,320


541
01:20:15,320 --> 01:20:19,280


542
01:20:19,280 --> 01:20:26,420


543
01:20:26,420 --> 01:20:31,340


544
01:20:31,340 --> 01:20:38,420


545
01:20:38,420 --> 01:20:43,550


546
01:20:43,550 --> 01:20:47,900


547
01:20:49,460 --> 01:20:55,040


548
01:20:55,040 --> 01:21:06,370


549
01:21:06,370 --> 01:21:15,310


550
01:21:15,310 --> 01:21:24,620


551
01:21:27,920 --> 01:21:31,820


552
01:21:31,820 --> 01:21:35,960


553
01:21:35,960 --> 01:21:43,190


554
01:21:43,190 --> 01:21:51,599


555
01:21:51,599 --> 01:22:01,320


556
01:22:01,320 --> 01:22:10,050


557
01:22:10,050 --> 01:22:17,929


558
01:22:18,050 --> 01:22:27,650


559
01:22:31,290 --> 01:22:39,210


560
01:22:39,210 --> 01:22:50,099


561
01:22:50,099 --> 01:22:57,239


562
01:23:00,480 --> 01:23:08,010


563
01:23:08,010 --> 01:23:12,090


564
01:23:12,090 --> 01:23:18,000


565
01:23:18,000 --> 01:23:25,020


566
01:23:25,020 --> 01:23:30,300


567
01:23:30,300 --> 01:23:37,349


568
01:23:37,349 --> 01:23:43,889


569
01:23:43,889 --> 01:23:54,869


570
01:23:54,869 --> 01:24:00,989


571
01:24:00,989 --> 01:24:05,190


572
01:24:05,190 --> 01:24:09,360


573
01:24:09,360 --> 01:24:14,100


574
01:24:14,100 --> 01:24:21,270


575
01:24:21,270 --> 01:24:27,690


576
01:24:31,290 --> 01:24:37,230


577
01:24:37,230 --> 01:24:41,760


578
01:24:41,760 --> 01:24:46,020


579
01:24:46,020 --> 01:24:52,680


580
01:24:52,680 --> 01:24:57,750


581
01:24:57,750 --> 01:25:01,770


582
01:25:01,770 --> 01:25:11,160


583
01:25:14,250 --> 01:25:18,570


584
01:25:18,570 --> 01:25:21,810


585
01:25:21,810 --> 01:25:28,469


586
01:25:28,469 --> 01:25:32,820


587
01:25:32,820 --> 01:25:38,550


588
01:25:38,550 --> 01:25:41,670


589
01:25:41,670 --> 01:25:47,100


590
01:25:47,100 --> 01:25:52,320


591
01:25:56,300 --> 01:26:01,580


592
01:26:01,580 --> 01:26:07,980


593
01:26:07,980 --> 01:26:14,160


594
01:26:14,160 --> 01:26:16,199


595
01:26:16,199 --> 01:26:20,550


596
01:26:20,550 --> 01:26:26,070


597
01:26:28,220 --> 01:26:34,950


598
01:26:34,950 --> 01:26:42,630


599
01:26:42,630 --> 01:26:45,690


600
01:26:48,030 --> 01:26:52,890


601
01:26:52,890 --> 01:26:57,660


602
01:27:00,810 --> 01:27:05,280


603
01:27:08,130 --> 01:27:14,610


604
01:27:14,610 --> 01:27:20,340


605
01:27:20,340 --> 01:27:25,860


606
01:27:27,840 --> 01:27:31,800


607
01:27:31,800 --> 01:27:38,100


608
01:27:38,100 --> 01:27:48,600


609
01:27:48,600 --> 01:27:54,810


610
01:27:54,810 --> 01:27:59,820


611
01:28:02,490 --> 01:28:07,830


612
01:28:07,830 --> 01:28:12,270


613
01:28:12,270 --> 01:28:18,570


614
01:28:24,420 --> 01:28:30,750


615
01:28:30,750 --> 01:28:34,619


616
01:28:34,619 --> 01:28:40,789


617
01:28:40,789 --> 01:28:46,590


618
01:28:46,590 --> 01:28:51,269


619
01:28:51,269 --> 01:28:59,309


620
01:28:59,309 --> 01:29:03,030


621
01:29:03,030 --> 01:29:10,230


622
01:29:10,230 --> 01:29:15,599


623
01:29:15,599 --> 01:29:23,519


624
01:29:23,519 --> 01:29:26,429


625
01:29:26,429 --> 01:29:30,960


626
01:29:30,960 --> 01:29:35,699


627
01:29:35,699 --> 01:29:50,789


628
01:29:50,789 --> 01:29:55,110


629
01:29:55,110 --> 01:29:57,389


630
01:29:57,389 --> 01:30:01,499


631
01:30:01,499 --> 01:30:06,269


632
01:30:06,269 --> 01:30:10,920


633
01:30:10,920 --> 01:30:15,420


634
01:30:15,420 --> 01:30:22,019


635
01:30:22,019 --> 01:30:24,960


636
01:30:24,960 --> 01:30:30,869


637
01:30:30,869 --> 01:30:36,150


638
01:30:36,150 --> 01:30:43,349


639
01:30:43,349 --> 01:30:51,000


640
01:30:51,000 --> 01:30:57,620


641
01:31:00,770 --> 01:31:08,489


642
01:31:12,570 --> 01:31:18,510


643
01:31:18,510 --> 01:31:22,830


644
01:31:22,830 --> 01:31:28,320


645
01:31:28,320 --> 01:31:31,710


646
01:31:31,710 --> 01:31:39,210


647
01:31:39,210 --> 01:31:48,630


648
01:31:48,630 --> 01:31:53,520


649
01:31:53,520 --> 01:32:08,790


650
01:32:18,630 --> 01:32:24,719


651
01:32:24,719 --> 01:32:31,469


652
01:32:31,469 --> 01:32:37,590


653
01:32:37,590 --> 01:32:42,780


654
01:32:42,780 --> 01:32:47,010


655
01:32:47,010 --> 01:32:52,230


656
01:32:53,790 --> 01:32:57,989


657
01:32:57,989 --> 01:33:02,500


658
01:33:02,500 --> 01:33:08,710


659
01:33:08,710 --> 01:33:12,040


660
01:33:12,040 --> 01:33:15,880


661
01:33:15,880 --> 01:33:27,000


662
01:33:27,000 --> 01:33:34,870


663
01:33:34,870 --> 01:33:42,220


664
01:33:42,220 --> 01:33:49,330


665
01:33:49,330 --> 01:33:54,160


666
01:33:54,160 --> 01:34:03,220


667
01:34:03,220 --> 01:34:08,110


668
01:34:11,200 --> 01:34:16,030


669
01:34:16,030 --> 01:34:20,560


670
01:34:20,560 --> 01:34:23,770


671
01:34:23,770 --> 01:34:30,040


672
01:34:30,430 --> 01:34:37,270


673
01:34:37,270 --> 01:34:45,330


674
01:34:48,400 --> 01:34:54,460


675
01:34:54,460 --> 01:35:09,160


676
01:35:09,160 --> 01:35:18,290


677
01:35:18,290 --> 01:35:23,630


678
01:35:23,630 --> 01:35:27,410


679
01:35:27,410 --> 01:35:32,180


680
01:35:32,180 --> 01:35:38,300


681
01:35:38,300 --> 01:35:45,650


682
01:35:47,450 --> 01:35:53,060


683
01:35:53,060 --> 01:36:03,740


684
01:36:06,500 --> 01:36:13,820


685
01:36:13,820 --> 01:36:18,440


686
01:36:18,440 --> 01:36:24,670


687
01:36:24,670 --> 01:36:27,850


688
01:36:27,880 --> 01:36:34,430


689
01:36:34,430 --> 01:36:37,940


690
01:36:41,390 --> 01:36:47,240


691
01:36:51,710 --> 01:36:54,860


692
01:36:54,860 --> 01:37:02,950


693
01:37:02,950 --> 01:37:10,460


694
01:37:10,460 --> 01:37:15,050


695
01:37:15,050 --> 01:37:20,330


696
01:37:20,330 --> 01:37:24,410


697
01:37:24,410 --> 01:37:33,019


698
01:37:33,019 --> 01:37:40,129


699
01:37:40,129 --> 01:37:45,769


700
01:37:45,769 --> 01:37:49,760


701
01:37:49,760 --> 01:37:57,049


702
01:37:57,049 --> 01:38:05,599


703
01:38:05,599 --> 01:38:09,969


704
01:38:09,969 --> 01:38:18,129


705
01:38:18,129 --> 01:38:23,059


706
01:38:23,059 --> 01:38:26,419


707
01:38:26,419 --> 01:38:30,769


708
01:38:30,769 --> 01:38:40,969


709
01:38:40,969 --> 01:38:46,219


710
01:38:46,219 --> 01:38:51,229


711
01:38:51,229 --> 01:38:59,089


712
01:38:59,089 --> 01:39:03,349


713
01:39:03,349 --> 01:39:07,399


714
01:39:07,399 --> 01:39:11,749


715
01:39:13,999 --> 01:39:18,469


716
01:39:18,469 --> 01:39:24,049


717
01:39:24,049 --> 01:39:30,530


718
01:39:30,530 --> 01:39:34,609


719
01:39:34,609 --> 01:39:39,570


720
01:39:43,530 --> 01:39:47,760


721
01:39:47,760 --> 01:39:51,540


722
01:39:51,540 --> 01:39:56,430


723
01:39:56,430 --> 01:40:00,540


724
01:40:00,540 --> 01:40:03,240


725
01:40:03,240 --> 01:40:08,910


726
01:40:08,910 --> 01:40:14,220


727
01:40:14,220 --> 01:40:18,390


728
01:40:18,390 --> 01:40:23,460


729
01:40:23,460 --> 01:40:29,490


730
01:40:29,490 --> 01:40:33,660


731
01:40:33,660 --> 01:40:36,780


732
01:40:36,780 --> 01:40:41,970


733
01:40:41,970 --> 01:40:47,640


734
01:40:47,640 --> 01:40:51,810


735
01:40:51,810 --> 01:40:58,080


736
01:41:01,710 --> 01:41:07,680


737
01:41:07,680 --> 01:41:13,620


738
01:41:13,620 --> 01:41:20,010


739
01:41:20,010 --> 01:41:29,010


740
01:41:29,010 --> 01:41:36,240


741
01:41:36,240 --> 01:41:42,020


742
01:41:42,890 --> 01:41:49,950


743
01:41:52,040 --> 01:41:56,050


744
01:41:56,050 --> 01:42:02,770


745
01:42:02,770 --> 01:42:06,969


746
01:42:06,969 --> 01:42:13,630


747
01:42:13,630 --> 01:42:22,090


748
01:42:22,090 --> 01:42:26,890


749
01:42:26,890 --> 01:42:33,580


750
01:42:33,580 --> 01:42:38,380


751
01:42:38,380 --> 01:42:45,850


752
01:42:45,850 --> 01:42:52,719


753
01:42:52,719 --> 01:43:03,100


754
01:43:03,100 --> 01:43:07,989


755
01:43:09,790 --> 01:43:14,739


756
01:43:14,739 --> 01:43:21,400


757
01:43:21,400 --> 01:43:24,250


758
01:43:24,250 --> 01:43:28,480


759
01:43:28,480 --> 01:43:37,870


760
01:43:37,870 --> 01:43:42,880


761
01:43:42,880 --> 01:43:47,199


762
01:43:49,060 --> 01:43:54,310


763
01:43:54,310 --> 01:43:59,260


764
01:43:59,260 --> 01:44:07,000


765
01:44:07,000 --> 01:44:14,200


766
01:44:14,200 --> 01:44:24,640


767
01:44:24,640 --> 01:44:29,020


768
01:44:29,020 --> 01:44:35,860


769
01:44:39,760 --> 01:44:43,060


770
01:44:43,060 --> 01:44:47,830


771
01:44:51,960 --> 01:44:56,380


772
01:44:56,380 --> 01:45:00,640


773
01:45:00,640 --> 01:45:04,240


774
01:45:06,430 --> 01:45:10,840


775
01:45:10,840 --> 01:45:15,580


776
01:45:15,580 --> 01:45:19,720


777
01:45:19,720 --> 01:45:23,530


778
01:45:28,270 --> 01:45:34,270


779
01:45:34,270 --> 01:45:40,150


780
01:45:41,500 --> 01:45:46,600


781
01:45:46,600 --> 01:45:53,050


782
01:45:53,050 --> 01:46:02,920


783
01:46:02,920 --> 01:46:10,720


784
01:46:10,720 --> 01:46:17,550


785
01:46:17,550 --> 01:46:22,450


786
01:46:22,450 --> 01:46:26,380


787
01:46:26,380 --> 01:46:33,670


788
01:46:33,670 --> 01:46:42,160


789
01:46:42,160 --> 01:46:45,100


790
01:46:45,100 --> 01:47:00,940


791
01:47:02,170 --> 01:47:06,940


792
01:47:10,960 --> 01:47:13,330


793
01:47:13,330 --> 01:47:17,860


794
01:47:17,860 --> 01:47:23,020


795
01:47:23,020 --> 01:47:25,690


796
01:47:28,150 --> 01:47:36,310


797
01:47:36,310 --> 01:47:43,810


798
01:47:43,810 --> 01:47:47,020


799
01:47:47,020 --> 01:47:56,440


800
01:47:59,170 --> 01:48:03,910


801
01:48:03,910 --> 01:48:10,240


802
01:48:10,240 --> 01:48:16,270


803
01:48:16,270 --> 01:48:23,050


804
01:48:23,050 --> 01:48:27,790


805
01:48:27,790 --> 01:48:31,750


806
01:48:31,750 --> 01:48:34,929


807
01:48:34,929 --> 01:48:39,429


808
01:48:39,429 --> 01:48:43,540


809
01:48:43,540 --> 01:48:48,010


810
01:48:48,010 --> 01:48:54,400


811
01:48:57,520 --> 01:49:03,159


812
01:49:05,079 --> 01:49:09,610


813
01:49:09,610 --> 01:49:14,020


814
01:49:14,020 --> 01:49:19,510


815
01:49:19,510 --> 01:49:23,860


816
01:49:25,480 --> 01:49:28,599


817
01:49:28,599 --> 01:49:33,880


818
01:49:33,880 --> 01:49:38,790


819
01:49:38,790 --> 01:49:45,130


820
01:49:45,130 --> 01:49:48,550


821
01:49:48,550 --> 01:49:52,090


822
01:49:52,090 --> 01:49:55,420


823
01:49:55,420 --> 01:49:59,710


824
01:49:59,710 --> 01:50:05,469


825
01:50:05,469 --> 01:50:10,719


826
01:50:10,719 --> 01:50:17,139


827
01:50:17,139 --> 01:50:22,239


828
01:50:24,670 --> 01:50:28,060


829
01:50:28,060 --> 01:50:37,300


830
01:50:37,300 --> 01:50:45,219


831
01:50:45,219 --> 01:50:52,239


832
01:50:56,349 --> 01:51:02,530


833
01:51:02,530 --> 01:51:09,099


834
01:51:09,099 --> 01:51:11,800


835
01:51:11,800 --> 01:51:17,590


836
01:51:17,590 --> 01:51:26,170


837
01:51:26,170 --> 01:51:32,559


838
01:51:32,559 --> 01:51:41,139


839
01:51:41,139 --> 01:51:48,849


840
01:51:48,849 --> 01:51:56,440


841
01:51:59,050 --> 01:52:06,070


842
01:52:10,420 --> 01:52:13,809


843
01:52:13,809 --> 01:52:19,570


844
01:52:22,989 --> 01:52:32,070


845
01:52:32,070 --> 01:52:40,989


846
01:52:40,989 --> 01:52:45,550


847
01:52:45,550 --> 01:52:49,690


848
01:52:53,769 --> 01:52:58,990


849
01:52:58,990 --> 01:53:05,170


850
01:53:05,170 --> 01:53:12,220


851
01:53:12,220 --> 01:53:19,750


852
01:53:19,750 --> 01:53:30,610


853
01:53:30,610 --> 01:53:35,410


854
01:53:35,410 --> 01:53:40,180


855
01:53:40,180 --> 01:53:51,850


856
01:53:51,850 --> 01:53:56,830


857
01:53:56,830 --> 01:54:01,260


858
01:54:01,260 --> 01:54:11,350


859
01:54:11,350 --> 01:54:16,510


860
01:54:16,510 --> 01:54:21,430


861
01:54:21,430 --> 01:54:28,810


862
01:54:28,810 --> 01:54:39,340


863
01:54:39,340 --> 01:54:49,660


864
01:54:49,660 --> 01:54:59,110


865
01:54:59,110 --> 01:55:03,850


866
01:55:03,850 --> 01:55:13,020


867
01:55:13,020 --> 01:55:26,800


868
01:55:26,800 --> 01:55:32,650


869
01:55:35,830 --> 01:55:41,740


870
01:55:41,740 --> 01:55:48,940


871
01:55:48,940 --> 01:55:55,600


872
01:55:55,600 --> 01:56:03,280


873
01:56:08,080 --> 01:56:14,200


874
01:56:14,200 --> 01:56:18,790


875
01:56:18,790 --> 01:56:24,100


876
01:56:24,100 --> 01:56:28,300


877
01:56:28,300 --> 01:56:32,140


878
01:56:32,140 --> 01:56:35,680


879
01:56:35,680 --> 01:56:40,240


880
01:56:41,950 --> 01:56:46,810


881
01:56:46,810 --> 01:56:51,700


882
01:56:57,340 --> 01:57:04,300


883
01:57:04,300 --> 01:57:11,950


884
01:57:11,950 --> 01:57:22,620


885
01:57:26,160 --> 01:57:31,660


886
01:57:31,660 --> 01:57:38,710


887
01:57:38,710 --> 01:57:41,680


888
01:57:41,680 --> 01:57:45,910


889
01:57:45,910 --> 01:57:50,800


890
01:57:50,800 --> 01:57:55,300


891
01:57:55,300 --> 01:57:59,170


892
01:57:59,170 --> 01:58:03,330


893
01:58:03,330 --> 01:58:08,140


894
01:58:08,140 --> 01:58:12,160


895
01:58:13,750 --> 01:58:21,670


896
01:58:21,670 --> 01:58:26,230


897
01:58:37,930 --> 01:58:44,740


898
01:58:46,960 --> 01:58:58,000


899
01:58:58,000 --> 01:59:03,240


900
01:59:03,720 --> 01:59:18,220


901
01:59:18,220 --> 01:59:22,720


902
01:59:22,720 --> 01:59:25,690


903
01:59:29,020 --> 01:59:36,690


904
01:59:38,489 --> 01:59:41,700


905
01:59:41,700 --> 01:59:46,440


906
01:59:46,440 --> 01:59:50,670


907
01:59:50,670 --> 01:59:56,880


908
01:59:56,880 --> 02:00:00,330


909
02:00:00,330 --> 02:00:08,640


910
02:00:08,640 --> 02:00:14,730


911
02:00:17,310 --> 02:00:22,200


912
02:00:24,750 --> 02:00:31,170


913
02:00:31,170 --> 02:00:36,390


914
02:00:36,390 --> 02:00:43,710


915
02:00:43,710 --> 02:00:49,560


916
02:00:49,560 --> 02:00:53,660


917
02:00:58,830 --> 02:01:04,560


918
02:01:04,560 --> 02:01:09,690


919
02:01:13,920 --> 02:01:19,020


920
02:01:19,020 --> 02:01:25,230


921
02:01:28,290 --> 02:01:34,110


922
02:01:34,110 --> 02:01:42,960


923
02:01:42,960 --> 02:01:49,989


924
02:01:56,739 --> 02:02:00,400


925
02:02:00,400 --> 02:02:05,650


926
02:02:05,650 --> 02:02:12,730


927
02:02:12,730 --> 02:02:19,300


928
02:02:19,300 --> 02:02:25,690


929
02:02:28,750 --> 02:02:36,550


930
02:02:36,550 --> 02:02:41,680


931
02:02:41,680 --> 02:02:48,610


932
02:02:52,920 --> 02:03:00,610


933
02:03:00,610 --> 02:03:07,210


934
02:03:07,210 --> 02:03:13,210


935
02:03:13,210 --> 02:03:22,420


936
02:03:22,420 --> 02:03:28,780


937
02:03:28,780 --> 02:03:34,090


938
02:03:34,090 --> 02:03:37,630


939
02:03:37,630 --> 02:03:42,130


940
02:03:42,130 --> 02:03:47,830


941
02:03:47,830 --> 02:03:53,370


942
02:04:00,180 --> 02:04:10,380


943
02:04:10,380 --> 02:04:14,980


944
02:04:16,210 --> 02:04:22,360


945
02:04:22,360 --> 02:04:31,900


946
02:04:31,900 --> 02:04:36,489


947
02:04:36,489 --> 02:04:40,930


948
02:04:40,930 --> 02:04:47,290


949
02:04:47,290 --> 02:04:52,390


950
02:04:52,390 --> 02:04:58,120


951
02:04:58,120 --> 02:05:02,770


952
02:05:02,770 --> 02:05:09,190


953
02:05:11,949 --> 02:05:15,280


954
02:05:15,280 --> 02:05:22,840


955
02:05:22,840 --> 02:05:28,180


956
02:05:28,180 --> 02:05:33,730


957
02:05:35,890 --> 02:05:39,670


958
02:05:39,670 --> 02:05:44,080


959
02:05:44,080 --> 02:05:50,620


960
02:05:50,620 --> 02:05:55,090


961
02:05:55,090 --> 02:05:59,440


962
02:06:00,820 --> 02:06:06,850


963
02:06:06,850 --> 02:06:11,020


964
02:06:11,020 --> 02:06:15,580


965
02:06:17,260 --> 02:06:21,730


966
02:06:24,400 --> 02:06:30,340


967
02:06:30,340 --> 02:06:37,540


968
02:06:37,540 --> 02:06:42,370


969
02:06:42,370 --> 02:06:49,320


970
02:06:49,320 --> 02:06:55,300


971
02:06:55,300 --> 02:06:58,750


972
02:06:58,750 --> 02:07:04,060


973
02:07:04,060 --> 02:07:09,550


974
02:07:09,550 --> 02:07:14,980


975
02:07:16,840 --> 02:07:22,630


976
02:07:22,630 --> 02:07:26,980


977
02:07:28,510 --> 02:07:34,870


978
02:07:34,870 --> 02:07:41,320


979
02:07:41,320 --> 02:07:46,210


980
02:07:46,210 --> 02:07:53,260


981
02:07:53,260 --> 02:07:56,650


982
02:07:59,290 --> 02:08:03,480


983
02:08:03,480 --> 02:08:09,760


984
02:08:09,760 --> 02:08:13,120


985
02:08:13,120 --> 02:08:18,100


986
02:08:18,100 --> 02:08:22,240


987
02:08:24,700 --> 02:08:29,650


988
02:08:29,650 --> 02:08:33,010


989
02:08:33,010 --> 02:08:37,720


990
02:08:37,720 --> 02:08:43,060


991
02:08:43,060 --> 02:08:48,550


992
02:08:48,550 --> 02:08:55,030


993
02:08:55,030 --> 02:08:58,840


994
02:08:58,840 --> 02:09:04,660


995
02:09:04,660 --> 02:09:09,940


996
02:09:09,940 --> 02:09:13,540


997
02:09:13,540 --> 02:09:18,660


998
02:09:19,830 --> 02:09:25,000


999
02:09:25,000 --> 02:09:31,480


1000
02:09:31,480 --> 02:09:35,140


1001
02:09:35,140 --> 02:09:42,100


1002
02:09:42,100 --> 02:09:48,370


1003
02:09:50,500 --> 02:09:56,500


1004
02:09:56,500 --> 02:10:00,670


1005
02:10:00,670 --> 02:10:03,790


1006
02:10:03,790 --> 02:10:15,430


1007
02:10:15,430 --> 02:10:21,310


1008
02:10:21,310 --> 02:10:26,770


1009
02:10:26,770 --> 02:10:29,590


1010
02:10:29,590 --> 02:10:35,500


1011
02:10:35,500 --> 02:10:38,610


1012
02:10:38,610 --> 02:10:45,930


1013
02:10:45,930 --> 02:10:50,880


1014
02:10:50,880 --> 02:10:57,720


1015
02:10:57,720 --> 02:11:02,850


1016
02:11:02,850 --> 02:11:12,750


1017
02:11:12,750 --> 02:11:19,860


1018
02:11:19,860 --> 02:11:27,480


1019
02:11:27,480 --> 02:11:34,739


1020
02:11:34,739 --> 02:11:39,510


1021
02:11:39,510 --> 02:11:46,440


1022
02:11:48,570 --> 02:11:54,330


1023
02:11:54,330 --> 02:11:57,989


1024
02:11:57,989 --> 02:12:03,360


1025
02:12:03,360 --> 02:12:08,910


1026
02:12:08,910 --> 02:12:14,100


1027
02:12:14,100 --> 02:12:19,140


1028
02:12:19,140 --> 02:12:23,400


1029
02:12:26,130 --> 02:12:32,880


1030
02:12:32,880 --> 02:12:39,270


1031
02:12:39,270 --> 02:12:49,619


1032
02:12:55,960 --> 02:13:04,840


1033
02:13:04,840 --> 02:13:10,750


1034
02:13:10,750 --> 02:13:15,909


1035
02:13:15,909 --> 02:13:19,630


1036
02:13:19,630 --> 02:13:24,219


1037
02:13:24,219 --> 02:13:31,719


1038
02:13:31,719 --> 02:13:39,159


1039
02:13:39,159 --> 02:13:47,679


1040
02:13:47,679 --> 02:13:52,150


1041
02:13:52,150 --> 02:13:57,550


1042
02:13:57,550 --> 02:14:02,770


1043
02:14:02,770 --> 02:14:07,210


1044
02:14:07,210 --> 02:14:14,469


1045
02:14:14,469 --> 02:14:21,780


1046
02:14:21,780 --> 02:14:28,809


1047
02:14:28,809 --> 02:14:35,829


1048
02:14:38,139 --> 02:14:42,940


1049
02:14:46,929 --> 02:14:53,559


1050
02:14:53,559 --> 02:14:56,920


1051
02:14:56,920 --> 02:15:02,739


1052
02:15:03,070 --> 02:15:09,580


1053
02:15:09,580 --> 02:15:15,460


1054
02:15:15,460 --> 02:15:22,000


1055
02:15:22,000 --> 02:15:28,480


1056
02:15:28,480 --> 02:15:32,110


1057
02:15:32,110 --> 02:15:36,400


1058
02:15:36,400 --> 02:15:40,300


1059
02:15:40,300 --> 02:15:47,410


1060
02:15:47,410 --> 02:15:51,970


1061
02:15:51,970 --> 02:15:57,340


1062
02:15:57,340 --> 02:16:01,960


1063
02:16:01,960 --> 02:16:11,440


1064
02:16:11,440 --> 02:16:17,410


1065
02:16:17,410 --> 02:16:26,950


1066
02:16:26,950 --> 02:16:34,510


1067
02:16:34,510 --> 02:16:40,150


1068
02:16:40,150 --> 02:16:46,540


1069
02:16:46,540 --> 02:16:53,200


1070
02:16:53,200 --> 02:16:57,460


1071
02:16:59,170 --> 02:17:03,130


1072
02:17:03,129 --> 02:17:05,550


1073
02:17:06,620 --> 02:17:11,460


1074
02:17:12,660 --> 02:17:21,420


1075
02:17:21,420 --> 02:17:27,030


1076
02:17:27,030 --> 02:17:32,640


1077
02:17:35,280 --> 02:17:40,350


1078
02:17:40,350 --> 02:17:46,080


1079
02:17:46,080 --> 02:17:50,340


1080
02:17:50,340 --> 02:17:57,120


1081
02:17:57,120 --> 02:18:00,480


1082
02:18:02,459 --> 02:18:06,149


1083
02:18:06,150 --> 02:18:10,680


1084
02:18:10,680 --> 02:18:17,280


1085
02:18:17,280 --> 02:18:21,060


1086
02:18:23,309 --> 02:18:26,969


1087
02:18:26,969 --> 02:18:32,219


1088
02:18:32,219 --> 02:18:39,439

