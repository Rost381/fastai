1
00:00:00,030 --> 00:00:05,784
Добро пожаловать на пятую лекцию.

2
00:00:05,884 --> 00:00:27,834
Один из студентов магистратуры нашего университета написал пост про анализ структурированных данных по нашему курсу.

3
00:00:27,934 --> 00:00:37,824
Пост оказался очень популярным, как я и ожидал. Его опубликовали на сайте towardsdatascience.com,

4
00:00:37,924 --> 00:00:46,840
это неплохой ресурс для тех, кто интересуется новостями анализа данных.

5
00:00:46,940 --> 00:00:58,195
Автор поста — Kerem Turgutlu. Его пост содержит основные идеи с последней лекции.

6
00:00:58,295 --> 00:01:05,452
Sebastian Ruder, которого я уже упоминал на прошлой неделе как одного из моих любимых исследователей,

7
00:01:05,552 --> 00:01:16,590
поделился ссылкой на этот пост, а кто-то из Stitch Fix ответил, что они давно такое умеют.

8
00:01:16,590 --> 00:01:23,125
Я знаю, что в индустрии многие занимаются анализом структурированных данных, но про это никто не пишет.

9
00:01:23,225 --> 00:01:31,509
Тут Kerem публикует пост, и Stitch Fix сразу отвечает — «ну, ничего нового».

10
00:01:31,609 --> 00:01:46,310
Я был рад этому посту, и думаю, что на эту тему можно ещё много написать — например, про работу с различными датасетами,

11
00:01:46,410 --> 00:01:57,429
или анализ старых соревнований Kaggle, которые можно или нельзя было бы выиграть с современными инструментами.

12
00:01:57,529 --> 00:02:13,970
Было бы интересно почитать про различные характеристики дропаута, я не видел про это статей.

13
00:02:13,970 --> 00:02:21,950
Я думаю, тут большой потенциал для развития. Кто-то в Twitter ответил на пост фразой «Я столько лет искал эту информацию!».

14
00:02:25,310 --> 00:02:36,940
Nikhil B, чьи классификаторы игроков в бейсбол или крикет и изображения купюр я упоминал после первой лекции,

15
00:02:36,940 --> 00:02:54,545
скачал из Google пару сотен фотографий актёров в очках и без очков, разметил их вручную и обучил классификатор.

16
00:02:54,645 --> 00:03:06,724
Архитектура ResNet работала плохо, поэтому он экспериментировал с разморозкой слоёв

17
00:03:06,824 --> 00:03:11,440
и дифференциальными скоростями обучения, и достиг доли правильных ответов в 100%.

18
00:03:11,709 --> 00:03:22,590
Мне нравится, что он выбрал реальную задачу — изображения из Google, а не размеченный датасет с Kaggle.

19
00:03:22,690 --> 00:03:30,930
В его посте есть ссылка на удобный инструмент для скачивания изображений из Google.

20
00:03:31,030 --> 00:03:41,379
Сегодня я выступал в Университете Сингулярности перед топ-менеджерами одной из крупнейших телекоммуникационных компаний.

21
00:03:41,479 --> 00:03:56,220
Их поставщики убеждали их собирать миллионы изображений, приобретать высокие вычислительные мощности и специальные программы.

22
00:03:56,320 --> 00:04:03,960
Я показал им этот пост и сказал — «Вот чего достиг человек после трёх недель обучения на машине за 60 центов в час».

23
00:04:04,060 --> 00:04:13,140
Они были очень рады, узнав, что такое доступно обычным людям.

24
00:04:13,240 --> 00:04:20,030
Я предполагаю, что Nikhil — обычный человек, прошу прощения, если ненароком его обидел.

25
00:04:20,129 --> 00:04:31,650
Я посмотрел на его классификатор игроков в крикет. Этот код совпадает с кодом с первой лекции за исключением количества эпох.

26
00:04:31,750 --> 00:04:42,852
Я надеялся, что так случится. Это доказывает, что эти четыре строки — полезный инструмент.

27
00:04:42,952 --> 00:04:50,894
Показывайте эти результаты топ-менеджерам своих компаний.

28
00:04:50,994 --> 00:05:04,820
Они будут сомневаться и говорить вам — «Если так можно, почему нам никто до сих пор этого не сказал?»,

29
00:05:04,820 --> 00:05:15,885
поэтому вам придётся продемонстрировать это на собственных примерах, например, данных вашей компании.

30
00:05:15,985 --> 00:05:28,700
Vitaly Bushaev написал введение в обучение нейронных сетей.

31
00:05:28,700 --> 00:05:40,340
У него хороший слог и умение объяснять сложные вещи простым языком, берите с него пример.

32
00:05:43,280 --> 00:05:52,220
Автор начинает с азов, но читатель понимает, что его не принимают за дурака —

33
00:05:52,220 --> 00:06:03,610
за каждым уравнением следует подробное объяснение того, что всё это значит.

34
00:06:03,710 --> 00:06:11,450
Автору удаётся сочетать уважение к читателям и принимать отсутствие у них изначальных знаний в данной области.

35
00:06:11,450 --> 00:06:21,480
На этой неделе я запостил скриншот рейтинга соревнования Plant Seedlings Classification на Kaggle, где занимал первое место.

36
00:06:21,580 --> 00:06:31,025
Это было ошибкой, потому что к текущему моменту уже пятеро студентов нашего курса обогнали меня в этом рейтинге.

37
00:06:31,125 --> 00:06:41,870
Это текущий рейтинг соревнования, первые пять результатов — студенты курса fast.ai, шестой — преподаватель курса.

38
00:06:41,970 --> 00:07:06,212
Датасет состоит из нескольких тысяч изображений, размер большинства которых меньше 100x100.

39
00:07:06,312 --> 00:07:16,115
Для своего результата я просто последовательно выполнил ячейки Jupyter ноутбука, это заняло где-то час.

40
00:07:16,215 --> 00:07:23,170
Я думаю, эти студенты в рейтинге сделали немного больше, но не сильно.

41
00:07:23,170 --> 00:07:48,520
Как видно, стандартные средства библиотеки fastai дают хорошие результаты без особых усилий.

42
00:07:48,520 --> 00:07:55,510
Сегодня мы перейдём ко второй половине первой части курса.

43
00:07:55,510 --> 00:08:09,067
В первой половине мы пробежались по основным темам, поняли, как создавать соответствующие модели,

44
00:08:09,167 --> 00:08:13,590
и получили примерное представление о том, как они работают.

45
00:08:17,830 --> 00:08:27,245
Сейчас мы пройдёмся по этим темам снова, но уже углублённо, разбираясь во всех деталях

46
00:08:27,345 --> 00:08:35,590
и читая исходный код библиотеки fastai для того, чтобы повторить все шаги.

47
00:08:35,590 --> 00:08:45,370
К текущему моменту я показал вам лучшие из известных мне практик, мы пока отойдём от этого.

48
00:08:45,370 --> 00:08:52,085
Я думаю, что перед тем, как изучать новые техники во второй части курса, важно понять,

49
00:08:52,185 --> 00:08:58,780
как работает код всего, что мы уже умеем.

50
00:08:58,780 --> 00:09:12,625
Сегодня мы почти с нуля создадим довольно успешную модель коллаборативной фильтрации.

51
00:09:12,725 --> 00:09:19,330
Мы используем PyTorch для дифференцирования и библиотеку для работы с GPU, всё остальное напишем сами.

52
00:09:19,330 --> 00:09:24,977
Мы не будем использовать средства PyTorch для работы с нейронными сетями и постараемся не злоупотреблять средствами fastai.

53
00:09:25,077 --> 00:09:35,800
Мы не успели подробно разобрать коллаборативную фильтрацию на прошлой лекции, давайте к этому вернёмся.

54
00:09:35,800 --> 00:09:45,155
Мы будем работать с датасетом Movielens, это список оценок фильмов.

55
00:09:45,255 --> 00:09:58,900
Пользователи представлены индексом userId, фильмы — индексом movieId, оценки и даты их выставления записаны в столбцах rating и timestamp.

56
00:09:58,900 --> 00:10:12,650
Я никогда не использовал признак timestamp, мы будем использовать признаки userId, movieId и rating.

57
00:10:12,750 --> 00:10:28,410
В терминах структурированных данных признаки userId и movieId — категориальные, а оценка — целевая переменная.

58
00:10:28,410 --> 00:10:35,330
У нас есть таблица названий фильмов, мы не будем использовать их для обучения модели, только для демонстрации её работы.

59
00:10:35,430 --> 00:10:46,089
Здесь также указаны жанры фильмов, я не использую их, кто-нибудь на этой неделе может проверить, прав ли я в этом.

60
00:10:46,089 --> 00:10:55,180
Для того, чтобы посмотреть на датасет, я выбрал пользователей, которые посмотрели больше всего фильмов,

61
00:10:57,880 --> 00:11:03,820
взял самые популярные фильмы и составил перекрёстную таблицу методом pandas.crosstab().

62
00:11:03,820 --> 00:11:12,680
Это подмножество датасета. Строки соответствуют пользователям, столбцы — фильмам, соответствующие оценки — в пересечениях.

63
00:11:12,780 --> 00:11:18,557
Некоторые пользователи не смотрели определённые фильмы, поэтому в таблице есть значения NaN.

64
00:11:18,657 --> 00:11:37,955
Я скопировал эту таблицу в Excel, демонстрация называется collab_filter.xlsx.

65
00:11:38,055 --> 00:12:09,790
Если вы чего-то не понимаете, задавайте вопросы здесь или на форуме. Янет следит за вопросами на форуме.

66
00:12:09,790 --> 00:12:19,803
Сейчас мы переходим к деталям работы, поэтому очень важно, чтобы все всё понимали.

67
00:12:19,903 --> 00:12:47,420
Мы не будем обучать нейронную сеть, а займёмся сначала факторизацией матриц, потому что это простейший способ решить нашу задачу.

68
00:12:47,520 --> 00:12:57,800
Эта матрица предсказаний, построенная по такому же принципу, как и скопированная из Jupyter ноутбука.

69
00:12:57,900 --> 00:13:18,645
Это истинные значения, это предсказания, это — среднеквадратичная ошибка (RMSE) между этими двумя таблицами.

70
00:13:18,745 --> 00:13:25,005
Таблица предсказаний состоит из случайных чисел, функция потерь равна 2.81.

71
00:13:25,105 --> 00:13:41,560
Сейчас я покажу, как мы предсказываем, что пользователь номер 14 оценит фильм номер 27 как 0.91. Пока оценка случайная.

72
00:13:41,560 --> 00:14:05,990
Оценка получается скалярным произведением выделенных векторов.

73
00:14:05,990 --> 00:14:22,509
Красный вектор — матрица размера 1x5, фиолетовый — матрица размера 5x1. Перемножая эти матрицы, получаем предсказание.

74
00:14:22,609 --> 00:14:33,050
Если для какой-то оценки нет истинного значения, мы предсказываем её нулём, чтобы корректно считать функцию потерь.

75
00:14:34,220 --> 00:14:46,149
Наша модель — не нейронная сеть, а просто перемножение двух матриц.

76
00:14:46,249 --> 00:15:04,430
Таблица предсказаний 15x15 получена перемножением левой матрицы 15x5 на верхнюю матрицу 5x15.

77
00:15:04,430 --> 00:15:28,165
Сейчас числа в этих матрицах, то есть начальные веса модели, случайные, а модель — это перемножение этих матриц.

78
00:15:28,265 --> 00:15:43,135
Excel умеет выполнять градиентный спуск, его нужно включить в настройках, и станет доступен Решатель.

79
00:15:43,235 --> 00:16:07,525
В Решатель передаются ячейка с целевой функцией (RMSE) и ячейки с оптимизируемыми значениями (две матрицы).

80
00:16:07,625 --> 00:16:20,110
Решатель меняет числа в матрицах и с помощью градиентного спуска находит значения, минимизирующие целевую функцию.

81
00:16:20,520 --> 00:16:33,985
После запуска Решателя значение целевой функции начинает уменьшаться.

82
00:16:34,085 --> 00:16:43,840
Умножение матриц и градиентный спуск наводят на мысли о нейронных сетях,

83
00:16:43,940 --> 00:16:51,630
но здесь нет нелинейного слоя и второго слоя, поэтому это не глубокое обучение.

84
00:16:51,630 --> 00:17:00,150
Модели, использующие произведения матриц без нелинейных слоёв, называют моделями неглубокого обучения.

85
00:17:01,830 --> 00:17:17,189
Мне надоело ждать, поэтому я остановлю Решатель. Среднеквадратичная ошибка упала с 2.81 до 0.39.

86
00:17:17,189 --> 00:17:36,650
Модель предсказывает, что пользователь 72 поставил фильму 27 оценку 4.4. Истинное значение — 4, как видите, модель работает.

87
00:17:36,650 --> 00:18:11,190
Необходимо предсказать 225 значений, используя 150 параметров, поэтому это не простой подгон, а машинное обучение.

88
00:18:11,190 --> 00:18:23,725
В линейной алгебре такой процесс называется разложением матрицы, это можно было сделать аналитически,

89
00:18:23,825 --> 00:18:29,430
а мы делаем это с помощью градиентного спуска. Градиентный спуск — мощный инструмент.

90
00:18:29,430 --> 00:18:36,960
Я предпочитаю рассматривать это с интуитивной точки зрения, а не с точки зрения линейной алгебры.

91
00:18:36,960 --> 00:18:56,225
Предположим, что фильм номер 27 — это Властелин Колец: Братство Кольца, и мы хотим узнать, понравится ли он пользователю 72.

92
00:18:56,325 --> 00:19:11,250
Фильму соответствует пять чисел. Допустим, первое число говорит, насколько фильм фантастический,

93
00:19:11,250 --> 00:19:21,390
второе — настолько давно он вышел и какие там спецэффекты, пятое — сколько в фильме диалогов.

94
00:19:21,390 --> 00:19:27,820
Пять чисел соответствуют пяти признакам фильма.

95
00:19:27,920 --> 00:19:45,265
Для каждого пользователя можно сказать, насколько он любит фэнтези, спецэффекты и диалоги в фильмах.

96
00:19:45,365 --> 00:19:54,310
Сумма поэлементных произведений чисел пользователя на числа фильма отразит то, понравится ему этот фильм или нет.

97
00:19:54,410 --> 00:20:13,060
У нас нет этих чисел, но мы думаем, что их смысл такой, и градиентный спуск их подбирает.

98
00:20:13,160 --> 00:20:36,030
Эти числа называются скрытые факторы. Они скрытые, потому что мы не выделяли и не называли эти неявные признаки,

99
00:20:36,030 --> 00:20:46,740
а просто предположили, что факторы их отражают. Мы предположили, что оценка фильма может быть получена

100
00:20:46,740 --> 00:20:53,605
перемножением значений каких-то признаков фильма и соответствующих предпочтений пользователя,

101
00:20:53,705 --> 00:21:06,175
и использовали градиентный спуск, чтобы найти значения этих неизвестных признаков.

102
00:21:06,275 --> 00:21:14,889
В этом суть вероятностной факторизации матриц, так работает коллаборативная фильтрация с её применением.

103
00:21:14,989 --> 00:21:26,490
Всё, что мы сделали — инициализировали две случайные матрицы и перемножили их.

104
00:21:26,490 --> 00:21:38,250
Вопрос из зала: Может, надо было отнормировать значения к шкале от 0 до 5?

105
00:21:38,250 --> 00:21:46,380
Да, мы сделаем это и ещё много чего. Это — простейшая версия.

106
00:21:46,380 --> 00:21:50,850
Мы напишем этот алгоритм на Python и запустим на всём датасете.

107
00:21:54,750 --> 00:22:03,050
Вопрос из зала: Как определить размеры матриц?

108
00:22:03,150 --> 00:22:43,220
Эти матрицы — матрицы эмбеддинга, 5 — их ширина. Для фильма 72 мы бы взяли строку номер 72 и получили эти пять чисел.

109
00:22:43,220 --> 00:22:53,780
Вопрос в том, как выбрать ширину матрицы эмбеддинга, и ответ — непонятно, надо пробовать.

110
00:22:53,780 --> 00:23:10,410
Число должно быть достаточно большим, чтобы учесть сложные закономерности, но не слишком большим,

111
00:23:10,510 --> 00:23:17,460
иначе параметров будет слишком много и модель будет очень долго обучаться и может переобучиться.

112
00:23:17,560 --> 00:23:26,865
Вопрос из зала: Что значат отрицательные факторы в матрицах эмбеддинга?

113
00:23:26,965 --> 00:23:34,610
В матрице для фильмов — например, то, что диалогов в фильме мало и они плохие.

114
00:23:34,610 --> 00:23:41,540
В матрице для пользователей — например, то, что пользователь терпеть не может спецэффекты в фильмах.

115
00:23:41,540 --> 00:23:49,645
Вопрос из зала: То есть факторы могут быть любые? Никаких ограничений?

116
00:23:49,745 --> 00:23:54,447
Да, любые, это просто матрицы эмбеддинга.

117
00:23:54,547 --> 00:24:19,340
Вопрос из зала: Почему мы доверяем этим матрицам эмбеддинга?

118
00:24:21,410 --> 00:24:33,380
Мы используем градиентный спуск для подбора факторов. Найдя хороший минимум, мы перестаём в них сомневаться,

119
00:24:33,380 --> 00:24:42,720
так как другие числа будут хуже. Конечно, нужно смотреть на результаты на валидационной выборке, мы будем это делать.

120
00:24:42,820 --> 00:24:50,240
Вопрос из зала: Нужно ли обучать модель заново при появлении нового пользователя или нового фильма?

121
00:24:50,240 --> 00:24:56,365
Очень хороший вопрос, на него нет короткого и быстрого ответа.

122
00:24:56,465 --> 00:25:11,000
Нужна будет немного другая модель, и со временем её придётся дообучать.

123
00:25:11,000 --> 00:25:28,110
Раньше Netflix после регистрации просил указать фильмы, которые вам понравились, и дообучал модель на этих данных.

124
00:25:28,210 --> 00:25:38,895
Вопрос из зала: Можно ли для этого просто найти максимально похожие фильмы?

125
00:25:38,995 --> 00:25:50,685
Да, но для этого нужно построить модель с признаками фильмов — жанр, год выпуска, актёры на главных ролях.

126
00:25:50,785 --> 00:26:05,235
У нас признаки не выделены, поэтому нужно использовать коллаборативную фильтрацию.

127
00:26:07,635 --> 00:26:17,010
Многие части кода вам уже знакомы. Мы начнём использовать PyTorch и fastai,

128
00:26:17,110 --> 00:26:26,610
а потом углубимся в детали их работы и несколько раз поменяем.

129
00:26:26,710 --> 00:26:39,860
Мы создаём валидационную выборку знакомой функцией get_ct_idxs().

130
00:26:39,860 --> 00:26:47,050
Параметр wd=2e-4 — ограничение весов, ещё обсудим. Для тех, кто проходил курс «Машинное обучение» — это L2-регуляризация.

131
00:26:47,050 --> 00:26:53,742
Параметр n_factors — ширина таблицы эмбеддинга.

132
00:26:53,842 --> 00:27:06,375
Объект данных модели создаётся методом CollabFilterDataset.from_csv(), в него передаётся таблица с оценками.

133
00:27:06,475 --> 00:27:28,425
После этого нужно передать признак userId для строк, признак movieId для столбцов и целевую переменную ratings.

134
00:27:28,525 --> 00:27:33,390
Все рекомендательные системы на основе коллаборативной фильтрации построены так —

135
00:27:33,490 --> 00:27:40,660
есть набор пользователей и набор товаров, эти наборы связаны.

136
00:27:40,660 --> 00:27:53,530
В соревновании по предсказанию продаж вместо пользователей — магазины, а товары — то, что они продадут.

137
00:27:53,530 --> 00:28:09,045
Принцип общий — по паре категориальных признаков высокой мощности произведением матриц вычисляется оценка или вероятность.

138
00:28:09,145 --> 00:28:26,800
Можно думать про это по-другому: когда мы предсказываем, понравится ли пользователю 72 фильм 27, мы смотрим,

139
00:28:26,900 --> 00:28:43,635
каким пользователям нравятся те же фильмы, что и пользователю 72, и какие фильмы нравятся пользователям, похожим на пользователя 72.

140
00:28:43,735 --> 00:28:56,475
Это две формулировки одного вопроса. Коллаборативная фильтрация рассматривает пары «пользователь — фильм»

141
00:28:56,575 --> 00:29:11,670
и ищет фильмы, которые смотрели похожие люди, и людей, которые смотрели похожие фильмы.

142
00:29:11,770 --> 00:29:21,240
Если ваш датасет построен таким образом, при работе с ним можно использовать коллаборативную фильтрацию.

143
00:29:21,340 --> 00:29:28,460
Итак, есть два признака и целевая переменная.

144
00:29:28,460 --> 00:29:34,310
Как обычно, мы получаем алгоритм обучения из объекта данных модели методом .get_learner().

145
00:29:34,310 --> 00:29:48,285
Метод принимает ширину матрицы эмбеддинга n_factors, валидационную выборку val_idxs, размер минибатча 64 и алгоритм оптимизации opt_fn.

146
00:29:48,385 --> 00:29:52,842
Мы ещё обсудим алгоритмы оптимизации, здесь используется Adam.

147
00:29:52,942 --> 00:30:03,210
После создания алгоритма обучения мы обучаем модель, всё как обычно.

148
00:30:03,310 --> 00:30:10,905
Такие модели обучаются быстро, здесь всего три эпохи.

149
00:30:11,005 --> 00:30:15,480
Можно использовать алгоритм поиска скорости обучения и всё остальное, к чему вы уже привыкли.

150
00:30:15,580 --> 00:30:24,590
Обучение модели заняло пару секунд, не было никаких предобученных моделей, всё с нуля.

151
00:30:24,690 --> 00:30:34,335
Для получения среднеквадратичной ошибки (RMSE) нужно взять корень из функции потерь в последнем столбце.

152
00:30:34,435 --> 00:30:58,880
Корень из 0.776 равен примерно 0.88, лучший бенчмарк на этом датасете — 0.91, мы побили его за две секунды.

153
00:30:58,880 --> 00:31:11,800
Так можно написать модель коллаборативной фильтрации с использованием fastai, не задумываясь о деталях.

154
00:31:11,900 --> 00:31:23,470
Сейчас мы построим эту модель с нуля и достигнем значения метрики 0.77-0.78.

155
00:31:23,570 --> 00:31:32,935
Если вы хотите повторить этот результат без углубления в детали, этих трёх строк кода достаточно.

156
00:31:33,035 --> 00:31:38,095
Предсказания получаются методом .predict(), можно визуализировать их с помощью библиотеки seaborn.

157
00:31:38,195 --> 00:31:48,960
Библиотека seaborn построена на основе библиотеки matplotlib, поэтому знание matplotlib пригодится при её освоении.

158
00:31:48,960 --> 00:31:54,230
В seaborn есть несколько удобных видов графиков. Например, метод seaborn.jointplot()

159
00:31:54,230 --> 00:32:00,120
строит распределение предсказаний (горизонтальная ось) и истинных значений (вертикальная ось).

160
00:32:02,340 --> 00:32:07,192
Видно, что модель отражает общую картину данных — высокие оценки предсказываются высокими числами.

161
00:32:07,292 --> 00:32:18,420
Сверху — гистограмма распределения предсказаний, справа — истинных значений, наглядная иллюстрация.

162
00:32:18,420 --> 00:32:23,615
Вопрос из зала: Что значит параметр n_factors и почему он равен 50?

163
00:32:23,915 --> 00:32:29,352
Он равен 50, потому что это значение здесь работает лучше всего, это ширина матрицы эмбеддинга.

164
00:32:29,452 --> 00:32:39,860
В демонстрации Excel этот параметр равен 5, а у нас 50.

165
00:32:41,750 --> 00:32:54,715
Янет: Что меняется, если оценка — не действительное число, а либо 0, либо 1?

166
00:32:54,815 --> 00:33:02,575
Тогда нужно строить классификатор, а не регрессию.

167
00:33:02,675 --> 00:33:11,650
Янет: Что для этого нужно изменить?

168
00:33:11,750 --> 00:33:15,385
Не уверен, что мы доберёмся до этого в этом курсе.

169
00:33:15,485 --> 00:33:21,600
Задача классификации с использованием коллаборативной фильтрации ещё не воплощена в fastai,

170
00:33:21,600 --> 00:33:26,315
может, кто-то из студентов захочет это добавить, это несложно.

171
00:33:26,415 --> 00:33:44,850
Нужно поменять функцию активации на сигмоиду и поменять функцию потерь с RMSE на перекрёстную энтропию.

172
00:33:44,850 --> 00:33:50,940
Больше ничего менять не надо, надеюсь, кто-нибудь это напишет, и к следующей неделе у нас уже будут средства.

173
00:33:50,940 --> 00:34:04,800
Произведение векторов — это то же самое, что и произведение матриц.

174
00:34:04,800 --> 00:34:13,209
Два вектора умножаются поэлементно, и результаты складываются.

175
00:34:13,309 --> 00:34:22,110
Давайте напишем это на Python. PyTorch-тензор создаётся конструктором T().

176
00:34:22,110 --> 00:34:34,434
Это функция fastai, в PyTorch тензор создаётся методом torch.from_numpy(). Мы создали два тензора из матриц

177
00:34:34,534 --> 00:34:46,090
a = [[1, 2], [3, 4]] и b = [[2, 2], [10, 10]].

178
00:34:46,190 --> 00:34:52,150
Я не добавил .cuda() при создании переменных, поэтому они лежат в CPU, а не в GPU.

179
00:34:52,250 --> 00:35:19,590
Оператор обычного умножения a*b в PyTorch перемножит два тензора одинакового размера поэлементно.

180
00:35:19,590 --> 00:36:10,285
(a*b).sum(1) просуммирует элементы в каждой строке матрицы a*b, то есть перемножит строки матриц a и b.

181
00:36:10,385 --> 00:36:25,220
Этот результат можно было бы получить с использованием матричного умножения, но мы будем делать так.

182
00:36:28,080 --> 00:36:44,455
Нужно помнить, что данные представлены в виде обычной таблицы, а не перекрёстной, как в демонстрации в Excel.

183
00:36:44,555 --> 00:36:50,962
Для каждого пользователя мы находим строку длиной 50 в матрице эмбеддинга пользователей и умножаем её на

184
00:36:51,062 --> 00:37:02,680
строку для фильма длиной 50 в матрице эмбеддинга фильмов.

185
00:37:02,780 --> 00:37:21,120
Для этого мы создадим свой слой нейронной сети в виде модуля PyTorch.

186
00:37:21,120 --> 00:37:32,710
Модуль PyTorch — специальный объект, который можно использовать в качестве слоя нейронной сети.

187
00:37:32,810 --> 00:37:41,470
Модуль предполагает наличие реализованного скалярного произведения.

188
00:37:41,570 --> 00:37:55,405
Модуль создаётся конструктором model=DotProduct() и после этого используется как функция.

189
00:37:55,505 --> 00:38:08,369
Модуль — не просто функция, можно брать его производную и создавать нейронные сети из многих модулей.

190
00:38:08,369 --> 00:38:14,730
По сути, это удобно определённая функция.

191
00:38:14,730 --> 00:38:23,260
Скалярное произведение DotProduct() задаётся классом Python.

192
00:38:23,360 --> 00:38:31,410
Если вы не писали на Python в объектно-ориентированном стиле, придётся начать, потому что в нём написаны все модули PyTorch.

193
00:38:33,690 --> 00:38:46,000
Мне нравится в PyTorch то, что там используются языковые средства Python, а не изобретается всё заново, как в TensorFlow.

194
00:38:46,100 --> 00:38:55,770
Для реализации нового поведения в Python используются классы.

195
00:38:55,770 --> 00:39:07,020
Янет: Можно ли использовать fastai для решения задачи коллаборативной фильтрации на очень больших данных?

196
00:39:07,020 --> 00:39:33,560
Да, конечно. Данные хранятся в датафрейме pandas, он хранится в оперативной памяти.

197
00:39:33,560 --> 00:39:40,920
На Amazon легко арендовать машину с 512 ГБ памяти.

198
00:39:40,920 --> 00:39:46,200
Если ваш csv-файл больше 512 ГБ, что впечатляет,

199
00:39:48,510 --> 00:40:03,519
можете использовать (???) или Dask-датафрейм.

200
00:40:03,619 --> 00:40:15,549
Я ни разу не встречал матриц коллаборативной фильтрации тяжелее 512 ГБ, но даже с таким можно работать.

201
00:40:15,649 --> 00:40:32,640
В PyTorch при создании класса необходимо реализовать метод forward().

202
00:40:32,640 --> 00:40:45,549
Обработка минибатча нейронной сетью называется прямое вычисление (forward pass), отсюда название метода.

203
00:40:45,649 --> 00:40:54,369
Вычисление градиентов — обратное вычисление (backwards pass), его реализовывать не надо.

204
00:40:54,469 --> 00:41:01,529
Итак, мы создаём класс и реализуем метод forward, выполняющий скалярное произведение.

205
00:41:01,529 --> 00:41:13,979
После реализации класса создаётся модуль, который потом используется для вычисления скалярного произведения.

206
00:41:16,529 --> 00:41:29,811
Так создаётся слой в PyTorch, это проще, чем в других библиотеках, потому что используются встроенные средства Python.

207
00:41:29,911 --> 00:41:34,499
Давайте создадим более сложный модуль с помощью класса EmbeddingDot().

208
00:41:38,039 --> 00:41:49,670
Снова понадобится метод forward. Появятся новые поля self.u (users) и self.m (movies) — матрицы эмбеддинга пользователей и фильмов.

209
00:41:49,670 --> 00:42:00,254
Метод forward() использует эти поля, а на вход принимает индексы категориальных и количественных признаков в минибатче cats и cons.

210
00:42:00,354 --> 00:42:07,054
Индексы пользователей и фильмов могут отличаться от натурального ряда —

211
00:42:07,154 --> 00:42:16,864
например, лежать в диапазоне от 1,000,000 до 1,001,000.

212
00:42:16,964 --> 00:42:25,952
В таком случае длина матрицы эмбеддинга была бы 1,001,000, это неразумное использование места.

213
00:42:26,052 --> 00:42:38,210
Поэтому первым делом мы получаем список уникальных индексов пользователей, а потом нумеруем их заново.

214
00:42:38,310 --> 00:43:03,640
Эта строка создания словаря новой нумерации индексов очень полезная, запомните её.

215
00:43:06,729 --> 00:43:18,439
После создания новых индексов мы заменяем ими старые.

216
00:43:18,539 --> 00:43:31,639
Метод .apply() в pandas позволяет применить к датафрейму любую функцию, здесь используется лямбда-функция.

217
00:43:31,739 --> 00:43:36,039
Для фильмов делается то же самое.

218
00:43:36,039 --> 00:43:41,319
После такого преобразования оценки фильмов не изменились, но индексы были заменены на числа натурального ряда,

219
00:43:43,690 --> 00:43:49,239
чтобы эффективно использовать матрицы эмбеддинга.

220
00:43:49,239 --> 00:43:54,819
Переменные n_users и n_movies содержат количество уникальных пользователей и фильмов.

221
00:43:54,819 --> 00:44:00,609
Давайте напишем демонстрацию Excel на Python.

222
00:44:00,609 --> 00:44:21,760
В самом простом варианте модуля PyTorch не нужно реализовывать конструктор класса, так как нет никаких параметров.

223
00:44:21,760 --> 00:44:37,850
У нас есть параметры — количество пользователей n_users и количество фильмов n_movies, поэтому нужен конструктор.

224
00:44:37,850 --> 00:44:50,550
Конструктор в Python реализуется функцией __init__().

225
00:44:50,650 --> 00:45:01,930
Если вы не писали классы раньше, попрактикуйтесь. Конструктор — это функция, вызывающаяся при создании объекта.

226
00:45:02,030 --> 00:45:16,920
Для наследования от класса nn.Module необходимо указать его в параметрах и вызвать конструктор родительского класса.

227
00:45:17,020 --> 00:45:27,685
Класс EmbeddingDot() наследует класс torch.nn.Module(), поэтому он — полноценный модуль PyTorch.

228
00:45:27,785 --> 00:45:41,870
Для реализации класса мы создаём поля self.u и self.m. Поле self.u — объект класса nn.Embedding(), матрица эмбеддинга.

229
00:45:41,870 --> 00:45:55,280
Матрица эмбеддинга пользователей self.u содержит n_users строк и n_factors столбцов, в демонстрации Excel n_users=15 и n_factors=5.

230
00:45:55,280 --> 00:46:01,880
То же самое для фильмов.

231
00:46:01,880 --> 00:46:09,910
После создания матрицы эмбеддинга заполняются случайными числами.

232
00:46:12,920 --> 00:46:33,665
Случайные числа должны лежать в разумном диапазоне, чтобы градиентный спуск нормально работал.

233
00:46:33,765 --> 00:46:51,020
Я прикинул, какими должны быть числа, чтобы оценки лежали в диапазоне от 0 до 5, получился диапазон от 0 до 0.05.

234
00:46:51,020 --> 00:47:13,960
Kaiming He разработал алгоритм для определения этого диапазона.

235
00:47:14,060 --> 00:47:34,765
Идея в том, чтобы случайные числа в матрице составляли нормальное распределение со стандартным отклонением,

236
00:47:34,865 --> 00:47:48,950
обратно пропорциональным ширине матрицы эмбеддинга.

237
00:47:48,950 --> 00:48:04,940
У нас ширина матрицы эмбеддинга равна 50, примерно так и выходит.

238
00:48:04,940 --> 00:48:28,430
В PyTorch есть функция для автоматического определения этого числа, но мы всё делаем с нуля, поэтому задаём руками.

239
00:48:28,430 --> 00:48:53,774
Поле weight поля self.u класса EmbeddingDot() содержит матрицу эмбеддинга. Матрица эмбеддинга — объект класса Variable,

240
00:48:53,874 --> 00:49:12,284
это то же самое, что и тензор, но с функцией автоматического дифференцирования. Тензор содержится в поле data.

241
00:49:12,384 --> 00:49:22,484
Итак, тензор матрицы эмбеддинга содержится в поле self.u.weight.data.

242
00:49:22,584 --> 00:49:33,419
Во всех функциях на тензорах в PyTorch можно поставить нижнее подчёркивание «_» после названия,

243
00:49:33,519 --> 00:49:48,344
и функция выполнится на вызываемом объекте. Эта функция заполняет тензор числами, распределёнными равномерно.

244
00:49:48,444 --> 00:50:12,869
Без этой функции строка была бы чуть длиннее.

245
00:50:12,969 --> 00:50:21,449
Итак, у нас есть матрицы эмбеддинга.

246
00:50:21,549 --> 00:50:31,069
В метод forward я передам данные, полученные методом ColumnarModelData.from_data_frame().

247
00:50:31,069 --> 00:50:38,579
Несмотря на то, что у нас нет количественных признаков, формально они передаются.

248
00:50:38,679 --> 00:50:48,329
Столбец пользователей содержится в первом столбце датафрейма с данными, столбец фильмов — во втором.

249
00:50:48,429 --> 00:50:58,264
Мне не хочется создавать новый класс, поэтому я использую эту конструкцию.

250
00:50:58,364 --> 00:51:21,220
Метод forward принимает индексы данных одного минибатча и достаёт из матриц эмбеддинга соответствующие векторы.

251
00:51:21,320 --> 00:51:31,359
Принцип работы я уже показывал, тут это делается сразу для минибатча, а не для одной пары «пользователь — фильм».

252
00:51:31,459 --> 00:51:43,449
Нам не нужно писать никаких циклов, потому что PyTorch почти все операции выполняет сразу над минибатчами.

253
00:51:43,549 --> 00:51:52,509
Если вы напишете цикл для того, чтобы просматривать минибатч по изображению за раз, это не ускорит работу.

254
00:51:52,609 --> 00:51:59,339
Поэтому из соображений быстроты стоит пользоваться встроенными средствами PyTorch.

255
00:51:59,339 --> 00:52:05,604
Повторюсь, почти всё в PyTorch так и работает, вам не нужно об этом думать.

256
00:52:05,704 --> 00:52:13,239
Итак, мы определили скалярное произведение векторов пользователей и фильмов.

257
00:52:13,339 --> 00:52:27,684
Я задаю признаки — весь датасет, кроме оценки фильма и времени, и целевую переменную — то есть оценку фильма.

258
00:52:27,784 --> 00:52:39,546
Из этих данных методом ColumnarModelData.from_data_frame() создаётся объект модели данных data.

259
00:52:39,646 --> 00:52:47,519
Алгоритм обучения model создаётся конструктором EmbeddingDot().

260
00:52:49,549 --> 00:52:55,469
После этого нужно создать алгоритм оптимизации opt.

261
00:52:55,469 --> 00:53:02,640
Единственная строка из fastai — создание объекта data, остальные строки используют только PyTorch.

262
00:53:02,640 --> 00:53:15,630
Во второй части курса я покажу и создание объекта данных с нуля, но это очень скучно, мы не будем делать это сейчас.

263
00:53:17,220 --> 00:53:33,610
Вы можете обсудить это на форуме, но сейчас я буду использовать этот удобный метод.

264
00:53:33,710 --> 00:53:39,130
Создание объекта данных модели — единственное место, где мы будем использовать fastai, в остальных — только PyTorch.

265
00:53:39,230 --> 00:53:51,579
Алгоритм оптимизации — это то, что меняет веса модели в процессе обучения, он создаётся методом optim.SGD().

266
00:53:51,679 --> 00:53:57,939
В качестве параметров передаются параметры модели model.parameters().

267
00:53:58,039 --> 00:54:07,859
Наша модель — объект класса, наследуемого от torch.nn.Module, она поддерживает весь функционал модулей PyTorch,

268
00:54:10,230 --> 00:54:29,319
в том числе и метод .parameters(), возвращающий все обучаемые веса модели.

269
00:54:29,419 --> 00:54:38,721
Другие параметры — скорость обучения 1e-1, ограничение весов weight_decay=wd и импульс momentum=0.9, их обсудим позже.

270
00:54:38,821 --> 00:54:43,950
Нужно будет написать цикл обучения, мы это сделаем потом.

271
00:54:45,809 --> 00:54:58,230
В цикле обучения на каждом минибатче из весов модели вычитается произведение градиента на скорость обучения.

272
00:54:58,230 --> 00:55:02,935
Цикл обучения в fastai выполняется функцией fit(), вот её код.

273
00:55:03,035 --> 00:55:25,099
Первая строка — цикл по эпохам. t — загрузчик данных, для каждого минибатча из t вычисляется функция потерь,

274
00:55:25,490 --> 00:55:39,960
отображается в прогресс-баре, вызываются callback-функции, считается метрика на валидационной выборке.

275
00:55:39,960 --> 00:55:55,120
В каждой эпохе на каждой итерации вызывается метод step(), описанный в оптимизаторе, скоро мы напишем это с нуля.

276
00:55:55,220 --> 00:56:06,745
Мы не создавали алгоритм обучения в объекте learner. Функция fit() — из библиотеки fastai,

277
00:56:06,845 --> 00:56:14,700
но она более низкоуровневая, чем learner.fit(), потому что принимает в качестве модели модуль PyTorch.

278
00:56:14,700 --> 00:56:33,355
Эта функция полезна, если у вас есть готовый модуль PyTorch и вы не хотите писать собственный цикл обучения.

279
00:56:33,455 --> 00:56:41,250
Удобство fastai — в доступности различных уровней абстракции.

280
00:56:41,250 --> 00:56:51,640
На данном уровне недоступны градиентный спуск с перезапуском, дифференциальные скорости обучения

281
00:56:51,740 --> 00:57:02,100
и другие реализованные в алгоритме обучения возможности. Их придётся писать с нуля, это недостаток.

282
00:57:02,100 --> 00:57:13,375
Но есть и преимущество — функция fit() очень простая, у неё понятный код и она работает с модулями PyTorch.

283
00:57:13,475 --> 00:57:24,230
Функция выводит потери на валидационной и обучающей выборках.

284
00:57:24,330 --> 00:57:33,190
Мы хотели достичь значения функции потерь в 0.76, пока не получилось,

285
00:57:33,290 --> 00:57:41,369
модель коллаборативной фильтрации в fastai с параметрами по умолчанию работает лучше.

286
00:57:41,369 --> 00:57:57,960
Функция fit() не выполняет имитацию отжига, поэтому мы меняем скорость обучения функцией set_lrs(opt, 0.01).

287
00:57:57,960 --> 00:58:05,275
Функция принимает алгоритм оптимизации PyTorch и новое значение скорости обучения, после этого опять вызывается fit().

288
00:58:05,375 --> 00:58:17,185
Так имитация отжига выполняется вручную. Значение функции потерь уменьшилось с 1.21 до 1.13.

289
00:58:17,285 --> 00:58:33,669
Давайте сделаем перерыв на семь минут, а после него ещё улучшим модель.

290
00:58:36,869 --> 00:58:54,960
Меня попросили показать функцию fit() подробнее, она реализована в модуле model библиотеки fastai, это файл model.py.

291
00:58:54,960 --> 00:59:12,204
В каждой эпохе для каждого минибатча вызывается метод .step(), вот его реализация.

292
00:59:12,304 --> 00:59:39,569
В методе переменная output инициализируется через поле self.m, его можно вызывать как функцию, так как реализован метод forward().

293
00:59:42,059 --> 00:59:51,772
Остальные строки в методе мы ещё обсудим, они вычисляют функцию потерь и выполняют обратный проход.

294
00:59:51,872 --> 01:00:00,130
Примерно так устроен код.

295
01:00:00,230 --> 01:00:09,780
Библиотека fastai сочетает в себе возможность достигать результатов мирового уровня и читаемость кода,

296
01:00:09,780 --> 01:00:22,840
поэтому читайте код, обсуждайте его на форумах и пишите, если придумали, как можно его упростить,

297
01:00:22,940 --> 01:00:29,995
потому что кода будет много.

298
01:00:30,095 --> 01:00:36,790
Давайте вернёмся к демонстрации Excel и попробуем её улучшить.

299
01:00:36,890 --> 01:00:47,830
Наши рассуждения основывались на идее того, что пользователь 72 любит фэнтези и спецэффекты,

300
01:00:47,930 --> 01:00:57,150
а фильм 27 подходит под это определение, поэтому данный пользователь поставил ему высокую оценку.

301
01:00:57,150 --> 01:01:17,040
Мы не учли тот факт, что пользователь 72 в принципе высоко оценивает фильмы, а фильм 27 не особо выдающийся.

302
01:01:17,040 --> 01:01:29,640
Для компенсации этого вводится новый параметр — смещение. Для пользователей и для фильмов нужны свои значения смещения.

303
01:01:32,280 --> 01:01:48,050
В демонстрации Excel есть лист bias, на нём те же данные, но к матрицам эмбеддинга добавлены строка и столбец смещений.

304
01:01:48,150 --> 01:02:01,929
При вычислении скалярного произведения векторов к результату добавляются два смещения.

305
01:02:02,029 --> 01:02:27,630
Функция потерь такая же. Если запустить Решатель и подобрать ещё и смещения, результат получится лучше, чем раньше.

306
01:02:27,630 --> 01:02:37,019
Это наше первое улучшение, код не сильно меняется.

307
01:02:37,119 --> 01:02:48,635
Я ввёл функцию get_emb() для создания матриц эмбеддинга, ni и nf — количество входных данных и количество факторов.

308
01:02:48,735 --> 01:02:55,685
Функция создаёт матрицу по указанным размерам и равномерно заполняет её случайными числами.

309
01:02:55,785 --> 01:03:00,575
В прошлый раз я заполнял матрицы числами от 0 до 0.05, а сейчас — от -0.01 до 0.01,

310
01:03:00,675 --> 01:03:05,765
точные диапазоны не так важны, главное — примерно попасть в необходимый диапазон.

311
01:03:05,865 --> 01:03:20,866
С помощью этой функции мы создаём и матрицы эмбеддинга, и столбцы смещений, столбец смещений — матрица с nf=1.

312
01:03:20,966 --> 01:03:27,634
Эта конструкция — генератор списков, четыре раза вызывающий функцию get_emb()

313
01:03:27,734 --> 01:03:34,630
и присваивающий результаты её работы поочерёдно переменным self.u, self.m, self.ub, self.mb.

314
01:03:34,630 --> 01:04:10,655
Метод forward() точно так же перемножает матрицы пользователей и фильмов, но добавляет к результату два смещения.

315
01:04:10,755 --> 01:04:15,962
С помощью метода .squeeze() PyTorch добавляет дополнительную размерность массивам.

316
01:04:16,062 --> 01:04:29,840
Это называется расширение аргумента (broadcasting), мы обсудим это в курсе по машинному обучению.

317
01:04:29,940 --> 01:04:40,700
Расширение аргумента нужно для того, чтобы складывать матрицы и векторы, приводя их к одному размеру.

318
01:04:40,800 --> 01:05:00,600
Для этого вектор дублируется несколько раз в одном направлении до достижения необходимого размера.

319
01:05:00,700 --> 01:05:05,280
Расширение аргумента в PyTorch работает так же, как и в numpy.

320
01:05:05,380 --> 01:05:11,920
Изначально PyTorch не поддерживал расширение аргумента. Я первый добавил его в PyTorch с помощью костыля,

321
01:05:11,920 --> 01:05:17,110
а потом авторы добавили его поддержку в саму библиотеку.

322
01:05:17,110 --> 01:05:22,180
Итак, расширение аргумента в PyTorch такое же, как и в numpy.

323
01:05:24,640 --> 01:05:37,390
Очень важно понять, как это работает, потому что это позволяет очень сильно ускорить вычисления, избежав циклов.

324
01:05:37,390 --> 01:05:46,870
Без этого мне пришлось бы в цикле прибавлять вектор смещения к каждому столбцу матрицы, это долго и неудобно.

325
01:05:50,590 --> 01:05:59,770
Расширение аргументов появилось в 60-х годах в языке программирования APL, его автор — Кен Айверсон.

326
01:05:59,770 --> 01:06:10,330
Концепция APL описана в его статье «Notation as a Tool of Thought» — это новая система математических обозначений.

327
01:06:10,330 --> 01:06:15,220
Идея статьи в том, что высокоуровневые системы обозначений позволяют думать и выражать очень сложные мысли.

328
01:06:15,220 --> 01:06:22,820
Расширение аргумента — часть этой идеи, мы ещё будем его использовать,

329
01:06:22,920 --> 01:06:34,832
поэтому изучите этот вопрос в курсе «Машинное обучение» или в Google по запросу «numpy broadcasting».

330
01:06:34,932 --> 01:06:45,195
Итак, расширение аргумента позволяет складывать матрицы и векторы.

331
01:06:45,295 --> 01:07:04,445
После этого мы откалибруем значения оценок к диапазону от 1 до 5, как предлагала Янет.

332
01:07:04,545 --> 01:07:19,455
Для этого от полученного значения оценки сначала берётся сигмоида, она выглядит вот так, значения от 0 до 1.

333
01:07:19,555 --> 01:07:24,900
Например, значение 4.96 превратилось бы в близкое к единице.

334
01:07:24,900 --> 01:07:51,610
Полученное значение умножается на 4 и к нему прибавляется 1, что даёт нам диапазон от 1 до 5.

335
01:07:51,610 --> 01:08:08,710
В коде это выглядит так: сначала оценка res пропускается через сигмоиду.

336
01:08:08,710 --> 01:08:33,645
Все функции над тензорами в PyTorch лежат в модуле nn.functional, его обычно импортируют как F.

337
01:08:33,745 --> 01:08:39,849
F.sigmoid() — функция сигмоиды из этого модуля.

338
01:08:39,949 --> 01:08:48,388
После применения сигмоиды оценка находится в диапазоне от 0 до 1.

339
01:08:48,389 --> 01:09:00,084
После этого оценка умножается на разброс оценок, здесь он равен 5 - 1 = 4, и прибавляется минимальная оценка min_rating = 1.

340
01:09:00,184 --> 01:09:24,569
Не обязательно приводить оценки к диапазону от 1 до 5, но мы сделали это для интерпретируемости предсказаний.

341
01:09:24,569 --> 01:09:37,959
Это не нейронная сеть, но принцип общий — создавайте необходимый вам формат вывода самым простым способом.

342
01:09:38,059 --> 01:09:44,304
Для этого мы и калибруем оценки.

343
01:09:44,404 --> 01:09:50,589
Итак, теперь класс нашей модели называется EmbeddingDotBias(), модель инициализируется как раньше.

344
01:09:50,689 --> 01:10:01,350
Я добавил .cuda() в конце, чтобы модель хранилась в GPU, fastai делает это автоматически.

345
01:10:01,350 --> 01:10:05,580
Алгоритм оптимизации и функция fit() такие же, как и раньше.

346
01:10:05,580 --> 01:10:23,770
Значения метрики улучшились. Мы меняем скорость обучения, как и раньше, и метрика достигает значения 0.8.

347
01:10:23,870 --> 01:10:34,885
В общем, так и строятся модели коллаборативной фильтрации.

348
01:10:34,985 --> 01:10:47,664
Янет напомнила мне о том, что не совсем корректно называть то, что мы делаем, факторизацией матриц.

349
01:10:47,764 --> 01:10:56,170
Факторизация матриц предполагает, что перемножение матриц пользователей и фильмов даёт матрицу оценок.

350
01:10:56,270 --> 01:11:14,860
У нас в матрице стоит оценка 0, если для данной пары «пользователь — фильм» нет истинного значения,

351
01:11:14,960 --> 01:11:22,290
а простое произведение матриц не может это учесть.

352
01:11:22,290 --> 01:11:29,650
Это было очень неудобно, когда люди решали эту задачу с применением линейной алгебры,

353
01:11:29,750 --> 01:11:36,780
потому что обычно матрицы оценок очень разреженные, в них очень много пустых значений.

354
01:11:36,780 --> 01:11:43,650
В нашей демонстрации их мало, потому что я выбрал самых заядлых зрителей и самые популярные фильмы.

355
01:11:43,650 --> 01:11:49,495
Традиционно в пустых значениях использовались нули, то есть модели нужно было предсказывать нулевую оценку —

356
01:11:49,595 --> 01:11:55,213
как будто то, что пользователь не смотрел фильм, значит, что он ему не понравился.

357
01:11:55,313 --> 01:12:11,220
Это давало ужасные результаты, а вероятностная факторизация матриц позволяет этого избежать,

358
01:12:11,220 --> 01:12:16,110
вычисляя функцию потерь только для непустых значений.

359
01:12:18,240 --> 01:12:25,030
Например, если пользователь 1 поставил фильму 1029 оценку 3.0, а мы предсказали 3.5, потери будут равны 0.5.

360
01:12:25,130 --> 01:12:35,440
Представление данных в таком виде не допускает возможности вычисления функции потерь для несуществующей пары.

361
01:12:35,540 --> 01:12:42,325
Минибатчи содержат только данные из этой таблицы.

362
01:12:43,825 --> 01:12:53,500
Вероятностная факторизация матриц сильно развилась во время соревнования Netflix Prize, окончившегося в 2009.

363
01:12:53,600 --> 01:13:02,540
Тогда она уже существовала, но нигде не использовалась. В первый год соревнования Netflix Prize

364
01:13:02,640 --> 01:13:10,625
кто-то написал пост про то, как эта простая методика даёт отличные результаты,

365
01:13:10,725 --> 01:13:15,860
и внезапно все результаты в рейтинге соревнования подскочили.

366
01:13:15,960 --> 01:13:21,500
Это было несколько лет назад, а сейчас все модели коллаборативной фильтрации так работают.

367
01:13:21,600 --> 01:13:40,975
Не все модели используют сигмоиду, хотя это очень простая вещь, ничего сверхестественного, а помогает.

368
01:13:41,075 --> 01:14:20,050
Давайте посмотри на реализацию класса CollabFilterDataset() в файле column_data.py, чтобы сравнить его с нашей моделью.

369
01:14:20,050 --> 01:14:29,985
Метод get_learner создаёт объект класса CollabFilterLearner(), передавая в конструктор результат работы метода get_model(),

370
01:14:30,085 --> 01:14:48,785
который, в свою очередь, создаёт объект класса EmbeddingDotBias(). Класс EmbeddingDotBias() выглядит в точности как наш.

371
01:14:48,885 --> 01:15:00,340
Написанный нами код — тот же код, что и внутри библиотеки fastai.

372
01:15:00,340 --> 01:15:11,410
Этот код чуть проще, так как в нём используется класс CollabFilterDataset(), который позволяет

373
01:15:11,410 --> 01:15:16,104
не доставать данные с использованием списков признаков cats и cons, но остальное совпадает.

374
01:15:16,204 --> 01:15:32,604
Надеюсь, вы почувствовали, что fastai — не зашифрованные письмена, а функции, которые легко написать с нуля.

375
01:15:32,704 --> 01:15:51,690
У модели fastai значение метрики было 0.76, а не 0.8, потому что она использовала SGDR и алгоритм оптимизации Adam.

376
01:15:51,690 --> 01:16:08,219
Янет: Я думаю, можно было бы улучшить модель, используя признак даты в датасете.

377
01:16:08,219 --> 01:16:18,179
Да, можно было бы. Даже если вы не реализовали класс EmbeddingDotBias() в своём Jupyter ноутбуке,

378
01:16:18,179 --> 01:16:29,850
а использовали свою модель, вы могли бы посмотреть в код fastai, скопировать его

379
01:16:29,850 --> 01:16:46,830
и написать на его основе улучшенный класс EmbeddingDotBiasBetter(), чтобы учесть временной признак.

380
01:16:46,830 --> 01:17:01,889
Да, можно многое улучшить — например, предположить, что предпочтения пользователей меняются со временем,

381
01:17:01,989 --> 01:17:06,690
как предложила Янет, или учесть жанры фильмов.

382
01:17:08,940 --> 01:17:27,110
Это сложно сделать на этой модели, она жёсткая, поэтому сейчас мы заменим её на нейронную сеть.

383
01:17:27,110 --> 01:17:49,435
Мы возьмём те же входные данные и те же матрицы эмбеддинга.

384
01:17:49,535 --> 01:17:58,880
Матрица эмбеддинга для фильмов транспонирована, чтобы обе матрицы были одинаково ориентированы.

385
01:17:58,880 --> 01:18:09,370
Датасет представлен в виде обычной таблицы, а не перекрёстной таблицы.

386
01:18:09,470 --> 01:18:45,170
Первым делом мы заменяем нумерацию пользователей на натуральные ряды функцией MATCH().

387
01:18:45,170 --> 01:18:58,640
После этого для каждого пользователя достаётся соответствующий вектор матрицы эмбеддинга функцией OFFSET().

388
01:18:58,640 --> 01:19:22,580
Функция OFFSET() копирует соответствующие значения из матрицы эмбеддинга.

389
01:19:22,580 --> 01:19:51,800
Доставание строки матрицы эмбеддинга — это умножение вектора, представленного прямым кодированием, на эту матрицу.

390
01:19:51,800 --> 01:19:59,190
Полезно это помнить — матрица эмбеддинга подразумевает матричное произведение.

391
01:19:59,290 --> 01:20:12,840
Под капотом не происходит умножения вектора, представленного прямым кодированием, на матрицу эмбеддинга,

392
01:20:12,940 --> 01:20:19,280
потому что есть удобная оптимизация — доставание по индексу.

393
01:20:19,280 --> 01:20:28,830
Матрицы эмбеддинга позволяют ускорить вычисления, избежав умножения матриц.

394
01:20:28,930 --> 01:20:47,900
Нумерация фильмов так же заменена на натуральный ряд и фильмам так же сопоставлены векторы эмбеддинга.

395
01:20:49,460 --> 01:21:06,370
Вместо скалярного произведения этих двух векторов длиной 5 для получения оценки, как мы делали раньше,

396
01:21:06,370 --> 01:21:17,562
мы объединим их в один вектор длиной 10 и передадим этот вектор в нейронную сеть.

397
01:21:17,662 --> 01:21:33,840
Из таких векторов будет состоять тензор активаций после слоя эмбеддинга,

398
01:21:33,940 --> 01:21:39,525
и уже на их основании будет делаться предсказание.

399
01:21:39,625 --> 01:21:47,344
Как мы знаем, нейронные сети могут научиться делать что угодно, в том числе и коллаборативную фильтрацию.

400
01:21:47,444 --> 01:21:52,699
Наша нейронная сеть реализуется классом EmbeddingNet().

401
01:21:52,799 --> 01:22:10,050
Я не вводил смещение, потому что в линейном слое PyTorch (класс nn.Linear) оно есть по умолчанию.

402
01:22:10,050 --> 01:22:39,210
Пусть размер матрицы эмбеддинга пользователей — nu x nf, фильмов — nm x nf.

403
01:22:39,210 --> 01:22:50,099
Для каждой пары «пользователь — фильм» мы берём по вектору длиной nf из обеих матриц

404
01:22:50,099 --> 01:22:57,239
и объединяем их в вектор длиной 2 x nf.

405
01:23:00,480 --> 01:23:27,610
Полученный вектор умножается на матрицу размера (2 * nf) x 10.

406
01:23:27,710 --> 01:23:49,329
Полученный вектор пропускается через выпрямитель, а потом умножается на матрицу 10x1 для получения оценки.

407
01:23:49,429 --> 01:23:57,879
Это классическая нейронная сеть с одним скрытым слоем.

408
01:23:57,979 --> 01:24:05,190
Я считаю, что здесь один скрытый слой. Слой эмбеддинга тоже скрытый,

409
01:24:05,190 --> 01:24:21,270
но оба этих слоя линейны и идут сразу друг за другом, поэтому это один большой линейный слой.

410
01:24:21,270 --> 01:24:27,690
Линейный слой в PyTorch создаётся конструктором nn.Linear().

411
01:24:31,290 --> 01:24:46,020
В курсе «Машинное обучение» мы создавали линейный слой с нуля, можете посмотреть и повторить, там нет ничего нового.

412
01:24:46,020 --> 01:24:57,750
Итак, мы создаём матрицы эмбеддинга, а потом два линейных слоя.

413
01:24:57,750 --> 01:25:06,415
Можно увеличить функционал класса и добавить параметр количества активаций в скрытом слое nh=10,

414
01:25:06,515 --> 01:25:32,820
это добавит возможностей для эксперимента. Параметр nh — это ширина матрицы весов полносвязного слоя.

415
01:25:32,820 --> 01:25:52,320
Конкатенация векторов выполняется методом torch.cat() с указанием индекса оси конкатенации dim=1.

416
01:25:56,300 --> 01:26:01,580
К дропауту мы ещё вернёмся.

417
01:26:01,580 --> 01:26:11,020
После создания матрицы мы подаём её на линейный слой методом self.lin1(), а потом — в выпрямитель методом F.relu().

418
01:26:11,120 --> 01:26:16,199
Выпрямитель — это просто функция активации, поэтому он реализован в модуле F.

419
01:26:16,199 --> 01:26:21,855
Напомню, что функции активации — это функции, принимающие одно число и возвращающие другое.

420
01:26:21,955 --> 01:26:31,676
Например, выпрямитель принимает любое число и возвращает его же или ноль, если число отрицательное.

421
01:26:31,776 --> 01:26:38,740
После этого применяется сигмоида.

422
01:26:38,840 --> 01:26:45,690
Теперь у нас есть нейронная сеть. В ней всего один скрытый слой, поэтому её нельзя назвать глубокой.

423
01:26:48,030 --> 01:26:54,007
Теперь можно создать модель внутри GPU, создать алгоритм оптимизации и начать её обучать.

424
01:26:54,107 --> 01:27:02,995
В функцию fit() передаётся минимизируемая функция потерь, здесь это квадрат среднеквадратичной ошибки (MSE).

425
01:27:03,095 --> 01:27:11,320
Она тоже лежит в модуле F, как и остальные функции.

426
01:27:11,420 --> 01:27:20,340
Функция fit() должна знать, на что ориентироваться при обучении модели.

427
01:27:20,340 --> 01:27:27,560
Янет: При использовании нейронной сети должны совпадать размеры матриц эмбеддинга пользователей и фильмов?

428
01:27:27,840 --> 01:27:38,100
Отличный вопрос. Нет, не нужно, и это удобно.

429
01:27:38,100 --> 01:27:54,810
Представим, что у нас есть вектор из двух строк матриц эмбеддинга пользователей и фильмов.

430
01:27:54,810 --> 01:28:05,110
Допустим, что мы учитываем жанр фильма и для него есть матрица эмбеддинга шириной 3.

431
01:28:05,210 --> 01:28:13,770
В таком случае к этому вектору можно добавить строку и из этой матрицы, добавить временной признак как число,

432
01:28:13,870 --> 01:28:18,570
и передать итоговый вектор нейронной сети.

433
01:28:24,420 --> 01:28:43,639
Напомню, что сигмоида — это ещё одна нелинейная функция активации, как выпрямитель.

434
01:28:43,739 --> 01:28:48,879
В качестве последнего слоя нейронной сети можно использовать любую функцию активации.

435
01:28:48,979 --> 01:29:06,580
Здесь можно было без неё обойтись, но мы хотим получать оценки в привычном диапазоне.

436
01:29:06,680 --> 01:29:19,509
Обучаем модель и получаем значение функции потерь ниже, чем у последней модели.

437
01:29:19,609 --> 01:29:50,789
Можно экспериментировать с SGDR, размером полносвязного слоя, дропаутом и посмотреть, станет ли она меньше 0.76.

438
01:29:50,789 --> 01:29:57,389
Если вы используете коллаборативную фильтрацию для вашего проекта,

439
01:29:57,389 --> 01:30:15,420
можете начать со стандартной модели fastai, задавая только количество факторов, попробовать стандартные подходы,

440
01:30:15,420 --> 01:30:30,869
а потом углубиться в код и сделать модель ещё лучше.

441
01:30:30,869 --> 01:30:39,699
В подходе с нейронной сетью удобно то, что можно задать разные размеры матриц эмбеддинга,

442
01:30:39,799 --> 01:30:51,000
количество активаций на скрытом слое и вероятность дропаута,

443
01:30:51,000 --> 01:31:18,510
то есть в слое выпрямителя есть ещё и дропаут, здесь его вероятность равна 75% после обоих слоёв.

444
01:31:18,510 --> 01:31:28,320
Очень многое можно поменять.

445
01:31:28,320 --> 01:31:51,025
Например, добавить массив вероятностей дропаута ps=[0.75, 0.75]

446
01:31:51,125 --> 01:32:08,790
или разбить его на две вероятности дропаута p1=0.75 и p2=0.75.

447
01:32:18,630 --> 01:32:28,044
Или сделать конструктор похожим на функцию из анализа структурированных данных

448
01:32:28,144 --> 01:32:44,845
и добавить возможность создавать любое количество скрытых слоёв параметром nh.

449
01:32:44,945 --> 01:32:49,570
С этим вы можете экспериментировать на протяжении недели.

450
01:32:49,670 --> 01:33:05,555
Возможно, для маленьких датасетов понадобятся более высокие значения дропаута, а для больших — больше слоёв.

451
01:33:05,655 --> 01:33:21,390
Я не видел подробных обсуждений таких нейронных сетей, но я не эксперт.
==============================

452
01:33:21,490 --> 01:33:34,870
Теперь я хочу поговорить про цикл обучения.

453
01:33:34,870 --> 01:33:58,640
Веса подбирает алгоритм оптимизации opt. Давайте посмотрим, как он работает и что значит параметр momentum=0.9.

454
01:33:58,740 --> 01:34:08,110
Для этого есть демонстрация graddesc.xlsm, листы в ней нужно просматривать справа налево.

455
01:34:11,200 --> 01:34:16,030
Лист data содержит входные данные, на которых мы продемонстрируем работу стохастического градиентного спуска (SGD).

456
01:34:16,030 --> 01:34:21,815
Эта демонстрация выполнена в Excel, потому что, очевидно, Excel - лучший инструмент для глубокого обучения.

457
01:34:22,115 --> 01:34:30,040
С его помощью мы реализовали CNN и коллаборативную фильтрацию, а теперь реализуем SGD и наконец избавимся от Python.

458
01:34:30,430 --> 01:34:41,250
В качестве начальных данных - столбец данных X и столбец с целевой переменной Y.

459
01:34:41,350 --> 01:35:01,760
Целевая переменная линейно связана с изначальной переменной: x = b + a * y.

460
01:35:01,860 --> 01:35:13,675
Давайте подберём значения a и b градиентным спуском.

461
01:35:13,775 --> 01:35:20,910
Давайте начнём с самой простой реализации стохастического градиентного спуска на листе basic SGD.

462
01:35:21,010 --> 01:35:35,190
При каждом запуске макроса Run выполняется пять эпох.

463
01:35:35,290 --> 01:35:41,925
Функция потерь после первой эпохи была слишком большой, я удалю её, чтобы была видна общая картина.

464
01:35:42,025 --> 01:35:53,060
Видно, что с каждой эпохой значение функции потерь уменьшается.

465
01:35:53,060 --> 01:36:01,045
Макрос Reset сбрасывает веса. Столбец данных x и столбец целевой переменной y скопированы с предыдущего листа.

466
01:36:01,145 --> 01:36:31,105
Я задаю угловой коэффициент a (slope) и свободный член b (intercept) случайными числами, у меня получились две единицы.

467
01:36:31,205 --> 01:36:44,265
Я копирую эти два значения в строку с первой парой значений x=14 и y=58 в столбцы intercept и slope.

468
01:36:44,365 --> 01:36:58,855
и хочу получить слегка улучшенные значения углового коэффициента и свободного члена, обработав эту пару значений.

469
01:36:58,955 --> 01:37:10,460
Для этого мне нужно понять, куда двигаться, то есть что нужно сделать для уменьшения функции потерь -

470
01:37:10,460 --> 01:37:17,640
увеличить или уменьшить угловой коэффициент и свободный член.

471
01:37:17,740 --> 01:37:22,320
Для начала посчитаем значение функции потерь в столбце err^2.

472
01:37:22,420 --> 01:37:28,664
Для этого нужно предсказание в столбце y_pred, оно вычисляется как y_pred = intercept + x * slope.

473
01:37:28,764 --> 01:37:36,524
Это предсказание сделано нейронной сетью без скрытых слоёв.

474
01:37:36,624 --> 01:37:42,899
Функция потерь err^2 - это квадрат разности истинного значения y и предсказания y_pred.

475
01:37:42,999 --> 01:37:57,049
Я хочу, чтобы функция потерь была меньше, для этого пробую увеличить угловой коэффициент. Помогло.

476
01:37:57,049 --> 01:38:13,999
Пробую увеличить свободный член - тоже помогло, что неудивительно, если вспомнить истинные значения этих параметров.

477
01:38:14,099 --> 01:38:23,059
Один из способов реализовать подбор этих параметров - повторить мои шаги,

478
01:38:23,059 --> 01:38:26,419
то есть увеличить угловой коэффициент и свободный член и посмотреть, что получится.

479
01:38:26,419 --> 01:38:30,769
Это называется нахождение производной численным дифференцированием.

480
01:38:30,769 --> 01:38:40,969
Столбец errb1 содержит значение функции потерь при увеличенном свободном члене:

481
01:38:40,969 --> 01:38:48,674
errb1 = (((intercept + 0.01) + x * slope) - y) ^ 2.

482
01:38:48,774 --> 01:39:05,324
Видно, что увеличение свободного члена уменьшило функцию потерь.

483
01:39:05,424 --> 01:39:11,749
Производная равна отношению изменения целевой переменной к изменению независимой переменной.

484
01:39:13,999 --> 01:39:21,511
Целевая переменная - функция потерь, она изменилась на (errb1 - err^2), а зависимая, то есть свободный член - на 0.01.

485
01:39:21,611 --> 01:39:27,239
Примерное значение производной функции потерь по свободному члену - в столбце est de/db.

486
01:39:27,339 --> 01:39:39,570
Производная - это предел этого отношения при стремлении числа 0.01 к нулю.

487
01:39:43,530 --> 01:39:56,430
Я недостаточно умён, чтобы мыслить производными и интегралами, поэтому всегда представляю такое отношение.

488
01:39:56,430 --> 01:40:06,025
Точно так же я всегда представляю броски монет, когда смотрю на распределения вероятности.

489
01:40:06,125 --> 01:40:16,255
Эта точка зрения имеет право на существование, потому что компьютеры не умеют устремлять к бесконечности,

490
01:40:16,355 --> 01:40:23,460
они оперируют очень маленькими, но конечными числами.

491
01:40:23,460 --> 01:40:35,170
Это мой ответ способу Джеффри Хинтона представлять 12-мерные пространства, очень быстро сказав "12 измерений!" -

492
01:40:35,270 --> 01:40:41,970
чтобы осознать производные, думайте о численном дифференцировании.

493
01:40:41,970 --> 01:40:54,895
Математики говорят, что это неправильно, но именно так это и вычисляется на практике.

494
01:40:54,995 --> 01:41:07,680
Аналогично столбцам errb1 и est de/db для свободного члена вычисляются столбцы erra1 и est de/da для углового коэффициента.

495
01:41:07,680 --> 01:41:13,620
Обе производных в столбцах est de/db и est de/da отрицательные, что значит, что при увеличении

496
01:41:13,620 --> 01:41:20,010
углового коэффициента и свободного члена функция потерь уменьшается.

497
01:41:20,010 --> 01:41:42,020
Производная функции потерь по угловому коэффициенту довольно большая, что неудивительно.

498
01:41:42,890 --> 01:42:06,969
Проблема с численным дифференцированием в многомерных пространствах в том, что это сложно представить.

499
01:42:06,969 --> 01:42:30,185
Допустим, у нас есть вектор длиной 1e6, он умножается на матрицу размера 1e6 x 1e5, получается вектор длиной 1e5.

500
01:42:30,285 --> 01:42:57,859
Градиент вычисляется для каждого из миллиона весов в этом векторе, получается матрица градиентов.

501
01:42:57,959 --> 01:43:03,100


502
01:43:03,100 --> 01:43:07,989


503
01:43:09,790 --> 01:43:14,739


504
01:43:14,739 --> 01:44:03,080
Подбор весов численным дифференцированием занимал бы очень много времени и памяти, поэтому нужен другой способ.

505
01:44:03,180 --> 01:44:24,640
Чтобы разобраться в теории, изучите понятия якобиан и гессиан.

506
01:44:24,640 --> 01:44:41,360
Люди обычно описывают их очень формально, но должна найтись пара хороших объяснений на пальцах.

507
01:44:41,460 --> 01:44:47,830
Если найдёте такие объяснения, поделитесь ими на форуме, потому что важно, чтобы все это понимали.

508
01:44:51,960 --> 01:45:04,240
Понимание пригодится, когда мы будем доставать значения градиентов из модели, чтобы улучшить модель.

509
01:45:06,430 --> 01:45:15,580
Это умение сделает из вас отличных специалистов по глубокому обучению - вы сможете понимать, что не так с моделью,

510
01:45:15,580 --> 01:45:23,530
строя гистограммы распределения градиентов, или изучая, как их среднее значение меняется с каждым слоем.

511
01:45:28,270 --> 01:45:35,665
Вместо численного дифференцирования мы будем вычислять градиенты аналитически.

512
01:45:35,765 --> 01:45:49,775
В старшей школе вы видели таблицы производных, позволяющие вычислить производные многих функций.

513
01:45:49,875 --> 01:46:06,770
Например, d(x^2)/dx = 2 * x. Наша функция потерь - квадрат разности, поэтому мы применяем эту формулу.

514
01:46:06,870 --> 01:46:17,550
Важны не производные отдельных функций, а правило дифференцирования сложной функции (цепное правило).

515
01:46:17,550 --> 01:46:33,670
Допустим, у нас есть сложная функция f(g(x)), где g() - линейный слой, f() - выпрямитель.

516
01:46:33,670 --> 01:46:43,580
Функцией может быть сколько угодно, потому что нейронная сеть - это просто композиция функций,

517
01:46:43,680 --> 01:47:03,287
например, связок "линейный слой - выпрямитель" и Softmax или сигмоиды в конце.

518
01:47:03,387 --> 01:47:15,545
Для вычисления производной функции потерь по весам модели нужно использовать цепное правило.

519
01:47:15,645 --> 01:47:24,305
Для вычисления производной на определённом слое необходимо использовать все наложенные на него слои.

520
01:47:24,405 --> 01:47:32,180
Использование цепного правила в нейронных сетях называется метод обратного распространения ошибки (backpropagation).

521
01:47:32,280 --> 01:47:56,440
d(f(g(x)))/dx = df(u)/du * dg(x)/dx, где u = g(x).

522
01:47:59,170 --> 01:48:07,025
Метод обратного распространения ошибки заключается в том, что градиент ошибки, то есть функции потерь,

523
01:48:07,125 --> 01:48:16,270
вычисляется для каждого слоя в обратном направлении до необходимого, и полученные градиенты перемножаются.

524
01:48:16,270 --> 01:48:25,370
Это просто применение цепного правила для нейронных сетей, для этого не стоило придумывать отдельное название,

525
01:48:25,470 --> 01:48:34,929
но мы придумали его, чтобы люди, не работающие с нейронными сетями, думали, что мы - какие-то сверхумные люди.

526
01:48:34,929 --> 01:48:41,434
Тот факт, что вы сидите в этом классе, показывает, что нам не удалось вас в этом убедить, но помните -

527
01:48:41,534 --> 01:48:48,010
очень важно в разговоре с другими людьми говорить "метод обратного распространения ошибки" и "выпрямитель",

528
01:48:48,010 --> 01:48:54,400
а не "просто перемножьте градиенты для разных слоёв" и "просто замените отрицательные значения нулями".

529
01:48:57,520 --> 01:49:07,294
Итак, de/db = d((y_pred - y)^2)/db = 2 * (y_pred - y); de/da = 2 * (y_pred - y) * x. Excel не умеет дифференцировать,

530
01:49:07,394 --> 01:49:16,715
поэтому я получил производную в явном виде в WolframAlpha.

531
01:49:16,815 --> 01:49:22,747
У нашей крошечной нейронной сети всего один слой, поэтому цепное правило не нужно.

532
01:49:22,847 --> 01:49:36,285
Видно, что аналитические производные близки к вычисленным с помощью численного дифференцирования.

533
01:49:36,385 --> 01:49:45,130
Когда я начал заниматься нейронными сетями двадцать лет назад, аналитические формулы приходилось писать вручную,

534
01:49:45,130 --> 01:49:57,515
а потом проверять результаты с помощью численного дифференцирования.

535
01:49:57,615 --> 01:50:10,719
Если вы берёте производную вручную, не забудьте проверить результат численным дифференцированием.

536
01:50:10,719 --> 01:50:17,139
Итак, аналитические значения производных находятся в столбцах de/db и de/da.

537
01:50:17,139 --> 01:50:22,239
Мы знаем, что при увеличении свободного члена уменьшается функция потерь, поэтому отнимаем от него

538
01:50:24,670 --> 01:50:52,239
произведение градиента и скорости обучения: new b = b - de/db * lr = 1.01, аналогично new a = a - de/da * lr = 1.12.

539
01:50:56,349 --> 01:51:10,399
Обработка минибатча завершена, у нас каждый минибатч содержит одну запись. Переходим к следующему.

540
01:51:10,499 --> 01:51:17,590
x = 86, y = 202, значения углового коэффициента и свободного члена скопированы из столбцов new a и new b предыдущей записи.

541
01:51:17,590 --> 01:51:41,139
Все шаги повторяются для каждого минибатча. Когда минибатчи кончаются, проходит одна эпоха.

542
01:51:41,139 --> 01:52:16,639
В конце эпохи изначальные значения углового коэффициента и свободного члена заменяются на вычисленные, и всё повторяется.

543
01:52:16,739 --> 01:52:48,533
Макрос Run запускает 5 эпох, в конце каждой эпохи копируя полученные значения для новой и сохраняя потери.

544
01:52:48,633 --> 01:52:56,329
Так работает стохастический градиентный спуск в Excel.

545
01:52:56,429 --> 01:53:19,750
Чтобы превратить эту нейронную сеть в свёрточную, нужно просто заменить функцию потерь и вставить реальные данные.

546
01:53:19,750 --> 01:53:54,290
Проблема с этой демонстрацией в том, что она работает чрезвычайно медленно и с одной и той же скоростью.

547
01:53:54,390 --> 01:54:11,350
Возможность увеличивать скорость продвижения вниз регулируется импульсом, это реализовано на листе momentum.

548
01:54:11,350 --> 01:54:18,920
На листе momentum - то же самое, что и на листе basic SGD, но без численного дифференцирования -

549
01:54:19,020 --> 01:54:34,025
независимая переменная x, целевая переменная y, свободный член b, угловой коэффициент a, функция потерь err^2 и производные.

550
01:54:34,125 --> 01:54:39,340
Новые значения параметров a и b вычисляются похоже: new a = a -

551
01:54:39,340 --> 01:54:49,660


552
01:54:49,660 --> 01:54:59,110


553
01:54:59,110 --> 01:55:03,850


554
01:55:03,850 --> 01:55:13,020


555
01:55:13,020 --> 01:55:26,800


556
01:55:26,800 --> 01:55:32,650


557
01:55:35,830 --> 01:55:41,740


558
01:55:41,740 --> 01:55:48,940


559
01:55:48,940 --> 01:55:55,600


560
01:55:55,600 --> 01:56:03,280


561
01:56:08,080 --> 01:56:14,200


562
01:56:14,200 --> 01:56:18,790


563
01:56:18,790 --> 01:56:24,100


564
01:56:24,100 --> 01:56:28,300


565
01:56:28,300 --> 01:56:32,140


566
01:56:32,140 --> 01:56:35,680


567
01:56:35,680 --> 01:56:40,240


568
01:56:41,950 --> 01:56:46,810


569
01:56:46,810 --> 01:56:51,700


570
01:56:57,340 --> 01:57:04,300


571
01:57:04,300 --> 01:57:11,950


572
01:57:11,950 --> 01:57:22,620


573
01:57:26,160 --> 01:57:31,660


574
01:57:31,660 --> 01:57:38,710


575
01:57:38,710 --> 01:57:41,680


576
01:57:41,680 --> 01:57:45,910


577
01:57:45,910 --> 01:57:50,800


578
01:57:50,800 --> 01:57:55,300


579
01:57:55,300 --> 01:57:59,170


580
01:57:59,170 --> 01:58:03,330


581
01:58:03,330 --> 01:58:08,140


582
01:58:08,140 --> 01:58:12,160


583
01:58:13,750 --> 01:58:21,670


584
01:58:21,670 --> 01:58:26,230


585
01:58:37,930 --> 01:58:44,740


586
01:58:46,960 --> 01:58:58,000


587
01:58:58,000 --> 01:59:03,240


588
01:59:03,720 --> 01:59:18,220


589
01:59:18,220 --> 01:59:22,720


590
01:59:22,720 --> 01:59:25,690


591
01:59:29,020 --> 01:59:36,690


592
01:59:38,489 --> 01:59:41,700


593
01:59:41,700 --> 01:59:46,440


594
01:59:46,440 --> 01:59:50,670


595
01:59:50,670 --> 01:59:56,880


596
01:59:56,880 --> 02:00:00,330


597
02:00:00,330 --> 02:00:08,640


598
02:00:08,640 --> 02:00:14,730


599
02:00:17,310 --> 02:00:22,200


600
02:00:24,750 --> 02:00:31,170


601
02:00:31,170 --> 02:00:36,390


602
02:00:36,390 --> 02:00:43,710


603
02:00:43,710 --> 02:00:49,560


604
02:00:49,560 --> 02:00:53,660


605
02:00:58,830 --> 02:01:04,560


606
02:01:04,560 --> 02:01:09,690


607
02:01:13,920 --> 02:01:19,020


608
02:01:19,020 --> 02:01:25,230


609
02:01:28,290 --> 02:01:34,110


610
02:01:34,110 --> 02:01:42,960


611
02:01:42,960 --> 02:01:49,989


612
02:01:56,739 --> 02:02:00,400


613
02:02:00,400 --> 02:02:05,650


614
02:02:05,650 --> 02:02:12,730


615
02:02:12,730 --> 02:02:19,300


616
02:02:19,300 --> 02:02:25,690


617
02:02:28,750 --> 02:02:36,550


618
02:02:36,550 --> 02:02:41,680


619
02:02:41,680 --> 02:02:48,610


620
02:02:52,920 --> 02:03:00,610


621
02:03:00,610 --> 02:03:07,210


622
02:03:07,210 --> 02:03:13,210


623
02:03:13,210 --> 02:03:22,420


624
02:03:22,420 --> 02:03:28,780


625
02:03:28,780 --> 02:03:34,090


626
02:03:34,090 --> 02:03:37,630


627
02:03:37,630 --> 02:03:42,130


628
02:03:42,130 --> 02:03:47,830


629
02:03:47,830 --> 02:03:53,370


630
02:04:00,180 --> 02:04:10,380


631
02:04:10,380 --> 02:04:14,980


632
02:04:16,210 --> 02:04:22,360


633
02:04:22,360 --> 02:04:31,900


634
02:04:31,900 --> 02:04:36,489


635
02:04:36,489 --> 02:04:40,930


636
02:04:40,930 --> 02:04:47,290


637
02:04:47,290 --> 02:04:52,390


638
02:04:52,390 --> 02:04:58,120


639
02:04:58,120 --> 02:05:02,770


640
02:05:02,770 --> 02:05:09,190


641
02:05:11,949 --> 02:05:15,280


642
02:05:15,280 --> 02:05:22,840


643
02:05:22,840 --> 02:05:28,180


644
02:05:28,180 --> 02:05:33,730


645
02:05:35,890 --> 02:05:39,670


646
02:05:39,670 --> 02:05:44,080


647
02:05:44,080 --> 02:05:50,620


648
02:05:50,620 --> 02:05:55,090


649
02:05:55,090 --> 02:05:59,440


650
02:06:00,820 --> 02:06:06,850


651
02:06:06,850 --> 02:06:11,020


652
02:06:11,020 --> 02:06:15,580


653
02:06:17,260 --> 02:06:21,730


654
02:06:24,400 --> 02:06:30,340


655
02:06:30,340 --> 02:06:37,540


656
02:06:37,540 --> 02:06:42,370


657
02:06:42,370 --> 02:06:49,320


658
02:06:49,320 --> 02:06:55,300


659
02:06:55,300 --> 02:06:58,750


660
02:06:58,750 --> 02:07:04,060


661
02:07:04,060 --> 02:07:09,550


662
02:07:09,550 --> 02:07:14,980


663
02:07:16,840 --> 02:07:22,630


664
02:07:22,630 --> 02:07:26,980


665
02:07:28,510 --> 02:07:34,870


666
02:07:34,870 --> 02:07:41,320


667
02:07:41,320 --> 02:07:46,210


668
02:07:46,210 --> 02:07:53,260


669
02:07:53,260 --> 02:07:56,650


670
02:07:59,290 --> 02:08:03,480


671
02:08:03,480 --> 02:08:09,760


672
02:08:09,760 --> 02:08:13,120


673
02:08:13,120 --> 02:08:18,100


674
02:08:18,100 --> 02:08:22,240


675
02:08:24,700 --> 02:08:29,650


676
02:08:29,650 --> 02:08:33,010


677
02:08:33,010 --> 02:08:37,720


678
02:08:37,720 --> 02:08:43,060


679
02:08:43,060 --> 02:08:48,550


680
02:08:48,550 --> 02:08:55,030


681
02:08:55,030 --> 02:08:58,840


682
02:08:58,840 --> 02:09:04,660


683
02:09:04,660 --> 02:09:09,940


684
02:09:09,940 --> 02:09:13,540


685
02:09:13,540 --> 02:09:18,660


686
02:09:19,830 --> 02:09:25,000


687
02:09:25,000 --> 02:09:31,480


688
02:09:31,480 --> 02:09:35,140


689
02:09:35,140 --> 02:09:42,100


690
02:09:42,100 --> 02:09:48,370


691
02:09:50,500 --> 02:09:56,500


692
02:09:56,500 --> 02:10:00,670


693
02:10:00,670 --> 02:10:03,790


694
02:10:03,790 --> 02:10:15,430


695
02:10:15,430 --> 02:10:21,310


696
02:10:21,310 --> 02:10:26,770


697
02:10:26,770 --> 02:10:29,590


698
02:10:29,590 --> 02:10:35,500


699
02:10:35,500 --> 02:10:38,610


700
02:10:38,610 --> 02:10:45,930


701
02:10:45,930 --> 02:10:50,880


702
02:10:50,880 --> 02:10:57,720


703
02:10:57,720 --> 02:11:02,850


704
02:11:02,850 --> 02:11:12,750


705
02:11:12,750 --> 02:11:19,860


706
02:11:19,860 --> 02:11:27,480


707
02:11:27,480 --> 02:11:34,739


708
02:11:34,739 --> 02:11:39,510


709
02:11:39,510 --> 02:11:46,440


710
02:11:48,570 --> 02:11:54,330


711
02:11:54,330 --> 02:11:57,989


712
02:11:57,989 --> 02:12:03,360


713
02:12:03,360 --> 02:12:08,910


714
02:12:08,910 --> 02:12:14,100


715
02:12:14,100 --> 02:12:19,140


716
02:12:19,140 --> 02:12:23,400


717
02:12:26,130 --> 02:12:32,880


718
02:12:32,880 --> 02:12:39,270


719
02:12:39,270 --> 02:12:49,619


720
02:12:55,960 --> 02:13:04,840


721
02:13:04,840 --> 02:13:10,750


722
02:13:10,750 --> 02:13:15,909


723
02:13:15,909 --> 02:13:19,630


724
02:13:19,630 --> 02:13:24,219


725
02:13:24,219 --> 02:13:31,719


726
02:13:31,719 --> 02:13:39,159


727
02:13:39,159 --> 02:13:47,679


728
02:13:47,679 --> 02:13:52,150


729
02:13:52,150 --> 02:13:57,550


730
02:13:57,550 --> 02:14:02,770


731
02:14:02,770 --> 02:14:07,210


732
02:14:07,210 --> 02:14:14,469


733
02:14:14,469 --> 02:14:21,780


734
02:14:21,780 --> 02:14:28,809


735
02:14:28,809 --> 02:14:35,829


736
02:14:38,139 --> 02:14:42,940


737
02:14:46,929 --> 02:14:53,559


738
02:14:53,559 --> 02:14:56,920


739
02:14:56,920 --> 02:15:02,739


740
02:15:03,070 --> 02:15:09,580


741
02:15:09,580 --> 02:15:15,460


742
02:15:15,460 --> 02:15:22,000


743
02:15:22,000 --> 02:15:28,480


744
02:15:28,480 --> 02:15:32,110


745
02:15:32,110 --> 02:15:36,400


746
02:15:36,400 --> 02:15:40,300


747
02:15:40,300 --> 02:15:47,410


748
02:15:47,410 --> 02:15:51,970


749
02:15:51,970 --> 02:15:57,340


750
02:15:57,340 --> 02:16:01,960


751
02:16:01,960 --> 02:16:11,440


752
02:16:11,440 --> 02:16:17,410


753
02:16:17,410 --> 02:16:26,950


754
02:16:26,950 --> 02:16:34,510


755
02:16:34,510 --> 02:16:40,150


756
02:16:40,150 --> 02:16:46,540


757
02:16:46,540 --> 02:16:53,200


758
02:16:53,200 --> 02:16:57,460


759
02:16:59,170 --> 02:17:03,130


760
02:17:03,129 --> 02:17:05,550


761
02:17:06,620 --> 02:17:11,460


762
02:17:12,660 --> 02:17:21,420


763
02:17:21,420 --> 02:17:27,030


764
02:17:27,030 --> 02:17:32,640


765
02:17:35,280 --> 02:17:40,350


766
02:17:40,350 --> 02:17:46,080


767
02:17:46,080 --> 02:17:50,340


768
02:17:50,340 --> 02:17:57,120


769
02:17:57,120 --> 02:18:00,480


770
02:18:02,459 --> 02:18:06,149


771
02:18:06,150 --> 02:18:10,680


772
02:18:10,680 --> 02:18:17,280


773
02:18:17,280 --> 02:18:21,060


774
02:18:23,309 --> 02:18:26,969


775
02:18:26,969 --> 02:18:32,219


776
02:18:32,219 --> 02:18:39,439


