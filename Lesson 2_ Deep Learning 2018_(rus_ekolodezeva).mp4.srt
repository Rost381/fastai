1
00:00:00,250 --> 00:00:04,350
Добро пожаловать на вторую лекцию курса Глубокое обучение.

2
00:00:06,940 --> 00:00:18,719
На прошлой неделе мы успешно обучили неплохой классификатор изображений, давайте кратко пройдёмся по основным понятиям.

3
00:00:21,580 --> 00:00:57,389
Видно экран? Приглушим свет? Да, так нормально.

4
00:01:02,440 --> 00:01:22,259
Напоминаю, что мы использовали три строки кода, работающие с датасетом в указанной директории,

5
00:01:23,049 --> 00:01:41,710
изображения были разделены на обучающую и валидационную выборки и разделены на кошек и собак внутри каждой выборки.

6
00:01:41,810 --> 00:01:55,470
Это один из двух способов организации данных для обучения модели.

7
00:01:55,780 --> 00:02:09,148
По сообщениям на форуме я вижу, что на протяжении недели вы пробовали создавать новые классификаторы со своими датасетами.

8
00:02:10,090 --> 00:02:24,959
Для начала этого достаточно — если вы создадите свой датасет из нескольких сотен или тысяч изображений

9
00:02:25,569 --> 00:02:31,679
и запустите эти три строки кода, вы получите классификатор изображений.

10
00:02:31,680 --> 00:02:35,760
В третьей колонке вывода вы увидите долю правильных ответов вашего классификатора.

11
00:02:37,420 --> 00:02:51,660
Мы смотрели, как работает модель — в чём она не уверена, в чём ошибается, поняли, что это полезная информация.

12
00:02:52,810 --> 00:03:05,970
Потом мы узнали про необходимость фиксировать скорость обучения, здесь она равна 0.01,

13
00:03:07,120 --> 00:03:15,509
позже мы изучим обосновывающую этот параметр теорию, а пока сконцентрируемся на практике.

14
00:03:18,790 --> 00:03:20,790
Да, Янет?

15
00:03:23,680 --> 00:03:27,540
Янет: Вас не видно на видео.
Да, теперь видно, я повернул камеру.

16
00:03:30,760 --> 00:03:35,910
Янет: Расскажите про значение метрик при обучении модели.

17
00:03:36,640 --> 00:03:45,959
Эти три? Мы ещё обсудим первую и вторую колонки, третья — доля правильных ответов.

18
00:03:47,110 --> 00:03:53,429
Нулевая колонка — количество эпох, то есть сколько раз модель просмотрела весь датасет.

19
00:03:54,610 --> 00:04:09,944
Первая колонка — значение функции потерь на тренировочной выборке, на которой обучается модель,

20
00:04:10,044 --> 00:04:22,739
вторая — значение функции потерь на валидационной выборке, которую мы используем, чтобы оценить качество модели.

21
00:04:25,400 --> 00:04:39,430
Ещё раз: номер эпохи, потери на тренировочной выборке, потери на валидациннной выборке, доля правильных ответов.

22
00:04:45,399 --> 00:04:48,599


23
00:04:54,520 --> 00:05:08,218
Скорость обучения показывает, как быстро мы стремимся найти решение.

24
00:05:08,219 --> 00:05:18,449
Хорошая аналогия — поиск минимума выпуклой функции.

25
00:05:19,029 --> 00:05:24,509
В процессе глубокого обучения решается та же задача.

26
00:05:26,349 --> 00:05:33,329
У функции могут быть сотни миллионов параметров, но они все устроены одинаково.

27
00:05:33,330 --> 00:05:44,459
По этой функции сразу видно, что её минимум находится здесь, давайте посмотрим, какой алгоритм может это вычислить.

28
00:05:44,619 --> 00:05:51,569
Выбираем случайную точку на оси, находим соответствующее ей значение функции потерь.

29
00:05:51,999 --> 00:06:05,759
Вычисляем градиент, это ответ на вопрос «В какую сторону надо идти, чтобы идти вниз, и с какой скоростью?».

30
00:06:06,519 --> 00:06:20,909
Делаем шаг в направлении от градиента, пропорциональный его величине.

31
00:06:21,219 --> 00:06:30,718
Коэффициент пропорциональности, на что мы домножаем градиент для получения длины шага, и есть скорость обучения.

32
00:06:31,209 --> 00:06:48,419
Если скорость обучения мала, алгоритм будет сходиться, но очень медленно.

33
00:06:48,459 --> 00:07:00,929
Если скорость обучения слишком велика, алгоритм разойдётся.

34
00:07:01,300 --> 00:07:12,930
Если вы обучаете нейронную сеть и функция потерь начинает резко увеличиваться, значит, скорость обучения слишком велика.

35
00:07:14,050 --> 00:07:20,520
Если она слишком низкая, это не так страшно — просто придётся долго ждать.

36
00:07:20,620 --> 00:07:36,089
Для нахождения оптимальной скорости обучения мы используем специальный алгоритм поиска скорости обучения.

37
00:07:36,090 --> 00:07:52,350
Напомню, что изображения рассматриваются пачками (минибатчами) по 64 или 128, параллельные вычисления на GPU позволяют это делать.

38
00:07:52,420 --> 00:08:02,850
После каждого минибатча алгоритм поиска скорости обучения увеличивает скорость обучения вдвое.

39
00:08:02,850 --> 00:08:12,180
Мы начинаем с очень маленьких значений скорости обучения и постепеннно увеличиваем её,

40
00:08:12,670 --> 00:08:18,870
в какой-то момент она становится слишком большой и функция потерь резко возрастает.

41
00:08:18,870 --> 00:08:26,249
Вот график зависимости функции потерь от скорости обучения.

42
00:08:27,250 --> 00:08:30,510
При маленьких значениях скорости обучения функция потерь высокая, при увеличении скорости потерь она уменьшается,

43
00:08:30,510 --> 00:08:35,100
а потом начинает ухудшаться.

44
00:08:35,380 --> 00:09:12,299
Числа на горизонтальной оси записаны в экспоненциальном виде. 10^-1 это 0.1, 10^-2 это 0.01, в Python это обычно пишут как 1e-1 и 1e-2.

45
00:09:15,100 --> 00:09:32,160
Игнорируйте значение функции потерь при поиске скорости обучения, это самая высокая точка на графике.

46
00:09:32,160 --> 00:09:38,999
Значение имеет только график зависимости функции потерь от скорости обучения.

47
00:09:39,670 --> 00:09:47,380
Точка минимума на графике — слишком высокая скорость обучения, в этой точке она уже не улучшается.

48
00:09:47,380 --> 00:09:58,110
Я обычно использую скорость обучения на порядок меньше этой точки, в данном случае 1е-2, а не 1е-1.

49
00:09:58,150 --> 00:10:08,460
Поэтому здесь стоит 1е-2.

50
00:10:10,180 --> 00:10:24,660
Важно понять, что правильный подбор одной только скорости обучения уже даст хорошие результаты.

51
00:10:24,820 --> 00:10:41,790
И это очень важная мысль — в других учебниках или курсах вы можете узнать про десятки гиперпараметров,

52
00:10:41,950 --> 00:10:52,150
и их довольно сложно подбирать, а библиотека fast.ai делает всё возможное автоматически.

53
00:10:52,150 --> 00:10:56,400
Потом мы узнаем о других параметрах, которые могут немного улучшить результаты,

54
00:10:57,760 --> 00:11:22,229
но на самом деле скорость обучения — ключевой параметр, хоть люди и считают, что глубокое обучение гораздо сложнее.

55
00:11:22,300 --> 00:11:41,990
Алгоритму около полутора лет, его автор не очень популярен, поэтому статья с описанием алгоритма почти никому не известна.

56
00:11:42,829 --> 00:12:00,589
Автор алгоритма — Лэсли Смит, расскажите о его изобретении своим коллегам.

57
00:12:01,709 --> 00:12:10,008
Я видел статью No More Pesky Learning Rates, в которой описан менее продуктивный метод.

58
00:12:10,009 --> 00:12:17,899
Большую часть истории глубокого обучения подбирать скорость обучения было действительно сложно.

59
00:12:19,019 --> 00:12:27,079
Метод простой — найдите самую низкую точку, поделите соответствующее значение на десять и используйте его,

60
00:12:27,079 --> 00:12:34,300
если не сработает, поделите ещё на десять, но мне обычно хватает.

61
00:12:40,160 --> 00:12:52,428
Вопрос из зала: Чем градиентный спуск с выбором скорости обучения лучше градиентного спуска с инерцией?

62
00:12:58,559 --> 00:13:03,498
Отличный вопрос. На протяжении курса мы узнаем о различных способах улучшить градиентный спуск,

63
00:13:03,929 --> 00:13:08,129
таких, как градиентный спуск с инерцией, Adam (Adaptive Moment Estimation) и других,

64
00:13:08,129 --> 00:13:17,149
но это не повлияет на практику — библиотека fast.ai сама подбирает необходимые оптимизации градиентного спуска.

65
00:13:17,149 --> 00:13:34,489
Метод нахождения скорости обучения использует Adam, но это не относится к делу — сначала подбирается скорость обучения,

66
00:13:34,490 --> 00:13:43,129
и только потом оптимизируется градиентный спуск, эти две вещи не связаны.

67
00:13:43,129 --> 00:14:00,589
Идея сначала выбирать скорость обучения, а потом оптимизировать градиентный спуск не нова, но почему-то её никто не использует.

68
00:14:05,800 --> 00:14:16,420
Вопрос из зала: Алгоритм Adam меняет скорость обучения на каждой итерации, зачем её тогда подбирать?

69
00:14:19,040 --> 00:14:29,649
Мы рассмотрим Adam позже, если вкратце — да, в Adam скорость обучения зависит от предыдущих значений градиента,

70
00:14:30,410 --> 00:14:53,080
но она всё ещё имеет смысл как отдельная величина, как и в других методах с динамической скоростью обучения.

71
00:14:55,640 --> 00:15:08,649
Самое важное для улучшения качества модели — давать ей достаточно данных для обучения.

72
00:15:09,290 --> 00:15:18,640
Есть проблема переобучения — у модели могут быть сотни миллионов параметров, и, если она обучается слишком долго,

73
00:15:19,070 --> 00:15:26,679
она начинает придавать большое значение особенностям датасета, а не общим закономерностям,

74
00:15:26,750 --> 00:15:32,829
которые применимы и к тренировочной, и к валидационной выборке.

75
00:15:33,529 --> 00:15:38,199
Чтобы избежать переобучения, нужно предоставить модели больше данных для обучения.

76
00:15:38,329 --> 00:15:49,119
Очевидный способ — собрать больше данных, но гораздо проще применить приращение данных, чтобы создать новые данные из существующих.

77
00:15:50,540 --> 00:15:57,530
Приращение данных во многих курсах опускают или оставляют на конец как дополнительный материал,

78
00:15:57,630 --> 00:15:59,560
хотя это ключевая техника для улучшения качества модели.

79
00:16:04,779 --> 00:16:09,849
Приращение данных встроено в библиотеку fast.ai и его просто применять.

80
00:16:09,850 --> 00:16:14,050
Мы ещё обсудим код, но общая идея такова -

81
00:16:14,740 --> 00:16:22,630
в наших трёх строках кода в первой строке в метод ImageClassifierData.from_paths() передавалась рабочая директория PATH,

82
00:16:22,630 --> 00:16:31,838
а также архитектура нейронной сети arch и размер sz, до которого обрезаются изображения перед обработкой.

83
00:16:32,180 --> 00:16:37,839
К этим параметрам мы добавим ещё один, указывающий вид приращения данных.

84
00:16:38,600 --> 00:16:51,819
Я продемонстрирую, как это работает. Мы разберём код позже,

85
00:16:53,180 --> 00:17:02,169
здесь алгоритм приращения данных шесть раз проходит через весь датасет и выводит результат для одного изображения.

86
00:17:02,779 --> 00:17:14,828
Видно, что эта кошка находится левее, эта — правее, эта отражена по горизонтали и так далее.

87
00:17:16,520 --> 00:17:24,309
Для различных типов изображений нужны различные виды приращения данных — в задаче распознавания букв и цифр

88
00:17:25,520 --> 00:17:30,400
отражение по горизонтали не сработало бы, потому что изображение меняет свой смысл,

89
00:17:31,040 --> 00:17:40,329
а в задаче распознавания кошек и собак неразумно включать вертикальное отражение, потому что обычно кошки не вверх ногами.

90
00:17:40,550 --> 00:17:50,859
В соревновании Kaggle по распознаванию айсбергов на спутниковых снимках, наоборот, имеет смысл отражать вертикально,

91
00:17:51,110 --> 00:17:56,500
потому что не имеет значения, с какой стороны спутника находится асйберг.

92
00:17:58,250 --> 00:18:06,069
Один из алгоритмов приращения данных — transform_on_side, который предполагает, что снимок был сделан сбоку,

93
00:18:06,590 --> 00:18:09,939
поэтому его можно отражать горизонтально, но не вертикально.

94
00:18:10,010 --> 00:18:13,749
Такой алгоритм отражает изображения горизонтально, поворачивает их на маленький угол,

95
00:18:14,390 --> 00:18:28,190
слегка меняет яркость и контрастность изображения, немного приближает, отдаляет и сдвигает центр изображения.

96
00:18:30,210 --> 00:18:39,410
Вопрос из зала: Расскажите ещё раз, почему минимум кривой потерь не подходит при выборе скорости обучения.

97
00:18:39,410 --> 00:18:54,590
Вопрос из зала: И ещё — работает ли алгоритм поиска скорости обучения для каждой свёрточной нейронной сети.

98
00:18:58,050 --> 00:19:03,919
Люди, рядом с которыми есть свободное место, поднимите руку, пожалуйста.

99
00:19:10,650 --> 00:19:21,709
К вопросу о том, почему при выборе скорости обучения мы берём не минимум на графике, а точку перед минимумом.

100
00:19:24,660 --> 00:19:56,700
Вспомним алгоритм: мы начинаем с маленького шага и каждый раз удваиваем его, двигаясь вдоль градиента.

101
00:19:56,700 --> 00:20:06,949
Цель не в том, чтобы найти минимум, а в том, чтобы понять, какая скорость обучения позволяет нам быстрее всего спускаться.

102
00:20:07,530 --> 00:20:20,300
В точне минимума функция потерь минимальна, но скорость обучения уже слишком большая, алгоритм начинает расходиться.

103
00:20:20,460 --> 00:20:30,410
Поэтому мы отходим чуть назад к моменту, где функция потерь выше.

104
00:20:30,720 --> 00:20:40,699
Это график зависимости скорости обучения от номера итерации, каждая итерация — новый минибатч, скорость обучения всегда растёт.

105
00:20:41,249 --> 00:20:47,029
Это график зависимости функции потерь от скорости обучения, в точке минимума скорость обучения уже слишком высокая,

106
00:20:47,789 --> 00:20:52,309
поэтому мы немного её уменьшаем, чтобы попасть в оптимальную область.

107
00:20:54,389 --> 00:20:58,968
Позже мы узнаем про стохастический градиентный спуск с перезапуском,

108
00:20:59,159 --> 00:21:13,189
который покажет, что здесь можно взять скорость обучения 1е-3 и модель будет обучаться быстрее, но,

109
00:21:13,190 --> 00:21:20,389
как мы увидим дальше, более высокие скорости обучения дадут лучшее обобщение, это сейчас не критично.

110
00:21:20,399 --> 00:21:26,209
Вопрос из зала: Скорость обучения должна быть высокой?

111
00:21:27,059 --> 00:21:29,059


112
00:21:29,849 --> 00:21:43,639
Ну, вот график, при увеличении номера итерации скорость обучения всегда увеличивается,

113
00:21:44,039 --> 00:21:51,199
а на этом графике в минимальной точке она уже слишком большая.

114
00:21:51,450 --> 00:21:57,289
Вопрос из зала: Я спросил, потому что вы сначала сказали, что 1е-1 это слишком много

115
00:21:58,019 --> 00:22:05,529
и надо выбрать 1е-2, а потом сказали, что надо увеличить это число на порядок.

116
00:22:05,549 --> 00:22:21,228
Я не собирался это сказать, извините, если оговорился. Я имел в виду уменьшение скорости обучение, возможно, сказал не то.

117
00:22:23,159 --> 00:22:35,720
Вопрос из зала: Раньше вы говорили, что все локальные минимумы одинаковые, и на этом графике это тоже видно, за этим стоит какая-то теория?

118
00:22:37,020 --> 00:22:48,500
Нет, этот график не демонстрирует этот факт. Этот график просто показывает, что существует оптимальное значение скорости обучения.

119
00:22:49,500 --> 00:23:00,110
Тот факт, что все локальные минимумы одинаковы — совсем про другое, мы к этому ещё вернёмся.

120
00:23:02,909 --> 00:23:20,720
Янет: Сколько раз нужно подбирать скорость обучения? На каждой эпохе?

121
00:23:24,030 --> 00:23:37,470
Хороший вопрос, Янет. Я выбираю скорость обучения в самом начале, и иногда после размораживания слоёв, мы это ещ обсудим.

122
00:23:37,470 --> 00:23:58,160
Идея в том, чтобы выбирать скорость обучения заново, если вы поменяли что-то в модели.

123
00:23:58,920 --> 00:24:06,950
Хуже вы точно не сделаете, алгоритм поиска довольно быстрый.

124
00:24:08,160 --> 00:24:09,085
Отличный вопрос.

125
00:24:09,185 --> 00:24:23,119
Возвращаемся к приращению данных. В этот метод можно передавать различные виды приращения данных,

126
00:24:23,820 --> 00:24:36,920
позже мы создадим свои, но пока остановимся на этом.

127
00:24:37,290 --> 00:24:53,780
Изображение при преобразовании может быть приближено, отдалено, повернуто, сдвинуто, или отражено -

128
00:24:54,420 --> 00:25:04,460
технически мы не создаём новые данные, но это помогает свёрточной нейронной сети лучше обучаться.

129
00:25:05,130 --> 00:25:24,260
Мы говорим модели — если редактировать изображение таким способом, оно не изменится.

130
00:25:25,830 --> 00:25:39,950
Итак, в метод ImageClassifierData.from_paths() передаются различные виды приращения данных, мы ещё это обсудим.

131
00:25:41,410 --> 00:25:49,850
Теперь обучим модель, вызвав метод .fit().

132
00:25:49,850 --> 00:26:00,639
Сейчас приращение данных никак не влияет, потому что мы указали параметр precompute=True, мы это ещё обсудим.

133
00:26:03,170 --> 00:26:09,519
Вспомните демонстрацию, где показывались различные уровни нейронной сети. Для каждого результата классификации -

134
00:26:10,520 --> 00:26:48,610
середины цветка, или глаза птицы — есть функция активации, которая говорит, с какой вероятностью на изображении есть этот объект.

135
00:26:49,520 --> 00:27:04,630
Параметр precompute=True значит, что наша модель заранее была обучена на полутора миллионах изображений базы ImageNet

136
00:27:04,630 --> 00:27:20,770
Это значит, что модель сохранила все функции активации с предпоследнего уровня, то есть информацию типа

137
00:27:20,770 --> 00:27:31,479
«это — на столько-то процентов глаз, это — на столько-то процентов собака, это — мохнатое ухо».

138
00:27:32,270 --> 00:27:45,489
При обучении модели использовались заранее вычисленные функции активаций,

139
00:27:46,040 --> 00:27:57,199
и на их основе быстро построилась простая линейная модель.

140
00:27:57,200 --> 00:28:07,008
Экспериментируя, вы могли заметить, что первый запуск кода занимает пару минут,

141
00:28:07,590 --> 00:28:13,849
а у меня уходит 5-10 секунд — это из-за того, что модель использует заранее вычисленные функции активации.

142
00:28:13,949 --> 00:28:22,249
Если вы используете свой компьютер или сервер Amazon, скачать функции активации надо будет один раз,

143
00:28:22,470 --> 00:28:39,739
если вы используете Crestle — каждый раз при перезапуске машины.

144
00:28:40,200 --> 00:28:47,449
Во всех случаях, кроме Crestle, это нужно делать всего один раз для каждого датасета.

145
00:28:49,110 --> 00:29:05,089
Проблема в том, что с заранее вычисленными функциями активации не работает приращение данных -

146
00:29:05,090 --> 00:29:11,809
для каждого изображения кошки уже вычислены функции активации, и наши преобразования ничего не меняют.

147
00:29:12,749 --> 00:29:20,929
Поэтому мы ставим precompute=False и запускаем ещё несколько эпох.

148
00:29:21,720 --> 00:29:33,799
Видно, что доля правильных ответов от эпохи к эпохе не увеличивается — и это плохо, зато

149
00:29:34,679 --> 00:29:46,249
уменьшаются потери на тренировочной выборке и почти не меняются потери на валидацонной, то есть не происхоит переобучения.

150
00:29:46,649 --> 00:29:58,039
Когда потери на тренировочной выборке сильно меньше потерь на валидационной, происходит переобучение, мы это ещё обсудим.

151
00:29:58,039 --> 00:30:07,069
Если модель гораздо лучше предсказывает тренировочную выборку, чем валидационную, она плохо обобщает.

152
00:30:07,780 --> 00:30:16,289
Мы избежали переобучения, но и доля правильных ответов не стала сильно выше — надо ещё что-нибудь придумать.

153
00:30:16,870 --> 00:30:24,240
Перед этим я хочу ещё кое-что показать. Я добавил параметр длины цикла cycle_len=1.

154
00:30:24,400 --> 00:30:40,800
Параметр длины цикла указывает на то, что здесь используется стохастический градиентный спуск с перезапуском (SGDR).

155
00:30:41,440 --> 00:31:05,129
Идея SGDR в том, что при приближении к оптимальной точке имеет смысл уменьшить скорость обучения, чтобы точнее в неё попасть.

156
00:31:05,470 --> 00:31:23,050
На этом участке зависимость скорости обучения от номера итерации может выглядеть так.

157
00:31:24,260 --> 00:31:39,160
Этот алгоритм называется алгоритм имитации отжига, он очень популярен.

158
00:31:39,920 --> 00:31:58,809
Обычно его применяют так: просто понижают выбранную скорость обучения на порядок каждый раз, когда она перестаёт работать.

159
00:31:59,210 --> 00:32:09,010
Это стандартный подход, всё приходится делать руками, это неудобно.

160
00:32:09,530 --> 00:32:15,280
Гораздо проще выбрать функцию, по которой будет меняться скорость обучения.

161
00:32:16,010 --> 00:32:30,650
Хорошая функция — половина периода косинуса. Когда оптимальная точка ещё далеко, скорость обучения велика,

162
00:32:30,650 --> 00:32:37,999
при приближении к оптимальной точке она сначала резко падает, а потом начинает падать сильно медленнее.

163
00:32:38,910 --> 00:32:48,680
Это называется имитация отжига по косинусу, если кто-то забыл — вот так выглядит косинус и мы берём его часть.

164
00:32:49,440 --> 00:32:53,270
Мы будем использовать имитацию отжига по косинусу.

165
00:32:54,570 --> 00:33:06,949
Проблема в том, что мы работаем в многомерном пространстве — у нас сотни миллионов измерений. На примере трёхмерного пространства:

166
00:33:08,010 --> 00:33:23,509
есть много плоских участков, не являющихся локальными минимумами.

167
00:33:24,690 --> 00:33:26,690
Сейчас покажу.

168
00:33:32,870 --> 00:33:51,370
Допустим, что кривая потерь выглядит как-то так и из случайного начального приближения нашелся минимум здесь.

169
00:33:52,279 --> 00:34:05,836
В этой точке низкие потери, но она плохая — если модели дать немного другой набор данных, она выдаст плохие результаты.

170
00:34:05,936 --> 00:34:31,119
Наоборот, эта точка хорошая — потери в ней такие же, но она лучше реагирует на изменения в начальных данных.

171
00:34:31,399 --> 00:34:53,649
Чтобы избежать застревания в плохой точке, мы будем циклически менять скорость обучения таким образом -

172
00:34:53,690 --> 00:34:59,200
сначала спускаемся по косинусоиде, потом резко поднимаемся, и так несколько раз.

173
00:34:59,530 --> 00:35:12,459
Это поможет выпрыгивать из плохих точек, а не застревать в них.

174
00:35:12,460 --> 00:35:33,580
Если мы попадём в хорошую область, мы в ней и останемся.

175
00:35:40,570 --> 00:35:49,409
Вопрос из зала: Можно ли достичь такого эффекта, просто несколько раз выбрав случайные начальные приближения?

176
00:35:50,620 --> 00:36:05,069
Отличный вопрос. Именно это люди и делали до изобретения SGDR -

177
00:36:05,740 --> 00:36:18,630
десять раз тренировали модель с нуля в надежде, что один из вариантов будет хорош.

178
00:36:19,450 --> 00:36:37,110
Преимущество SGDR в том, что модель тренируется только один раз, постепенно улучшаясь.

179
00:36:37,420 --> 00:36:51,780
Циклическое изменение скорости обучения даёт результаты лучше, чем просто случайные начальные приближения.

180
00:36:52,360 --> 00:37:02,099
Его изобрели недавно, он очень удобный, но про него мало кто знает.

181
00:37:02,800 --> 00:37:16,739
Мне кажется, что SGDR и алгоритм поиска скорости обучения — мои суперсилы, позволяющие обходить почти всех на соревнованиях Kaggle.

182
00:37:16,740 --> 00:37:26,789
Я включаюсь в соревнование в первые две недели и получаю резко отличающиеся от остальных результаты.

183
00:37:27,460 --> 00:37:37,679
Именно поэтому на этом графике я выбрал область резкого спуска, а не пологого -

184
00:37:37,960 --> 00:37:54,299
значение 1е-2 при применении SGDR будет верхней точкой этой функции.

185
00:37:54,580 --> 00:38:03,509
Если вместо 1е-2 взять значение меньше, SGDR не сможет выбраться из ненужных минимумов.

186
00:38:05,950 --> 00:38:11,819
Вопрос из зала: Сколько раз меняется скорость обучения внутри эпохи?

187
00:38:12,610 --> 00:38:26,339
Скорость обучения меняется после каждого минибатча,

188
00:38:27,190 --> 00:38:31,559
а параметр длины цикла показывает, сколько эпох проходит от скачка до скачка — у нас одна.

189
00:38:32,110 --> 00:38:36,450
При длине цикла 2 скачок происходил бы каждые две эпохи.

190
00:38:36,520 --> 00:38:51,599
Главное в алгоритме — менять скорость обучения каждый минибатч, повторюсь, обычно так никто не делает.

191
00:38:53,470 --> 00:38:59,760
Вопрос из зала: Объясните ещё раз значение параметра precompute.

192
00:39:00,820 --> 00:39:13,259
Да, мы к этому вернёмся. Мы будем поверхностно узнавать вещи, а потом возвращаться к ним,

193
00:39:13,260 --> 00:39:18,239
каждый раз читая новый код и узнавая новую теорию.

194
00:39:18,240 --> 00:39:24,630
На протяжении недели вы можете задавать ваши вопросы на форуме.

195
00:39:27,040 --> 00:39:40,290
Вопрос из зала: Мы хотим уловить общие закономерности, не сваливаясь в частности. Для этого берётся среднее от всех минимумов?

196
00:39:41,260 --> 00:39:50,850
Как видите, здесь написано ансамбль снимков — пока мы не прописываем это в коде, но да,

197
00:39:51,730 --> 00:40:04,489
для улучшения обобщения берётся среднее значение в минимумах. Пока мы просто выбираем последний минимум.

198
00:40:09,420 --> 00:40:27,889
Если хотите поэкспериментировать, есть параметр cycle_save_name, который сохраняет значения минимумов для ручного усреднения.

199
00:40:31,830 --> 00:40:33,830
Хорошо.

200
00:40:34,200 --> 00:40:45,229
Итак, у нас есть модель с долей правильных ответов 99.3% и мы потратили несколько минут на её обучение.

201
00:40:45,780 --> 00:41:01,670
Периодически я сохраняю веса модели в файл методом .save(), их можно загрузить обратно методом .load().

202
00:41:02,670 --> 00:41:19,310
Когда вы обучаете модель, все промежуточные файлы — заранее вычисленные функции активации, обрезанные для обработки изображения -

203
00:41:20,090 --> 00:41:48,020
хранятся в директории /data/dogscats/tmp.

204
00:41:48,540 --> 00:42:03,679
Если модель ведёт себя странно, причиной могут быть испорченные промежуточные файлы.

205
00:42:04,109 --> 00:42:08,659
Если удалить папку tmp, некоторые ошибки могут исчезнуть.

206
00:42:09,540 --> 00:42:12,549
В библиотеке fast.ai это аналог «выключить и заново включить, если работает неправильно».

207
00:42:13,200 --> 00:42:21,160
Веса модели сохраняются в папку /data/dogscats/models.

208
00:42:22,020 --> 00:42:26,089
Помню, когда только вышла статья про SGDR, кто-то написал в Twitter -

209
00:42:26,090 --> 00:42:30,650
«Чтобы ваша нейронная сеть работала, выключите и включите её».

210
00:42:33,180 --> 00:42:35,180
Вопрос?

211
00:42:36,360 --> 00:42:43,640
Вопрос из зала: Если я хочу заново обучить модель, мне нужно удалить все промежуточные файлы?

212
00:42:49,020 --> 00:43:07,730
Нет смысла удалять заранее вычисленные функции активации, это просто веса, скачанные из Интернета.

213
00:43:09,180 --> 00:43:21,049
Их стоит удалять, если они скачались неправильно или файлы были повреждены.

214
00:43:21,360 --> 00:43:31,309
Для разных датасетов и архитектур автоматически создаются промежуточные файлы с разными названиями, об этом думать не нужно.

215
00:43:31,770 --> 00:43:46,669
Если вы начинаете всё с нуля, просто создайте новый объект learn, и при вызове ConvLearner.pretrained() создастся новая модель.

216
00:43:49,140 --> 00:43:58,220
До перерыва хочется успеть обсудить тонкую настройку и дифференциальные скорости обучения.

217
00:43:59,040 --> 00:44:04,950
До сих пор мы никак не меняли вычисленные заранее функции активации, то есть использовали модели,

218
00:44:14,850 --> 00:44:30,829
которые уже знали, как находить края, градиенты, углы, кривые, повторяющиеся узоры, куски текста и глаза.

219
00:44:33,059 --> 00:44:51,319
Мы не меняли эти фильтры, не меняли веса в матрицах свёртки, просто добавляли сверху новые слои.

220
00:44:52,559 --> 00:45:10,309
Может оказаться, что ваша модель должна различать различные виды глаз или лиц, или вы ищете айсберги на спутниковых снимках,

221
00:45:10,920 --> 00:45:19,579
и для этого нужны совершенно другие признаки — поэтому придётся отбросить верхние слои и создавать их с первых слоёв.

222
00:45:21,029 --> 00:45:32,190
Мы строим классификатор изображений кошек и собак, и сильные изменения не понадобятся, но кое-что поправим.

223
00:45:32,190 --> 00:45:47,539
Для изменения фильтров свёртки нужно вызвать метод разморозки .unfreeze(). Замороженный слой — это неизмененный слой.

224
00:45:47,539 --> 00:45:49,999
Метод .unfreeze() размораживает все слои.

225
00:45:50,880 --> 00:46:07,549
Очевидно, что первый слой сильно менять не нужно — за полтора миллиона изображений модель научилась видеть края и градиенты,

226
00:46:07,549 --> 00:46:17,629
это полезное умение. Углы и закругления тоже можно оставить.

227
00:46:17,690 --> 00:46:37,159
В целом, первые слои не нужно обновлять, в отличие от последних, которые имеет смысл подстраивать под свою задачу.

228
00:46:38,909 --> 00:46:59,239
Поэтому мы создаём массив с различными скоростями обучения для различных слоёв — от внешних до внутренних.

229
00:46:59,339 --> 00:47:03,078
Эти скорости обучения соответствуют базовым геометрическим признакам,

230
00:47:03,779 --> 00:47:08,718
эти — более сложным свёрточным признакам,

231
00:47:09,179 --> 00:47:16,249
а эти — признакам, которые мы добавили в процессе обучения.

232
00:47:16,380 --> 00:47:29,390
Эти значения записаны в массив и передаются в метод .fit() для обучения модели.

233
00:47:29,640 --> 00:47:45,529
Мы назвали это дифференциальные скорости обучения, это не наше изобретение, но оно не очень известное.

234
00:47:46,019 --> 00:47:52,158
Я не знаю, описан ли этот метод в какой-нибудь статье.

235
00:47:52,859 --> 00:48:01,079
У Джейсона Йосински была статья, в которой он предлагал идею использовать разные скорости обучения,

236
00:48:01,079 --> 00:48:07,999
но вроде бы она нигде не воплощена, и я не знаю, называется ли это как-то иначе.

237
00:48:08,819 --> 00:48:19,338
Я обнаружил, что размораживание слоёв и использование дифференцированных скоростей обучения превращает хорошую модель в отличную.

238
00:48:24,959 --> 00:48:37,578
Вопрос из зала: У вас в массиве три гиперпараметра, и первый — это для последних добавленных слоёв?

239
00:48:40,049 --> 00:48:47,449
Нет, наоборот. Эти параметры относятся к группам слоёв, мы ещё будем говорить про архитектуру,

240
00:48:47,449 --> 00:48:51,000
эта нейронная сеть называется ResNet, остаточная нейронная сеть.

241
00:48:51,100 --> 00:48:51,970
Мы разделили её слои на три группы.

242
00:48:57,249 --> 00:49:09,269
Первая группа — внутренние слои, отвечающие за распознавание углов и краёв предметов.

243
00:49:09,940 --> 00:49:28,319
Вопрос из зала: Я думал, эти слои заморожены. Мы их разморозили и теперь обучаем вообще всё, что есть?

244
00:49:29,049 --> 00:49:33,538
Вопрос из зала: И для внутренних слоёв скорость обучения маленькая, потому что их не нужно сильно менять?

245
00:49:33,539 --> 00:49:43,169
Да, скорее всего, их вообще не нужно менять, но в принципе это возможно.

246
00:49:43,960 --> 00:49:45,960


247
00:49:48,759 --> 00:49:53,009
Вопрос из зала: Чем дифференциальные скорости обучения отличаются от подбора параметров по сетке?

248
00:49:55,119 --> 00:50:06,568
Всем. Подбор параметров по сетке — это поиск оптимального значения гиперпараметра.

249
00:50:07,719 --> 00:50:13,859
Можно думать об алгоритме поиска скорости обучения как о подборе параметров по сетке,

250
00:50:15,350 --> 00:50:16,490
но это никак не относится к дифференциальным скоростям обучения.

251
00:50:16,490 --> 00:50:23,180
На протяжении всего обучения модели для различных слоёв будут использоваться различные скорости обучения.

252
00:50:28,980 --> 00:50:49,758
Вопрос из зала: Нужно ли после обучения модели подавать ей на вход изображения тех же размеров, что и в тренировочной выборке?

253
00:50:50,099 --> 00:50:59,508
Про размеры мы ещё пока поговорим, пока ответ такой — в библиотеке fast.ai на вход можно подавать изображения любого размера.

254
00:51:02,849 --> 00:51:07,159
Вопрос из зала: Можно ли разморозить только один уровень?

255
00:51:07,619 --> 00:51:14,629
Да, метод .unfreeze_to(n) разморозит все слои до n-го.

256
00:51:19,440 --> 00:51:38,960
Я считаю, что это бесполезная практика и дифференциальные скорости обучения работают лучше.

257
00:51:43,470 --> 00:51:47,779
Вопрос из зала: А если данных для обучения очень мало?

258
00:51:48,539 --> 00:52:00,259
Нет, не очень помогает. Помогает в обратном случае — когда не хватает мощности GPU для обработки большого количества данных,

259
00:52:00,630 --> 00:52:06,740
размораживание не всех уровней помогает снизить нагрузку на память и уменьшить время обучения.

260
00:52:06,779 --> 00:52:13,758
Вопрос из зала: Переспрошу ещё раз. Можно ли разморозить только один слой?

261
00:52:14,190 --> 00:52:19,069
Нет, только все слои, начиная с какого-то.

262
00:52:21,119 --> 00:52:25,639
Думаю, что можно переписать исходный код и включить эту возможность, но не вижу, зачем.

263
00:52:28,589 --> 00:52:37,070
Я очень рад, что показываю вам все эти штуки, мы работали над ними весь год и это действительно новейшие технологии.

264
00:52:37,070 --> 00:52:49,680
Мы получаем долю правильных ответов 99.5% — это удивительно.

265
00:52:51,780 --> 00:53:05,599
Я оговорился, когда раньше говорил про значение второго параметра. Второй параметр — это количество циклов, а не эпох.

266
00:53:06,000 --> 00:53:19,700
Если бы параметр cycle_len был равен двум, то выполнилось бы три цикла, каждый длиной в две эпохи, итого шесть.

267
00:53:20,339 --> 00:53:24,979
Здесь семь эпох, это из-за параметра cycle_mult=2.

268
00:53:25,380 --> 00:53:39,609
Параметр cycle_mult=2 удваивает длину цикла в эпохах после каждого цикла. Первый цикл длится 1 эпоху, второй — 2, третий — 4, итого 7 эпох.

269
00:53:39,630 --> 00:53:55,520
Автор статьи, описавший этот подход, считает его полезным, и я с ним согласен, вот почему.

270
00:53:57,810 --> 00:54:11,299
Если длина цикла слишком короткая, алгоритм будет постоянно выскакивать вверх и не найдёт хорошую точку.

271
00:54:11,339 --> 00:54:23,269
Это может быть полезно в начале для прощупывания поверхности, но потом имеет смысл увеличить длину цикла.

272
00:54:24,329 --> 00:54:29,869
Значение cycle_mult=2 обычно подходит.

273
00:54:30,480 --> 00:54:35,179
У нас появляется много гиперпараметров, хотя сначала я говорил, что такого не будет.

274
00:54:35,400 --> 00:54:52,729
Всё нормально — скорость обучения всё ещё важнее всего, эти гиперпараметры просто позволяют немного улучшить модель.

275
00:54:53,759 --> 00:55:03,019
Конфигурация из трёх циклов с параметрами cycle_len=1 и cycle_mult=2 очень часто отлично работает.

276
00:55:04,769 --> 00:55:09,409
Если работает плохо, я пробую три цикла с параметром cycle_len=2 и без параметра cycle_mult.

277
00:55:09,930 --> 00:55:17,190
Эти две конфигурации охватывают большинство случаев, я не вижу смысла кропотливо подбирать новые.

278
00:55:17,190 --> 00:55:25,008
Вы можете просто использовать эту строку и получать хорошие результаты.

279
00:55:28,680 --> 00:55:34,669
Вопрос из зала: Почему более гладкие локальные минимумы соответствуют нейронным сетям, которые лучше обобщают?

280
00:55:39,660 --> 00:56:08,509
Возвращаемся к графику зависимости функции потерь от фиксированного параметра модели.

281
00:56:08,969 --> 00:56:18,349
Хорошо обобщающая модель невосприимчива к небольшим различиям в датасетах.

282
00:56:19,469 --> 00:56:27,059
Пусть синей и красной линиями показаны кривые потерь для двух различных датасетов.

283
00:56:27,159 --> 00:56:34,749


284
00:56:35,360 --> 00:56:43,090
Модель в остром локальном минимуме плохо предскажет слегка отличающийся датасет, а в гладком минимуме хорошо предскажет оба.

285
00:56:49,730 --> 00:57:02,858
Избежать этого помогает cycle_mult=2. До перерыва мы успеем ещё раз улучшить модель.

286
00:57:03,380 --> 00:57:16,929
Для этого посмотрим ещё раз на неправильно распознанные изображения.

287
00:57:20,720 --> 00:57:41,709
Как я уже говорил раньше, все изображения сначала обрезаются до квадратов.

288
00:57:42,740 --> 00:57:56,855
GPU быстрее работает, когда все изображения одинаковых размеров, возможно, в будущем это изменится.

289
00:57:56,955 --> 00:58:20,530
Изображение обрезается до квадрата с сохранением центра — теперь видно, почему это изображение было распознано неправильно.

290
00:58:20,530 --> 00:58:35,709
Модель видела только тело животного, и по такому снимку действительно сложно понять, кошка это или собака.

291
00:58:36,380 --> 00:58:42,160
Для решения этой проблемы мы применим тестовое приращение данных (TTA).

292
00:58:42,560 --> 00:58:52,385
После обучения модели мы проведём приращение данных на валидационной выборке

293
00:58:52,485 --> 00:59:02,310
и для каждого изображения выберем 4 новых случайных варианта.

294
00:59:02,720 --> 00:59:14,110
После обрезания до квадрата получится 5 вариантов изображения, для каждого варианта получим предсказание и усредним.

295
00:59:14,750 --> 00:59:33,789
Для неудачных изображений один из вариантов после обрезания может содержать морду животного и оценка улучшится.

296
00:59:35,270 --> 00:59:40,510
Для применения тестового приращения данных нужно вызвать метод .TTA().

297
00:59:40,700 --> 00:59:53,620
Оно называется тестовым, потому что применяется во время тестирования, сразу после обучения модели.

298
00:59:53,620 --> 01:00:00,910
Доля правильных ответов увеличилась до 99.65%.

299
01:00:01,460 --> 01:00:14,380
Вопрос из зала: Но во время обучения модели мы показываем ей только один вариант для каждого изображения?

300
01:00:14,930 --> 01:00:26,319
Нет, TTA здесь нет, я пробовал добавлять это в библиотеку, но тут этого нет.

301
01:00:26,320 --> 01:00:46,449
Здесь модель обучается с обычным приращением данных, то есть после каждой эпохи все изображения немного менялись.

302
01:00:47,030 --> 01:00:56,229
После обучения модели мы вызываем TTA на валидационной выборке (по умолчанию).

303
01:00:56,230 --> 01:01:00,630
Для каждого изображения в валидационной выборке создаются 4 новых варианта,

304
01:01:00,710 --> 01:01:09,610
предсказания по ним усредняются с предсказаниями по оригинальному изображению, и получается новая доля правильных ответов.

305
01:01:10,200 --> 01:01:16,199
Вопрос из зала: То есть во время TTA модель видит изображения, которые не видела при обучении?

306
01:01:17,590 --> 01:01:25,559
Да, все получающиеся в результате приращения данных изображения уникальны.

307
01:01:25,660 --> 01:01:33,960
Изображение может быть повёрнуто на 0.34 градуса и увеличено в 1.056 раз, но это новое изображение.

308
01:01:36,849 --> 01:01:46,169
Вопрос из зала: Почему нельзя нарисовать белые границы, дополнив изображение до квадрата, вместо обрезания?

309
01:01:46,170 --> 01:01:55,160
Можно. Есть много разных видов приращения данных, один из них — как раз добавление границ.

310
01:01:55,900 --> 01:02:06,240
По своему опыту могу сказать, что это не сильно помогает.

311
01:02:06,790 --> 01:02:12,209
Позже я покажу один из видов добавления границ — отражение,

312
01:02:12,210 --> 01:02:19,230
вместо белых границ вставляются отраженные части изображения, помогает со спутниковыми снимками.

313
01:02:19,869 --> 01:02:24,838
Обычно я приближаю изображение и обрезаю, а не добавляю границы.

314
01:02:28,390 --> 01:02:40,979
Вопрос из зала: Но в случае с длинной собакой при обрезании теряется морда, а при добавлении границ — нет.

315
01:02:41,560 --> 01:02:46,019
Да, в этом случае помогло бы добавление границ с отражением.

316
01:02:46,020 --> 01:02:49,739
В библиотеке fast.ai воплощено много видов приращения данных.

317
01:02:50,440 --> 01:03:01,229
Конечно, всё зависит от размеров изображения,

318
01:03:01,870 --> 01:03:09,750
но, как правило, при использовании приращения данных и TTA эффективнее найти максимально большое изображение

319
01:03:09,750 --> 01:03:22,049
и обрезать его до квадрата, чем вставлять границы и нагружать GPU.

320
01:03:22,050 --> 01:03:27,550
На практике добавление границ менее эффективно.

321
01:03:35,410 --> 01:03:44,190
Вопрос из зала: Как выглядит приращение данных для датасетов не из изображений?

322
01:03:44,680 --> 01:03:45,880


323
01:03:45,880 --> 01:03:47,440


324
01:03:47,440 --> 01:03:50,399
Сложный вопрос.

325
01:03:52,630 --> 01:03:58,560
Я обсуждал это со своими друзьями из области обработки естественного языка (NLP), мы доберёмся до этого через пару лекций.

326
01:03:59,110 --> 01:04:18,480
Есть пара примеров статей, где слова заменялись на синонимы, но в целом область приращения данных в NLP не развита.

327
01:04:23,500 --> 01:04:38,939
Вопрос из зала: Разве не проще было бы просто разрезать изображение, скажем, на три части вместо TTA?

328
01:04:40,349 --> 01:04:52,139
Для обучения модели — нет, гораздо эффективнее предоставить много слегка различающихся версий,

329
01:04:52,140 --> 01:04:58,890
чем просто три части изображения.

330
01:04:59,739 --> 01:05:07,960
Для TTA — да, возможно, это было бы лучше, но я ещё не написал соответствующий код в библиотеку.

331
01:05:07,960 --> 01:05:21,539
У меня где-то лежит старая версия кода. Я думаю, разрезание изображений хорошо бы сочеталось с приращением данных.

332
01:05:23,619 --> 01:05:32,729
Я тестировал это и результаты почти незаменты, поэтому этого нет в библиотеке, да и код сильно усложнился бы.

333
01:05:34,490 --> 01:05:41,510
Вопрос из зала: Открыт ли исходный код библиотеки fast.ai?

334
01:05:43,440 --> 01:05:53,660
Да, открыт. Здесь надо упомянуть пару вещей.

335
01:05:54,089 --> 01:06:01,699
Библиотека fast.ai построена на основе PyTorch,

336
01:06:02,940 --> 01:06:15,199
PyTorch появился недавно и все уважаемые мной исследователи его используют.

337
01:06:15,960 --> 01:06:20,584
Во второй части прошлого запуска второго курса обнаружилось, что новейшие техники

338
01:06:20,684 --> 01:06:32,629
не получается преподавать с Keras и TensorFlow, как раньше, поэтому мы перешли на PyTorch в середине работы.

339
01:06:33,630 --> 01:06:37,110
Проблема в том, что PyTorch довольно сложно использовать — всё надо писать с нуля.

340
01:06:37,210 --> 01:06:59,119
Вся библиотека fast.ai написана с нуля на основе PyTorch, чтобы вам не пришлось писать сотни строк кода для простых вещей.

341
01:06:59,910 --> 01:07:10,939
Мы хотим научить вас создавать модели мирового уровня. Для этого нужен PyTorch,

342
01:07:11,520 --> 01:07:27,740
но его сложно применять, поэтому мы написали библиотеку на его основе.

343
01:07:29,339 --> 01:07:36,859
Как я уже сказал, изначально мы использовали Keras, но потом поняли, что можно сильно всё упростить.

344
01:07:36,930 --> 01:07:50,298
В Jupyter ноутбуках прошлых запусков код в два-три раза длиннее и много возможностей ошибиться,

345
01:07:51,539 --> 01:08:01,969
поэтому мы написали библиотеку fast.ai, чтобы легко научить вас создавать современные модели.

346
01:08:02,729 --> 01:08:16,818
За последний год мы поняли, что эта библиотека помогает и нам. Мы начали разрабатывать больше новых методов,

347
01:08:16,819 --> 01:08:30,109
стали внедрять малоизвестные, но эффективные техники вроде поиска скорости обучения, которые ещё никто не автоматизировал.

348
01:08:31,109 --> 01:08:50,178
Библиотека fast.ai не только упрощает процесс, а ещё и предлагает массу уникальных возможностей.

349
01:08:51,299 --> 01:09:04,668
Сейчас библиотека довольно сырая, многие уже помогли нам в её написании, и я надеюсь, что к концу этого курса

350
01:09:06,270 --> 01:09:19,039
мы доведём её до ума, и все смогут её использовать. Открытый исходный код доступен на GitHub.

351
01:09:23,069 --> 01:09:32,689
Создаваемые в fast.ai модели можно экспортировать во множество форматов.

352
01:09:33,689 --> 01:09:40,339
Если вы создаёте приложение для смартфона, скорее всего, вам придётся использовать TensorFlow.

353
01:09:41,040 --> 01:09:53,329
Позже мы обсудим, что из библиотеки fast.ai работает под Keras и TensorFlow, чтобы вы поняли, чем они различаются.

354
01:09:53,908 --> 01:10:06,679
Если вкратце — простые вещи быстрее делать с Keras и TensorFlow, а fast.ai и PyTorch лучше подходят для сложных моделей.

355
01:10:07,590 --> 01:10:14,659
Если вам нужно использовать именно TensorFlow, возможно, придётся что-то упростить.

356
01:10:18,060 --> 01:10:29,600
Конкретная библиотека не так важна — каждый год всё меняется.

357
01:10:29,600 --> 01:10:34,879
Главное, чтобы вы поняли основные идеи — как подбирать скорость обучения, зачем нужны дифференциальные скорости обучения,

358
01:10:34,880 --> 01:10:43,009
как менять скорость обучения в процессе обучения модели, что делает SGDR и так далее.

359
01:10:44,550 --> 01:10:53,540
Через год библиотеки могут сильно измениться.

360
01:10:54,389 --> 01:10:56,389


361
01:11:03,510 --> 01:11:10,310
Вопрос из зала: Что вы думаете про Pyro?

362
01:11:10,310 --> 01:11:14,060
Мне очень интересно вероятностное программирование, но я пока не смотрел на Pyro. Очень круто, что Pyro использует PyTorch.

363
01:11:14,060 --> 01:11:18,859
Позже мы поговорим о том, что PyTorch — не просто библиотека для глубокого обучения.

364
01:11:18,860 --> 01:11:34,760
Например, PyTorch позволяет писать свои алгоритмы GPU-ускорения, мы этим ещё займёмся.

365
01:11:35,969 --> 01:11:41,719
Ладно, давайте сделаем перерыв на 8 минут и продолжим в 7:55.

366
01:11:46,590 --> 01:11:56,929
Итак, что значит доля правильных ответов 99.65%?

367
01:11:57,570 --> 01:12:06,409
В машинном обучении для оценивания качества модели часто используют матрицу ошибок.

368
01:12:06,719 --> 01:12:26,329
Сколько из 1000 кошек в валидационной выборке было распознано как кошки?

369
01:12:26,820 --> 01:12:33,259
Здесь 998 кошек из 1000 были распознаны как кошки, 2 — как собаки.

370
01:12:33,260 --> 01:12:39,980
Из 1000 собак 995 были распознаны как собаки и 5 — как кошки.

371
01:12:40,710 --> 01:12:50,599
Такие матрицы ошибок очень помогают, когда классов больше двух и непонятно, с чем больше всего проблем.

372
01:12:50,940 --> 01:12:59,480
Высокие значения выделены цветом, с такой матрицей удобно работать из предположения, что все цветные блоки должны быть на диагонали.

373
01:13:00,150 --> 01:13:10,130
После улучшения модели имеет смысл ещё раз посмотреть на неправильно распознанные изображения.

374
01:13:10,680 --> 01:13:18,770
Неправильных кошек было две, но по умолчанию выводится четыре изображения.

375
01:13:18,770 --> 01:13:32,600
Есть два изображения, на которых точно не кошка, но с этим непонятно — изображение плохого качества и не видно зрачков.

376
01:13:33,120 --> 01:13:49,069
Неправильных собак было пять, вот четыре из них. Одна из них очевидно не собака, две выглядят как ошибки и ещё одна — как недостаток информации.

377
01:13:50,190 --> 01:14:01,640
Классификатор получился отличный. Я участвовал с ним в нескольких соревнованиях Kaggle и написал про это две статьи.

378
01:14:01,640 --> 01:14:08,930
Он уже отличный, но потом мы ещё немного его улучшим.

379
01:14:08,930 --> 01:14:13,489
Вот что нужно делать для создания подобного классификатора:

380
01:14:13,770 --> 01:14:24,020
1. Применить на датасете один из видов приращения данных

381
01:14:24,660 --> 01:14:26,660
и использовать уже обученную нейронную сеть с помощью precompute=true.

382
01:14:27,179 --> 01:14:35,059
2. Найти оптимальную скорость обучения и 3. создать новый слой нейронной сети, обучая его 1-2 эпохи.

383
01:14:35,460 --> 01:14:44,720
4. Выставить precompute=false для использования приращения данных и создать новый слой, обучая его 2-3 эпохи с параметром cycle_len=1.

384
01:14:45,090 --> 01:14:56,059
5. Разморозить все уровни и 6. выставить различные скорости обучения для различных слоёв.

385
01:15:00,450 --> 01:15:07,110
В нашем случае разница между скоростями обучения для различных слоёв была в десять раз.

386
01:15:07,110 --> 01:15:21,410
Если вы работаете с обученной на изображениях ImageNet модели и собираетесь классифицировать обычные фотографии,

387
01:15:22,110 --> 01:15:29,179
имеет смысл делать скорость обучения каждый раз в 10 раз меньше, потому что внутренние слои уже достаточно хороши.

388
01:15:29,760 --> 01:15:39,139
Если вместо обычных фотографий у вас спутниковые или томографические снимки, внутренние слои придётся немного изменить,

389
01:15:39,140 --> 01:15:42,799
для этого можно выставить скорости обучения, различающиеся в 3 раза, а не в 10.

390
01:15:43,440 --> 01:15:48,109
Итак, скорости различаются в 3 или 10 раз.

391
01:15:51,450 --> 01:15:59,540
7. После разморозки можно снова подобрать скорость обучения.

392
01:15:59,580 --> 01:16:08,270
Я не подбирал, но модель поменялась - мы разморозили слои, добавили дифференциальные скорости обучения, можно и подобрать.

393
01:16:09,030 --> 01:16:14,179
После подбора можно сверить, поменялась ли оптимальная скорость обучения.

394
01:16:14,850 --> 01:16:20,630
Когда вы вызываете метод .lr_find() при наличии дифференциальных скоростей обучения, он выведет

395
01:16:21,000 --> 01:16:28,900
оптимальную скорость обучения для последнего слоя.

396
01:16:29,190 --> 01:16:35,450
8. Обучать всю нейронную сеть с параметром cycle_mult=2, пока не наступит переобучение или не кончится время.

397
01:16:35,610 --> 01:16:41,089
Давайте повторим эти шаги на новом датасете.

398
01:16:41,640 --> 01:16:53,070
Сегодня утром я заметил, что некоторые из вас приняли участие в соревновании Kaggle по различению пород собак.

399
01:16:53,680 --> 01:17:08,849
В этом соревновании нужно определить, к какой из 120 пород принадлежат собаки на фотографиях.

400
01:17:09,370 --> 01:17:29,789
Датасет может быть любой - томографические снимки, спутнивые снимки, любые размеченные изображения.

401
01:17:30,820 --> 01:17:40,499
Сейчас я покажу, что сделал сегодня утром за час.

402
01:17:41,650 --> 01:17:47,790
Я скачал данные соревнования по различеню пород собак с Kaggle, используя kaggle-cli -

403
01:17:48,130 --> 01:17:58,919
это интерфейс командной строки Kaggle, позволяющий скачать данные любого соревнования на ваш сервер Amazon, Crestle или любой другой.

404
01:17:59,440 --> 01:18:10,349
Я посмотрел на файлы - они организованы не так, как наш учебный датасет.

405
01:18:11,560 --> 01:18:22,350
Обучающая и тестовая выборки не размечены, их метки лежат в отдельном csv-файле.

406
01:18:22,450 --> 01:18:25,410
Я прочитал csv с помощью pandas, это библиотека Python для работы со структурированными файлами.

407
01:18:31,030 --> 01:18:39,120
Мы импортируем pandas как pd и вызываем метод pd.read_csv().

408
01:18:39,120 --> 01:18:46,260
Внутри csv файла - таблица соответствий имён файлов и пород собак, это второй из двух способов разметки данных.

409
01:18:46,260 --> 01:19:02,489
Первый способ - раскладывать изображения по разным папкам, второй - держать разметку в отдельном файле.

410
01:19:04,359 --> 01:19:10,019
С помощью pandas я создал сводную таблицу, чтобы посмотреть на распределение пород.

411
01:19:10,119 --> 01:19:24,689
Видно, что на самые распространённые породы приходится где-то по 100 изображений, на менее распространённые - около 60.

412
01:19:25,269 --> 01:19:30,239
В сводной таблице 120 строк, потому что в датасете представлено 120 пород собак.

413
01:19:30,760 --> 01:19:34,079
Пойдём по описанному выше алгоритму.

414
01:19:35,260 --> 01:19:48,599
1. Применить приращение данных. Я опять выбрал приращение данных transfoms_side_on и передал его в функцию tfms_from_model().

415
01:19:50,349 --> 01:20:00,148
Про параметр max_zoom мы ещё поговорим, он показывает максимально допустимое увеличение при приращении данных.

416
01:20:00,789 --> 01:20:13,618
Все измененные изображения будут увеличены максимум в 1.1 раза.

417
01:20:14,409 --> 01:20:30,929
Вместо метода .from_path() мы вызываем метод .from_csv и передаём туда csv-файл с метками данных.

418
01:20:31,479 --> 01:20:41,069
Параметры метода - директория с данными, папка с обучающей выборкой, csv с метками,

419
01:20:42,699 --> 01:20:47,728
папка с тестовой выборкой - она нужна, если вы хотите отправить результат на Kaggle, мы это ещё обсудим.

420
01:20:49,149 --> 01:21:05,499
В предыдущем датасете у нас была валидационная выборка, а в этом её нет.

421
01:21:05,499 --> 01:21:13,089
Для оценивания качества модели перед отправкой на Kaggle мы случайным образом выделим валидационную выборку из обучающей.

422
01:21:13,670 --> 01:21:26,679
Здесь я сначала получил размер обучающей выборки n, преобразовав csv файл в список строк и взяв его длину.

423
01:21:27,050 --> 01:21:31,779
Размер выборки на единицу меньше количества строк, потому что первая строка - заголовок.

424
01:21:32,030 --> 01:21:47,679
Затем я вызвал метод получения индексов для кросс-валидации get_cv_idxs(). Про кросс-валидацию мы ещё поговорим.

425
01:21:48,590 --> 01:22:09,430
По умолчанию метод возвращает индексы случайных 20% выборки, это и будет наша валидационная выборка.

426
01:22:11,090 --> 01:22:34,279
Давайте посмотрим на неё. Индексы - это просто числа, n=10222, а размер валидационной выборки - 2044.

427
01:22:35,310 --> 01:22:50,629
Массив индексов валидационной выборки тоже передаётся как параметр в метод .from_csv.

428
01:22:52,350 --> 01:23:18,709
Названия файлов в csv не содержат суффикса .jpg, поэтому мы передаём его туда же как suffix='.jpg'.

429
01:23:19,710 --> 01:23:25,219
Это все необходимые параметры.

430
01:23:25,890 --> 01:23:36,739
Многие из вас на этой неделе заметили, что обучающая выборка находится в объекте data.trn_ds и её можно изучать.

431
01:23:37,290 --> 01:23:55,699
Например, она содержит имена изображений, можно взять, например, самое первое и посмтореть на него.

432
01:23:56,040 --> 01:24:04,940
Мне было интересно, как выглядят данные, и я нашёл очаровательного щенка, очень мило.

433
01:24:04,940 --> 01:24:20,149
Дальше я смотрю, какого размера изображения в датасете. Если они слишком большие или слишком маленькие, это неудобно.

434
01:24:20,670 --> 01:24:29,779
Стандартные форматы моделей, обучающихся на изображениях ImageNet - 224x224 и 299x299.

435
01:24:30,090 --> 01:24:38,059
Если ваши изображения близки к таким размерам, как здесь - это отлично.

436
01:24:39,880 --> 01:24:51,509
Здесь я создаю словарь, используя генератор словарей. Генераторы словарей и списков в Python - очень удобные конструкции.

437
01:24:52,060 --> 01:25:02,040
Я прохожу по всем файлам и создаю словарь, где каждому имени файла соответствует его размер.

438
01:25:04,389 --> 01:25:17,760
Ещё одна удобная конструкция, о которой я потом расскажу - распаковка аргументов, здесь мы выделяем высоты и ширины изображений.

439
01:25:18,639 --> 01:25:27,449
После этого массивы высот и ширин оборачиваются в массивы numpy, вот первые пять высот изображений.

440
01:25:27,969 --> 01:25:45,899
Здесь мы, как обычно, импортируем matplotlib.pyplot как plt, и строим гистограмму распределения высот методом plt.hist().

441
01:25:45,900 --> 01:25:48,480
Видно, что большинство изображений ниже 1000 пикселей, построим гистограмму распределения высот

442
01:25:48,480 --> 01:25:52,589


443
01:25:53,139 --> 01:25:56,909


444
01:25:58,060 --> 01:26:03,029


445
01:26:03,909 --> 01:26:07,319


446
01:26:07,960 --> 01:26:10,889


447
01:26:10,889 --> 01:26:16,379


448
01:26:16,960 --> 01:26:23,520


449
01:26:23,520 --> 01:26:25,520


450
01:26:27,940 --> 01:26:34,799


451
01:26:39,179 --> 01:26:41,689


452
01:26:44,909 --> 01:26:52,129


453
01:26:54,030 --> 01:26:55,679


454
01:26:55,679 --> 01:26:57,449


455
01:27:00,949 --> 01:27:07,699


456
01:27:08,909 --> 01:27:12,919


457
01:27:12,920 --> 01:27:17,599


458
01:27:18,630 --> 01:27:24,799


459
01:27:24,800 --> 01:27:26,800


460
01:27:27,449 --> 01:27:33,049


461
01:27:34,530 --> 01:27:41,300


462
01:27:41,519 --> 01:27:43,519


463
01:27:44,010 --> 01:27:46,489


464
01:27:47,369 --> 01:27:50,328


465
01:27:51,119 --> 01:27:53,119


466
01:27:53,940 --> 01:27:55,940


467
01:27:56,489 --> 01:28:01,458


468
01:28:03,059 --> 01:28:06,228


469
01:28:07,709 --> 01:28:09,739


470
01:28:11,639 --> 01:28:15,018


471
01:28:15,019 --> 01:28:19,639


472
01:28:19,639 --> 01:28:21,209


473
01:28:21,209 --> 01:28:22,349


474
01:28:22,349 --> 01:28:24,469


475
01:28:27,389 --> 01:28:29,179


476
01:28:29,179 --> 01:28:32,149


477
01:28:32,280 --> 01:28:37,489


478
01:28:38,130 --> 01:28:39,440


479
01:28:44,929 --> 01:28:48,408


480
01:28:48,850 --> 01:28:54,720


481
01:28:55,420 --> 01:29:01,500


482
01:29:02,320 --> 01:29:04,710


483
01:29:04,990 --> 01:29:11,969


484
01:29:11,970 --> 01:29:13,090


485
01:29:13,090 --> 01:29:16,410


486
01:29:17,050 --> 01:29:20,490


487
01:29:21,700 --> 01:29:23,200


488
01:29:23,200 --> 01:29:29,189


489
01:29:30,280 --> 01:29:34,319


490
01:29:35,020 --> 01:29:40,080


491
01:29:40,270 --> 01:29:43,379


492
01:29:44,170 --> 01:29:47,670


493
01:29:48,040 --> 01:29:52,950


494
01:29:53,770 --> 01:29:58,560


495
01:29:58,810 --> 01:30:03,780


496
01:30:04,570 --> 01:30:10,680


497
01:30:11,350 --> 01:30:17,939


498
01:30:17,940 --> 01:30:19,940


499
01:30:21,190 --> 01:30:22,440


500
01:30:22,440 --> 01:30:29,250


501
01:30:30,040 --> 01:30:34,410


502
01:30:34,410 --> 01:30:38,939


503
01:30:38,940 --> 01:30:43,020


504
01:30:44,500 --> 01:30:49,740


505
01:30:49,810 --> 01:30:52,709


506
01:30:53,320 --> 01:30:54,610


507
01:30:54,610 --> 01:30:56,440


508
01:30:56,440 --> 01:31:00,450


509
01:31:00,850 --> 01:31:03,579


510
01:31:04,580 --> 01:31:06,580


511
01:31:06,830 --> 01:31:10,000


512
01:31:10,000 --> 01:31:12,939


513
01:31:12,940 --> 01:31:18,190


514
01:31:18,770 --> 01:31:25,479


515
01:31:25,670 --> 01:31:30,069


516
01:31:30,350 --> 01:31:36,340


517
01:31:37,190 --> 01:31:44,829


518
01:31:44,830 --> 01:31:52,030


519
01:31:53,120 --> 01:31:58,750


520
01:32:00,530 --> 01:32:02,530


521
01:32:02,630 --> 01:32:04,630


522
01:32:05,150 --> 01:32:08,199


523
01:32:09,170 --> 01:32:11,170


524
01:32:11,480 --> 01:32:16,719


525
01:32:17,660 --> 01:32:19,660


526
01:32:20,000 --> 01:32:22,929


527
01:32:22,930 --> 01:32:27,159


528
01:32:27,740 --> 01:32:35,650


529
01:32:36,170 --> 01:32:37,220


530
01:32:37,220 --> 01:32:41,949


531
01:32:41,950 --> 01:32:49,780


532
01:32:52,160 --> 01:32:58,720


533
01:32:59,720 --> 01:33:07,449


534
01:33:08,120 --> 01:33:13,270


535
01:33:13,270 --> 01:33:17,589


536
01:33:18,289 --> 01:33:19,939


537
01:33:19,939 --> 01:33:21,939


538
01:33:22,610 --> 01:33:28,269


539
01:33:28,579 --> 01:33:31,629


540
01:33:32,840 --> 01:33:36,249


541
01:33:36,249 --> 01:33:39,909


542
01:33:39,909 --> 01:33:45,398


543
01:33:45,399 --> 01:33:50,589


544
01:33:50,899 --> 01:33:52,929


545
01:33:52,929 --> 01:33:59,379


546
01:33:59,840 --> 01:34:02,229


547
01:34:03,260 --> 01:34:08,949


548
01:34:10,789 --> 01:34:12,499


549
01:34:12,499 --> 01:34:19,089


550
01:34:19,090 --> 01:34:26,229


551
01:34:26,630 --> 01:34:28,630


552
01:34:29,209 --> 01:34:32,349


553
01:34:32,349 --> 01:34:37,478


554
01:34:37,479 --> 01:34:39,479


555
01:34:43,610 --> 01:34:47,349


556
01:34:48,199 --> 01:34:50,199


557
01:34:50,869 --> 01:34:55,629


558
01:34:56,510 --> 01:35:01,329


559
01:35:06,709 --> 01:35:10,629


560
01:35:12,199 --> 01:35:15,339


561
01:35:17,209 --> 01:35:22,839


562
01:35:22,840 --> 01:35:25,929


563
01:35:26,599 --> 01:35:28,599


564
01:35:29,869 --> 01:35:34,089


565
01:35:34,090 --> 01:35:37,090


566
01:35:37,809 --> 01:35:39,809


567
01:35:42,219 --> 01:35:44,669


568
01:35:44,670 --> 01:35:50,850


569
01:35:50,850 --> 01:35:57,120


570
01:35:57,310 --> 01:36:00,330


571
01:36:00,429 --> 01:36:02,380


572
01:36:02,380 --> 01:36:07,980


573
01:36:13,870 --> 01:36:20,519


574
01:36:20,770 --> 01:36:25,199


575
01:36:29,800 --> 01:36:36,480


576
01:36:37,060 --> 01:36:41,789


577
01:36:42,699 --> 01:36:46,499


578
01:36:47,050 --> 01:36:51,029


579
01:36:51,030 --> 01:36:54,659


580
01:36:55,179 --> 01:36:58,859


581
01:37:00,179 --> 01:37:01,330


582
01:37:01,330 --> 01:37:03,040


583
01:37:03,040 --> 01:37:05,129


584
01:37:05,130 --> 01:37:10,199


585
01:37:10,270 --> 01:37:15,270


586
01:37:15,270 --> 01:37:21,749


587
01:37:22,690 --> 01:37:27,899


588
01:37:28,480 --> 01:37:33,779


589
01:37:34,570 --> 01:37:36,570


590
01:37:36,610 --> 01:37:41,190


591
01:37:41,949 --> 01:37:43,949


592
01:37:45,280 --> 01:37:47,610


593
01:37:48,610 --> 01:37:55,880


594
01:37:57,030 --> 01:38:04,280


595
01:38:06,929 --> 01:38:11,539


596
01:38:11,540 --> 01:38:14,959


597
01:38:16,170 --> 01:38:21,500


598
01:38:22,800 --> 01:38:25,670


599
01:38:25,670 --> 01:38:30,230


600
01:38:36,110 --> 01:38:38,110


601
01:38:39,660 --> 01:38:41,660


602
01:38:46,350 --> 01:38:51,949


603
01:38:53,780 --> 01:38:58,820


604
01:38:59,640 --> 01:39:06,559


605
01:39:12,600 --> 01:39:19,249


606
01:39:19,250 --> 01:39:21,290


607
01:39:21,290 --> 01:39:27,649


608
01:39:28,170 --> 01:39:30,170


609
01:39:33,510 --> 01:39:40,880


610
01:39:42,870 --> 01:39:45,559


611
01:39:46,560 --> 01:39:50,600


612
01:39:51,150 --> 01:39:57,080


613
01:39:59,910 --> 01:40:02,719


614
01:40:04,080 --> 01:40:06,709


615
01:40:08,559 --> 01:40:13,319


616
01:40:13,420 --> 01:40:18,479


617
01:40:19,300 --> 01:40:24,449


618
01:40:25,989 --> 01:40:29,518


619
01:40:30,429 --> 01:40:35,219


620
01:40:35,559 --> 01:40:43,109


621
01:40:43,780 --> 01:40:45,510


622
01:40:45,510 --> 01:40:46,840


623
01:40:46,840 --> 01:40:52,409


624
01:40:52,989 --> 01:40:57,328


625
01:40:58,119 --> 01:41:03,509


626
01:41:03,820 --> 01:41:08,729


627
01:41:08,729 --> 01:41:15,479


628
01:41:16,630 --> 01:41:22,679


629
01:41:23,590 --> 01:41:26,519


630
01:41:29,499 --> 01:41:34,289


631
01:41:34,289 --> 01:41:39,958


632
01:41:40,539 --> 01:41:43,859


633
01:41:45,010 --> 01:41:47,010


634
01:41:48,429 --> 01:41:54,388


635
01:41:55,090 --> 01:41:59,699


636
01:42:01,949 --> 01:42:04,158


637
01:42:05,130 --> 01:42:10,069


638
01:42:11,579 --> 01:42:13,289


639
01:42:13,289 --> 01:42:15,589


640
01:42:16,409 --> 01:42:20,538


641
01:42:23,099 --> 01:42:27,558


642
01:42:27,559 --> 01:42:31,819


643
01:42:39,659 --> 01:42:44,538


644
01:42:44,729 --> 01:42:50,239


645
01:42:50,729 --> 01:42:53,689


646
01:42:55,530 --> 01:43:01,639


647
01:43:02,550 --> 01:43:03,809


648
01:43:03,809 --> 01:43:10,819


649
01:43:12,780 --> 01:43:15,739


650
01:43:16,289 --> 01:43:21,049


651
01:43:21,719 --> 01:43:24,408


652
01:43:25,349 --> 01:43:27,529


653
01:43:28,199 --> 01:43:30,059


654
01:43:30,059 --> 01:43:32,268


655
01:43:33,719 --> 01:43:39,138


656
01:43:39,139 --> 01:43:41,839


657
01:43:41,840 --> 01:43:46,969


658
01:43:46,969 --> 01:43:51,498


659
01:43:52,559 --> 01:43:58,248


660
01:43:58,249 --> 01:44:03,469


661
01:44:03,900 --> 01:44:09,769


662
01:44:10,709 --> 01:44:12,709


663
01:44:14,439 --> 01:44:16,559


664
01:44:18,639 --> 01:44:22,679


665
01:44:22,679 --> 01:44:28,199


666
01:44:28,659 --> 01:44:31,498


667
01:44:31,659 --> 01:44:37,409


668
01:44:37,409 --> 01:44:38,429


669
01:44:38,429 --> 01:44:39,159


670
01:44:39,159 --> 01:44:45,149


671
01:44:48,090 --> 01:44:49,929


672
01:44:49,929 --> 01:44:55,289


673
01:44:55,290 --> 01:45:02,219


674
01:45:06,010 --> 01:45:10,170


675
01:45:10,840 --> 01:45:13,980


676
01:45:14,800 --> 01:45:20,639


677
01:45:22,090 --> 01:45:24,210


678
01:45:24,210 --> 01:45:30,179


679
01:45:30,179 --> 01:45:33,839


680
01:45:33,969 --> 01:45:40,019


681
01:45:40,210 --> 01:45:45,419


682
01:45:45,820 --> 01:45:50,340


683
01:45:50,949 --> 01:45:55,499


684
01:45:55,570 --> 01:45:59,520


685
01:45:59,590 --> 01:46:02,849


686
01:46:03,489 --> 01:46:11,039


687
01:46:11,920 --> 01:46:18,989


688
01:46:19,869 --> 01:46:22,859


689
01:46:33,820 --> 01:46:35,820


690
01:46:38,920 --> 01:46:43,109


691
01:46:44,619 --> 01:46:51,299


692
01:46:51,940 --> 01:46:56,639


693
01:46:57,880 --> 01:47:02,190


694
01:47:03,310 --> 01:47:05,310


695
01:47:05,560 --> 01:47:08,160


696
01:47:10,880 --> 01:47:13,040


697
01:47:17,130 --> 01:47:20,839


698
01:47:20,840 --> 01:47:25,429


699
01:47:26,310 --> 01:47:31,850


700
01:47:33,510 --> 01:47:36,679


701
01:47:37,260 --> 01:47:40,610


702
01:47:41,010 --> 01:47:45,920


703
01:47:46,020 --> 01:47:50,779


704
01:47:50,780 --> 01:47:56,480


705
01:47:57,449 --> 01:47:59,449


706
01:48:00,179 --> 01:48:02,658


707
01:48:05,969 --> 01:48:07,940


708
01:48:07,940 --> 01:48:11,839


709
01:48:13,670 --> 01:48:15,670


710
01:48:16,760 --> 01:48:22,900


711
01:48:24,860 --> 01:48:28,420


712
01:48:29,840 --> 01:48:31,960


713
01:48:31,960 --> 01:48:37,870


714
01:48:38,000 --> 01:48:41,830


715
01:48:42,170 --> 01:48:46,330


716
01:48:46,880 --> 01:48:52,390


717
01:48:53,300 --> 01:48:55,300


718
01:48:57,110 --> 01:49:03,699


719
01:49:04,520 --> 01:49:06,230


720
01:49:14,750 --> 01:49:18,879


721
01:49:19,550 --> 01:49:26,350


722
01:49:26,350 --> 01:49:30,309


723
01:49:31,610 --> 01:49:36,489


724
01:49:36,890 --> 01:49:41,289


725
01:49:41,930 --> 01:49:43,930


726
01:49:44,090 --> 01:49:49,299


727
01:49:49,670 --> 01:49:54,699


728
01:49:59,420 --> 01:50:05,710


729
01:50:06,590 --> 01:50:11,080


730
01:50:11,840 --> 01:50:14,710


731
01:50:14,710 --> 01:50:19,120


732
01:50:19,120 --> 01:50:24,219


733
01:50:24,219 --> 01:50:28,239


734
01:50:28,790 --> 01:50:31,149


735
01:50:31,429 --> 01:50:36,399


736
01:50:36,400 --> 01:50:38,400


737
01:50:38,570 --> 01:50:42,009


738
01:50:42,770 --> 01:50:49,029


739
01:50:49,030 --> 01:50:54,219


740
01:50:54,219 --> 01:50:58,479


741
01:50:58,480 --> 01:51:00,320


742
01:51:00,320 --> 01:51:07,690


743
01:51:08,119 --> 01:51:09,440


744
01:51:09,440 --> 01:51:11,329


745
01:51:11,329 --> 01:51:13,779


746
01:51:13,780 --> 01:51:20,559


747
01:51:20,659 --> 01:51:22,309


748
01:51:22,309 --> 01:51:28,779


749
01:51:28,780 --> 01:51:32,050


750
01:51:34,099 --> 01:51:38,049


751
01:51:39,440 --> 01:51:42,129


752
01:51:42,829 --> 01:51:45,729


753
01:51:46,520 --> 01:51:47,869


754
01:51:58,280 --> 01:52:04,690


755
01:52:05,750 --> 01:52:08,949


756
01:52:09,980 --> 01:52:11,179


757
01:52:11,179 --> 01:52:13,209


758
01:52:13,969 --> 01:52:19,328


759
01:52:21,020 --> 01:52:22,909


760
01:52:27,429 --> 01:52:31,359


761
01:52:31,880 --> 01:52:37,719


762
01:52:39,860 --> 01:52:44,770


763
01:52:46,040 --> 01:52:52,390


764
01:52:54,470 --> 01:52:56,470


765
01:52:58,640 --> 01:53:00,640


766
01:53:01,100 --> 01:53:03,100


767
01:53:03,140 --> 01:53:05,140


768
01:53:05,450 --> 01:53:10,599


769
01:53:10,600 --> 01:53:14,140


770
01:53:16,190 --> 01:53:21,760


771
01:53:24,980 --> 01:53:26,980


772
01:53:27,440 --> 01:53:31,690


773
01:53:31,730 --> 01:53:36,160


774
01:53:36,500 --> 01:53:39,850


775
01:53:40,850 --> 01:53:45,399


776
01:53:46,010 --> 01:53:52,780


777
01:53:53,840 --> 01:53:59,559


778
01:53:59,690 --> 01:54:01,690


779
01:54:02,390 --> 01:54:04,629


780
01:54:04,630 --> 01:54:09,460


781
01:54:10,490 --> 01:54:12,999


782
01:54:13,760 --> 01:54:16,419


783
01:54:16,420 --> 01:54:23,710


784
01:54:23,710 --> 01:54:29,530


785
01:54:30,140 --> 01:54:31,700


786
01:54:32,720 --> 01:54:34,300


787
01:54:34,300 --> 01:54:37,300


788
01:54:37,340 --> 01:54:39,909


789
01:54:40,400 --> 01:54:41,960


790
01:54:41,960 --> 01:54:44,859


791
01:54:44,950 --> 01:54:49,090


792
01:54:50,660 --> 01:54:57,609


793
01:54:59,000 --> 01:55:01,000


794
01:55:01,670 --> 01:55:08,770


795
01:55:09,800 --> 01:55:17,350


796
01:55:18,020 --> 01:55:23,919


797
01:55:24,140 --> 01:55:29,409


798
01:55:30,020 --> 01:55:35,859


799
01:55:35,860 --> 01:55:42,100


800
01:55:42,800 --> 01:55:44,800


801
01:55:45,830 --> 01:55:47,300


802
01:55:47,300 --> 01:55:52,029


803
01:55:52,100 --> 01:55:59,379


804
01:55:59,380 --> 01:56:03,219


805
01:56:03,860 --> 01:56:09,250


806
01:56:09,250 --> 01:56:13,750


807
01:56:14,510 --> 01:56:17,199


808
01:56:25,460 --> 01:56:26,810


809
01:56:26,810 --> 01:56:33,370


810
01:56:34,159 --> 01:56:36,159


811
01:56:36,469 --> 01:56:43,719


812
01:56:43,719 --> 01:56:49,448


813
01:56:49,449 --> 01:56:56,979


814
01:56:56,980 --> 01:56:58,489


815
01:56:58,489 --> 01:57:00,489


816
01:57:00,679 --> 01:57:02,679


817
01:57:02,840 --> 01:57:08,620


818
01:57:08,989 --> 01:57:11,859


819
01:57:12,560 --> 01:57:14,560


820
01:57:14,720 --> 01:57:19,059


821
01:57:19,970 --> 01:57:22,659


822
01:57:23,450 --> 01:57:28,539


823
01:57:29,660 --> 01:57:31,839


824
01:57:32,870 --> 01:57:38,260


825
01:57:38,450 --> 01:57:42,789


826
01:57:44,870 --> 01:57:49,300


827
01:57:49,940 --> 01:57:51,940


828
01:57:52,100 --> 01:57:57,249


829
01:57:57,830 --> 01:58:03,010


830
01:58:03,740 --> 01:58:10,269


831
01:58:11,090 --> 01:58:13,090


832
01:58:13,550 --> 01:58:16,059


833
01:58:16,820 --> 01:58:18,820


834
01:58:19,160 --> 01:58:21,160


835
01:58:21,200 --> 01:58:27,729


836
01:58:29,450 --> 01:58:31,420


837
01:58:31,420 --> 01:58:36,220


838
01:58:36,290 --> 01:58:40,330


839
01:58:41,000 --> 01:58:43,000


840
01:58:43,340 --> 01:58:50,440


841
01:58:50,990 --> 01:58:53,109


842
01:58:53,180 --> 01:58:59,349


843
01:58:59,350 --> 01:59:02,289


844
01:59:02,290 --> 01:59:05,620


845
01:59:06,170 --> 01:59:08,530


846
01:59:09,140 --> 01:59:11,800


847
01:59:13,190 --> 01:59:16,000


848
01:59:16,640 --> 01:59:22,660


849
01:59:23,190 --> 01:59:25,460


850
01:59:26,010 --> 01:59:31,250


851
01:59:32,099 --> 01:59:38,119


852
01:59:38,429 --> 01:59:42,379


853
01:59:43,080 --> 01:59:48,679


854
01:59:48,840 --> 01:59:54,500


855
01:59:55,139 --> 02:00:00,919


856
02:00:01,440 --> 02:00:03,679


857
02:00:04,590 --> 02:00:11,630


858
02:00:12,690 --> 02:00:17,149


859
02:00:18,030 --> 02:00:22,580


860
02:00:23,520 --> 02:00:24,570


861
02:00:27,510 --> 02:00:33,260


862
02:00:33,530 --> 02:00:36,349


863
02:00:37,170 --> 02:00:39,170


864
02:00:40,199 --> 02:00:42,199


865
02:00:43,530 --> 02:00:50,239


866
02:00:50,310 --> 02:00:52,310


867
02:00:52,710 --> 02:00:57,409


868
02:00:59,040 --> 02:01:00,869


869
02:01:00,869 --> 02:01:02,869


870
02:01:03,780 --> 02:01:07,070


871
02:01:08,730 --> 02:01:10,730


872
02:01:11,010 --> 02:01:16,010


873
02:01:16,010 --> 02:01:18,010


874
02:01:18,540 --> 02:01:24,560


875
02:01:24,599 --> 02:01:29,839


876
02:01:30,610 --> 02:01:34,239


877
02:01:34,940 --> 02:01:36,940


878
02:01:37,010 --> 02:01:38,750


879
02:01:38,750 --> 02:01:43,659


880
02:01:45,500 --> 02:01:47,500


881
02:01:48,650 --> 02:01:56,409


882
02:01:57,800 --> 02:02:02,560


883
02:02:05,480 --> 02:02:07,689


884
02:02:08,960 --> 02:02:13,659


885
02:02:13,660 --> 02:02:19,180


886
02:02:19,340 --> 02:02:22,060


887
02:02:23,780 --> 02:02:27,639


888
02:02:31,010 --> 02:02:34,119


889
02:02:36,020 --> 02:02:37,430


890
02:02:37,430 --> 02:02:39,230


891
02:02:41,510 --> 02:02:44,739


892
02:02:45,410 --> 02:02:47,410


893
02:02:49,490 --> 02:02:53,920


894
02:02:54,890 --> 02:02:58,900


895
02:03:00,020 --> 02:03:01,610


896
02:03:05,180 --> 02:03:07,180


897
02:03:08,520 --> 02:03:10,520


898
02:03:10,990 --> 02:03:14,879


899
02:03:16,000 --> 02:03:18,299


900
02:03:18,970 --> 02:03:21,119


901
02:03:21,190 --> 02:03:26,609


902
02:03:26,710 --> 02:03:29,640


903
02:03:30,460 --> 02:03:32,460


904
02:03:33,190 --> 02:03:38,790


905
02:03:38,790 --> 02:03:45,990


906
02:03:46,180 --> 02:03:48,180


907
02:03:48,430 --> 02:03:52,439


908
02:03:52,750 --> 02:03:55,109


909
02:03:55,720 --> 02:04:02,970


910
02:04:02,970 --> 02:04:04,970


911
02:04:05,680 --> 02:04:10,019


912
02:04:11,410 --> 02:04:16,260


913
02:04:18,190 --> 02:04:20,879


914
02:04:22,510 --> 02:04:24,510


915
02:04:25,270 --> 02:04:28,950


916
02:04:33,840 --> 02:04:34,600


917
02:04:34,600 --> 02:04:39,419


918
02:04:39,820 --> 02:04:45,600


919
02:04:47,080 --> 02:04:50,039


920
02:04:50,040 --> 02:04:55,379


921
02:04:56,680 --> 02:04:58,680


922
02:04:58,990 --> 02:05:03,059


923
02:05:04,060 --> 02:05:05,610


924
02:05:11,440 --> 02:05:17,069


925
02:05:17,260 --> 02:05:22,990


926
02:05:25,970 --> 02:05:30,820


927
02:05:31,460 --> 02:05:37,390


928
02:05:37,540 --> 02:05:39,540


929
02:05:39,950 --> 02:05:45,249


930
02:05:45,440 --> 02:05:49,150


931
02:05:49,150 --> 02:05:54,400


932
02:05:55,100 --> 02:05:58,990


933
02:05:59,180 --> 02:06:01,930


934
02:06:02,570 --> 02:06:04,570


935
02:06:05,600 --> 02:06:07,600


936
02:06:11,330 --> 02:06:18,400


937
02:06:19,100 --> 02:06:25,059


938
02:06:25,870 --> 02:06:31,570


939
02:06:32,630 --> 02:06:38,199


940
02:06:38,900 --> 02:06:40,100


941
02:06:40,100 --> 02:06:42,100


942
02:06:42,530 --> 02:06:44,530


943
02:06:44,960 --> 02:06:46,460


944
02:06:46,460 --> 02:06:47,870


945
02:06:47,870 --> 02:06:49,870


946
02:06:51,110 --> 02:06:53,650


947
02:06:53,810 --> 02:06:59,110


948
02:07:00,560 --> 02:07:01,670


949
02:07:01,670 --> 02:07:08,170


950
02:07:08,170 --> 02:07:10,170


951
02:07:11,749 --> 02:07:14,858


952
02:07:16,159 --> 02:07:18,159


953
02:07:18,800 --> 02:07:22,869


954
02:07:23,629 --> 02:07:27,309


